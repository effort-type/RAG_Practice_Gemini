{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPgfsa1K4Uus76DuNRm3kNR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"d55a4dfd368e40b990f6dcfdd99289d8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f475ef1cba674ea2afcfe4e023466423","IPY_MODEL_aa2e448de69a43c78aa6411902546c74","IPY_MODEL_2ab73e37b32940479ea6985ed57f8587"],"layout":"IPY_MODEL_17d58864859b49d6865b9efb0760f868"}},"f475ef1cba674ea2afcfe4e023466423":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d32bbb4d46574807881b418e6b356910","placeholder":"​","style":"IPY_MODEL_e08930e8e63e4932823e1b52ad9e2ed4","value":"modules.json: 100%"}},"aa2e448de69a43c78aa6411902546c74":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c537a19e10f480c8edcd8dae0f510b7","max":349,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b711df6aca4f4b8b8a5ea0fc562087d1","value":349}},"2ab73e37b32940479ea6985ed57f8587":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_231fa7a773a444d69090c21cf07c3e7c","placeholder":"​","style":"IPY_MODEL_4e7eaeff3aa24e8cb1287290864f1fb2","value":" 349/349 [00:00&lt;00:00, 31.0kB/s]"}},"17d58864859b49d6865b9efb0760f868":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d32bbb4d46574807881b418e6b356910":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e08930e8e63e4932823e1b52ad9e2ed4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c537a19e10f480c8edcd8dae0f510b7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b711df6aca4f4b8b8a5ea0fc562087d1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"231fa7a773a444d69090c21cf07c3e7c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4e7eaeff3aa24e8cb1287290864f1fb2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"95bb875bf8cd4c838f4eac842726e4f8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cd4eec5186db45e3bdb94aba0ce0baab","IPY_MODEL_fbac92b290f5491a834223ec1c58e4f0","IPY_MODEL_05719c7d5f0a42c98fe580778910f35f"],"layout":"IPY_MODEL_9489610210a44f369841b058e42fe7db"}},"cd4eec5186db45e3bdb94aba0ce0baab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8876b6b590f64e37bdafcbb3d974b93e","placeholder":"​","style":"IPY_MODEL_28c2d90277354d8f99282de952fc1fec","value":"config_sentence_transformers.json: 100%"}},"fbac92b290f5491a834223ec1c58e4f0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5d6fe94e3561419d94cfd5a3c18d8f4a","max":220,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dca5fed3fb4d47b8bb3498ecf29157c1","value":220}},"05719c7d5f0a42c98fe580778910f35f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ee27f2c1b57348b68a5b340ba3c0ecac","placeholder":"​","style":"IPY_MODEL_dae8e96abf6943a8a4486853f53eadf6","value":" 220/220 [00:00&lt;00:00, 25.0kB/s]"}},"9489610210a44f369841b058e42fe7db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8876b6b590f64e37bdafcbb3d974b93e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"28c2d90277354d8f99282de952fc1fec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5d6fe94e3561419d94cfd5a3c18d8f4a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dca5fed3fb4d47b8bb3498ecf29157c1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ee27f2c1b57348b68a5b340ba3c0ecac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"dae8e96abf6943a8a4486853f53eadf6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c2104c9ae414e43a74792bf093897f6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e36e0b1fadd1465fbd31592d1d55db5f","IPY_MODEL_7bef92f52dec4020bc2d8c8da24343a8","IPY_MODEL_01a84f219a754a9a8e0ac98478c455a2"],"layout":"IPY_MODEL_29ff442fc0244f60a645ca375a0fabff"}},"e36e0b1fadd1465fbd31592d1d55db5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_25cd8356c6984327b790062aea4570db","placeholder":"​","style":"IPY_MODEL_938eff52d7864d149d7ea4e1e2314114","value":"README.md: "}},"7bef92f52dec4020bc2d8c8da24343a8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_523e8da5ee08462399304da6a646572b","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_dd1e8121bd5d4bf5816ad8fc53234a63","value":1}},"01a84f219a754a9a8e0ac98478c455a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a9bc39d52bd347d18db806b0dd39f87d","placeholder":"​","style":"IPY_MODEL_e9b1672d12f94d9389f3396da3789611","value":" 16.9k/? [00:00&lt;00:00, 800kB/s]"}},"29ff442fc0244f60a645ca375a0fabff":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"25cd8356c6984327b790062aea4570db":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"938eff52d7864d149d7ea4e1e2314114":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"523e8da5ee08462399304da6a646572b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"dd1e8121bd5d4bf5816ad8fc53234a63":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a9bc39d52bd347d18db806b0dd39f87d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e9b1672d12f94d9389f3396da3789611":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1f94f392b03348d5b7a3a90a90189e4b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_32293010d7584e29b5a1e435b186cdd4","IPY_MODEL_f1452aa82d4249ecb94f115ee28b3b09","IPY_MODEL_26544e38ad314aca8f19d5fe3280952c"],"layout":"IPY_MODEL_43b6225ff6fa48968885f4df7696a18c"}},"32293010d7584e29b5a1e435b186cdd4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1b0895cd63ff45c6a0620208ecf09708","placeholder":"​","style":"IPY_MODEL_e6021e8f633c4317b42e75de8b7b317f","value":"sentence_bert_config.json: 100%"}},"f1452aa82d4249ecb94f115ee28b3b09":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e47baab285dc44a1b6ded5239f7f0f46","max":54,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a7c443c9ee6e422d81b9f69bd4c33813","value":54}},"26544e38ad314aca8f19d5fe3280952c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9012ad287782499eb06c02b1df78ddaa","placeholder":"​","style":"IPY_MODEL_06aaf3bea78b4c1dbcdff1638d7a575f","value":" 54.0/54.0 [00:00&lt;00:00, 4.96kB/s]"}},"43b6225ff6fa48968885f4df7696a18c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b0895cd63ff45c6a0620208ecf09708":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6021e8f633c4317b42e75de8b7b317f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e47baab285dc44a1b6ded5239f7f0f46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7c443c9ee6e422d81b9f69bd4c33813":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9012ad287782499eb06c02b1df78ddaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"06aaf3bea78b4c1dbcdff1638d7a575f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"40d5ba05a6bf4fd3b99884b5ccb6856c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_45468b00689043a3b180d1811c2acd14","IPY_MODEL_f2af2e521d7c4443b65678d2627ec7f6","IPY_MODEL_98f64cf19bad4a079ebf6b30be869faf"],"layout":"IPY_MODEL_08323d56341e4243aaae38876d949fbe"}},"45468b00689043a3b180d1811c2acd14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_159b2be851a0483799e295585859fce7","placeholder":"​","style":"IPY_MODEL_6e4b12e8cf354aa2832b7e327c8fce64","value":"config.json: 100%"}},"f2af2e521d7c4443b65678d2627ec7f6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2aa593034f5f492aa1fc582f4281673e","max":807,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9465b61bf046416f8501e66ac68ebf3d","value":807}},"98f64cf19bad4a079ebf6b30be869faf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4539e3e971864d0fa1a645cb0fa9e35e","placeholder":"​","style":"IPY_MODEL_234edaf2fbe64afeadf7a79fa5b14c17","value":" 807/807 [00:00&lt;00:00, 52.2kB/s]"}},"08323d56341e4243aaae38876d949fbe":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"159b2be851a0483799e295585859fce7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6e4b12e8cf354aa2832b7e327c8fce64":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2aa593034f5f492aa1fc582f4281673e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9465b61bf046416f8501e66ac68ebf3d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4539e3e971864d0fa1a645cb0fa9e35e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"234edaf2fbe64afeadf7a79fa5b14c17":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"64b3ce222416479ebba44b7da990ed41":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_974f48d4a23d40db91fb90b26125f0e6","IPY_MODEL_5ed90f7f919943f784b33b0c98edfce9","IPY_MODEL_5fea0a53d3be4a8196bfb183eff05c54"],"layout":"IPY_MODEL_1dda127ccacc4978973994997f611e18"}},"974f48d4a23d40db91fb90b26125f0e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7edfaabb9462433186a40d00f97305d8","placeholder":"​","style":"IPY_MODEL_a9f8a2e922e1435b85b4148591d2a916","value":"model.safetensors: 100%"}},"5ed90f7f919943f784b33b0c98edfce9":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9d0cdc4f5ba451882861b67a6672f0d","max":2271064456,"min":0,"orientation":"horizontal","style":"IPY_MODEL_91bcaaa6a78c41e4952d2981e8c16d26","value":2271064456}},"5fea0a53d3be4a8196bfb183eff05c54":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad0ba95b4a8c4739a838fc1de8816786","placeholder":"​","style":"IPY_MODEL_72e875e631044c5b971331c40f134f38","value":" 2.27G/2.27G [00:15&lt;00:00, 69.4MB/s]"}},"1dda127ccacc4978973994997f611e18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7edfaabb9462433186a40d00f97305d8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a9f8a2e922e1435b85b4148591d2a916":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9d0cdc4f5ba451882861b67a6672f0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91bcaaa6a78c41e4952d2981e8c16d26":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"ad0ba95b4a8c4739a838fc1de8816786":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"72e875e631044c5b971331c40f134f38":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ccef6831aa864460b58e301e7fed1b13":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_650964019ff041c7a8994af4046fa2bc","IPY_MODEL_f588953a5f6d486193bd7acefb2420ef","IPY_MODEL_ab73a15a760842a0ab59edc899672bc7"],"layout":"IPY_MODEL_daaf6dd95f7d49d6af20157b15c3e08f"}},"650964019ff041c7a8994af4046fa2bc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_baab81ad3e2e43d2af1cd8a7aaa1f2e7","placeholder":"​","style":"IPY_MODEL_b10f547221354b668c3b3e81107c08e9","value":"tokenizer_config.json: "}},"f588953a5f6d486193bd7acefb2420ef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_97e7bf12318b4d8cbb8fcb9d5ceb9717","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_899fcb3a32d04f49b0551366d681398e","value":1}},"ab73a15a760842a0ab59edc899672bc7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8766434cc15e458eb50135fc409ff6dc","placeholder":"​","style":"IPY_MODEL_8de6f72206a9490fab043f6e39ddd95d","value":" 1.20k/? [00:00&lt;00:00, 99.1kB/s]"}},"daaf6dd95f7d49d6af20157b15c3e08f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baab81ad3e2e43d2af1cd8a7aaa1f2e7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b10f547221354b668c3b3e81107c08e9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"97e7bf12318b4d8cbb8fcb9d5ceb9717":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"899fcb3a32d04f49b0551366d681398e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8766434cc15e458eb50135fc409ff6dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8de6f72206a9490fab043f6e39ddd95d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e2c9fbc0836455db8143b579a14a15a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0fd1f015aef243869e4d129edc20677c","IPY_MODEL_5fb63c3b9f714c7fa31399bc331bd927","IPY_MODEL_7d4a156e4dfb4844bf65a0efbd47bd28"],"layout":"IPY_MODEL_d177f931d5214ac19227904921188833"}},"0fd1f015aef243869e4d129edc20677c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f43164966e8c4de79d968048118942b1","placeholder":"​","style":"IPY_MODEL_fa019c4272cd442692fbd14ea104ed2a","value":"tokenizer.json: 100%"}},"5fb63c3b9f714c7fa31399bc331bd927":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1826db5c1b704d2996055385e07a23dc","max":17083053,"min":0,"orientation":"horizontal","style":"IPY_MODEL_239dcc8bcf7b4a939e58ab32bfdb642f","value":17083053}},"7d4a156e4dfb4844bf65a0efbd47bd28":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c42c2e7fc5a64e56ae420ace48a4981c","placeholder":"​","style":"IPY_MODEL_998894630a8943e8b39ac902ccb0263c","value":" 17.1M/17.1M [00:00&lt;00:00, 109MB/s]"}},"d177f931d5214ac19227904921188833":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f43164966e8c4de79d968048118942b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa019c4272cd442692fbd14ea104ed2a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1826db5c1b704d2996055385e07a23dc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"239dcc8bcf7b4a939e58ab32bfdb642f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c42c2e7fc5a64e56ae420ace48a4981c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"998894630a8943e8b39ac902ccb0263c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"724bc2e8a3a34f6fbb10b3672c895d58":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e97c1ccc3dbc4db79864df6fca2cb8cc","IPY_MODEL_3f379e5730fd4302b78da00efcfce736","IPY_MODEL_2fb031909a3f486fbc294220bd2433f5"],"layout":"IPY_MODEL_689c03ad60714a309930c03e38a97965"}},"e97c1ccc3dbc4db79864df6fca2cb8cc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abfa239b95ef4156931841445fbd1270","placeholder":"​","style":"IPY_MODEL_8879bc040be4411f9412731a48d7ecc7","value":"special_tokens_map.json: 100%"}},"3f379e5730fd4302b78da00efcfce736":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_547c8e890c8b44aa9e7bf7fc3c0ae84b","max":964,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3cceb94973ff4bbbae9cd4201f1f4c0a","value":964}},"2fb031909a3f486fbc294220bd2433f5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a4421f6e1ce04c2d8612e79baab81a5c","placeholder":"​","style":"IPY_MODEL_f06811329263477baf4d3a845cb3d37c","value":" 964/964 [00:00&lt;00:00, 69.6kB/s]"}},"689c03ad60714a309930c03e38a97965":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"abfa239b95ef4156931841445fbd1270":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8879bc040be4411f9412731a48d7ecc7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"547c8e890c8b44aa9e7bf7fc3c0ae84b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3cceb94973ff4bbbae9cd4201f1f4c0a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"a4421f6e1ce04c2d8612e79baab81a5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f06811329263477baf4d3a845cb3d37c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cfe1ae6f39684430ac9c3097e7c6889b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_a1a81c05f1bb448e86267549f5724d10","IPY_MODEL_f92a6dd6a74748a4b188ff3f9e226935","IPY_MODEL_2a43654fdb4d4effa5bfbeb7204d62f3"],"layout":"IPY_MODEL_8e7aae2b39ca4090b9e4dc819b25dd3f"}},"a1a81c05f1bb448e86267549f5724d10":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d410fb28fbb443cc960d58410a068b9f","placeholder":"​","style":"IPY_MODEL_2276859db5d84bac971b14fa60015244","value":"config.json: 100%"}},"f92a6dd6a74748a4b188ff3f9e226935":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f6a950c843f44e4882b29b4406fd3e24","max":297,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f4dfbf4c9a0d470a9ab47532624d6b6c","value":297}},"2a43654fdb4d4effa5bfbeb7204d62f3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e58e2260db0a4c80a539779ef2365342","placeholder":"​","style":"IPY_MODEL_7dbe6553c7c144479689b61d110c96c2","value":" 297/297 [00:00&lt;00:00, 18.6kB/s]"}},"8e7aae2b39ca4090b9e4dc819b25dd3f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d410fb28fbb443cc960d58410a068b9f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2276859db5d84bac971b14fa60015244":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f6a950c843f44e4882b29b4406fd3e24":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4dfbf4c9a0d470a9ab47532624d6b6c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e58e2260db0a4c80a539779ef2365342":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7dbe6553c7c144479689b61d110c96c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["## 패키지 다운로드"],"metadata":{"id":"jIwLDV9XFq2Q"}},{"cell_type":"code","execution_count":2,"metadata":{"id":"d10ix0f2AAgp","executionInfo":{"status":"ok","timestamp":1751799127859,"user_tz":-540,"elapsed":10169,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"outputs":[],"source":["!pip install -qU langchain langchain-community langchain-google-genai langchain-huggingface langchain-chroma pdfplumber"]},{"cell_type":"code","source":["!pip list"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-Ew2yPU2CJg9","executionInfo":{"status":"ok","timestamp":1751799130592,"user_tz":-540,"elapsed":2731,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"989e666e-88e9-4e96-b5ad-7911d90999d5"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Package                                  Version\n","---------------------------------------- -------------------\n","absl-py                                  1.4.0\n","accelerate                               1.8.1\n","aiofiles                                 24.1.0\n","aiohappyeyeballs                         2.6.1\n","aiohttp                                  3.11.15\n","aiosignal                                1.3.2\n","alabaster                                1.0.0\n","albucore                                 0.0.24\n","albumentations                           2.0.8\n","ale-py                                   0.11.1\n","altair                                   5.5.0\n","annotated-types                          0.7.0\n","antlr4-python3-runtime                   4.9.3\n","anyio                                    4.9.0\n","argon2-cffi                              25.1.0\n","argon2-cffi-bindings                     21.2.0\n","array_record                             0.7.2\n","arviz                                    0.21.0\n","astropy                                  7.1.0\n","astropy-iers-data                        0.2025.6.30.0.39.40\n","astunparse                               1.6.3\n","atpublic                                 5.1\n","attrs                                    25.3.0\n","audioread                                3.0.1\n","autograd                                 1.8.0\n","babel                                    2.17.0\n","backcall                                 0.2.0\n","backoff                                  2.2.1\n","backports.tarfile                        1.2.0\n","bcrypt                                   4.3.0\n","beautifulsoup4                           4.13.4\n","betterproto                              2.0.0b6\n","bigframes                                2.8.0\n","bigquery-magics                          0.9.0\n","bleach                                   6.2.0\n","blinker                                  1.9.0\n","blis                                     1.3.0\n","blobfile                                 3.0.0\n","blosc2                                   3.5.0\n","bokeh                                    3.7.3\n","Bottleneck                               1.4.2\n","bqplot                                   0.12.45\n","branca                                   0.8.1\n","build                                    1.2.2.post1\n","CacheControl                             0.14.3\n","cachetools                               5.5.2\n","catalogue                                2.0.10\n","certifi                                  2025.6.15\n","cffi                                     1.17.1\n","chardet                                  5.2.0\n","charset-normalizer                       3.4.2\n","chex                                     0.1.89\n","chromadb                                 1.0.15\n","clarabel                                 0.11.1\n","click                                    8.2.1\n","cloudpathlib                             0.21.1\n","cloudpickle                              3.1.1\n","cmake                                    3.31.6\n","cmdstanpy                                1.2.5\n","colorcet                                 3.1.0\n","coloredlogs                              15.0.1\n","colorlover                               0.3.0\n","colour                                   0.1.5\n","community                                1.0.0b1\n","confection                               0.1.5\n","cons                                     0.4.6\n","contourpy                                1.3.2\n","cramjam                                  2.10.0\n","cryptography                             43.0.3\n","cuda-python                              12.6.2.post1\n","cudf-cu12                                25.2.1\n","cudf-polars-cu12                         25.2.2\n","cufflinks                                0.17.3\n","cuml-cu12                                25.2.1\n","cupy-cuda12x                             13.3.0\n","curl_cffi                                0.11.4\n","cuvs-cu12                                25.2.1\n","cvxopt                                   1.3.2\n","cvxpy                                    1.6.6\n","cycler                                   0.12.1\n","cyipopt                                  1.5.0\n","cymem                                    2.0.11\n","Cython                                   3.0.12\n","dask                                     2024.12.1\n","dask-cuda                                25.2.0\n","dask-cudf-cu12                           25.2.2\n","dask-expr                                1.1.21\n","dataclasses-json                         0.6.7\n","dataproc-spark-connect                   0.7.5\n","datascience                              0.17.6\n","datasets                                 2.14.4\n","db-dtypes                                1.4.3\n","dbus-python                              1.2.18\n","debugpy                                  1.8.0\n","decorator                                4.4.2\n","defusedxml                               0.7.1\n","diffusers                                0.34.0\n","dill                                     0.3.7\n","distributed                              2024.12.1\n","distributed-ucxx-cu12                    0.42.0\n","distro                                   1.9.0\n","dlib                                     19.24.6\n","dm-tree                                  0.1.9\n","docstring_parser                         0.16\n","docutils                                 0.21.2\n","dopamine_rl                              4.1.2\n","duckdb                                   1.2.2\n","durationpy                               0.10\n","earthengine-api                          1.5.22\n","easydict                                 1.13\n","editdistance                             0.8.1\n","eerepr                                   0.1.2\n","einops                                   0.8.1\n","en_core_web_sm                           3.8.0\n","entrypoints                              0.4\n","et_xmlfile                               2.0.0\n","etils                                    1.12.2\n","etuples                                  0.3.9\n","Farama-Notifications                     0.0.4\n","fastai                                   2.7.19\n","fastapi                                  0.115.14\n","fastcore                                 1.7.29\n","fastdownload                             0.0.7\n","fastjsonschema                           2.21.1\n","fastprogress                             1.0.3\n","fastrlock                                0.8.3\n","ffmpy                                    0.6.0\n","filelock                                 3.18.0\n","filetype                                 1.2.0\n","firebase-admin                           6.9.0\n","Flask                                    3.1.1\n","flatbuffers                              25.2.10\n","flax                                     0.10.6\n","folium                                   0.19.7\n","fonttools                                4.58.4\n","frozendict                               2.4.6\n","frozenlist                               1.7.0\n","fsspec                                   2025.3.2\n","future                                   1.0.0\n","gast                                     0.6.0\n","gcsfs                                    2025.3.2\n","GDAL                                     3.8.4\n","gdown                                    5.2.0\n","geemap                                   0.35.3\n","geocoder                                 1.38.1\n","geographiclib                            2.0\n","geopandas                                1.0.1\n","geopy                                    2.4.1\n","gin-config                               0.5.0\n","gitdb                                    4.0.12\n","GitPython                                3.1.44\n","glob2                                    0.7\n","google                                   2.0.3\n","google-ai-generativelanguage             0.6.18\n","google-api-core                          2.25.1\n","google-api-python-client                 2.174.0\n","google-auth                              2.38.0\n","google-auth-httplib2                     0.2.0\n","google-auth-oauthlib                     1.2.2\n","google-cloud-aiplatform                  1.100.0\n","google-cloud-bigquery                    3.34.0\n","google-cloud-bigquery-connection         1.18.3\n","google-cloud-bigquery-storage            2.32.0\n","google-cloud-core                        2.4.3\n","google-cloud-dataproc                    5.20.0\n","google-cloud-datastore                   2.21.0\n","google-cloud-firestore                   2.21.0\n","google-cloud-functions                   1.20.4\n","google-cloud-iam                         2.19.1\n","google-cloud-language                    2.17.2\n","google-cloud-resource-manager            1.14.2\n","google-cloud-spanner                     3.55.0\n","google-cloud-storage                     2.19.0\n","google-cloud-translate                   3.21.0\n","google-colab                             1.0.0\n","google-crc32c                            1.7.1\n","google-genai                             1.23.0\n","google-generativeai                      0.8.5\n","google-pasta                             0.2.0\n","google-resumable-media                   2.7.2\n","googleapis-common-protos                 1.70.0\n","googledrivedownloader                    1.1.0\n","gradio                                   5.31.0\n","gradio_client                            1.10.1\n","graphviz                                 0.21\n","greenlet                                 3.2.3\n","groovy                                   0.1.2\n","grpc-google-iam-v1                       0.14.2\n","grpc-interceptor                         0.15.4\n","grpcio                                   1.73.1\n","grpcio-status                            1.71.2\n","grpclib                                  0.4.8\n","gspread                                  6.2.1\n","gspread-dataframe                        4.0.0\n","gym                                      0.25.2\n","gym-notices                              0.0.8\n","gymnasium                                1.2.0\n","h11                                      0.16.0\n","h2                                       4.2.0\n","h5netcdf                                 1.6.3\n","h5py                                     3.14.0\n","hdbscan                                  0.8.40\n","hf_transfer                              0.1.9\n","hf-xet                                   1.1.5\n","highspy                                  1.11.0\n","holidays                                 0.75\n","holoviews                                1.21.0\n","hpack                                    4.1.0\n","html5lib                                 1.1\n","httpcore                                 1.0.9\n","httpimport                               1.4.1\n","httplib2                                 0.22.0\n","httptools                                0.6.4\n","httpx                                    0.28.1\n","httpx-sse                                0.4.1\n","huggingface-hub                          0.33.1\n","humanfriendly                            10.0\n","humanize                                 4.12.3\n","hyperframe                               6.1.0\n","hyperopt                                 0.2.7\n","ibis-framework                           9.5.0\n","idna                                     3.10\n","imageio                                  2.37.0\n","imageio-ffmpeg                           0.6.0\n","imagesize                                1.4.1\n","imbalanced-learn                         0.13.0\n","immutabledict                            4.2.1\n","importlib_metadata                       8.7.0\n","importlib_resources                      6.5.2\n","imutils                                  0.5.4\n","inflect                                  7.5.0\n","iniconfig                                2.1.0\n","intel-cmplr-lib-ur                       2025.2.0\n","intel-openmp                             2025.2.0\n","ipyevents                                2.0.2\n","ipyfilechooser                           0.6.0\n","ipykernel                                6.17.1\n","ipyleaflet                               0.20.0\n","ipyparallel                              8.8.0\n","ipython                                  7.34.0\n","ipython-genutils                         0.2.0\n","ipython-sql                              0.5.0\n","ipytree                                  0.2.2\n","ipywidgets                               7.7.1\n","itsdangerous                             2.2.0\n","jaraco.classes                           3.4.0\n","jaraco.context                           6.0.1\n","jaraco.functools                         4.2.1\n","jax                                      0.5.2\n","jax-cuda12-pjrt                          0.5.1\n","jax-cuda12-plugin                        0.5.1\n","jaxlib                                   0.5.1\n","jeepney                                  0.9.0\n","jieba                                    0.42.1\n","Jinja2                                   3.1.6\n","jiter                                    0.10.0\n","joblib                                   1.5.1\n","jsonpatch                                1.33\n","jsonpickle                               4.1.1\n","jsonpointer                              3.0.0\n","jsonschema                               4.24.0\n","jsonschema-specifications                2025.4.1\n","jupyter-client                           6.1.12\n","jupyter-console                          6.1.0\n","jupyter_core                             5.8.1\n","jupyter_kernel_gateway                   2.5.2\n","jupyter-leaflet                          0.20.0\n","jupyter-server                           1.16.0\n","jupyterlab_pygments                      0.3.0\n","jupyterlab_widgets                       3.0.15\n","jupytext                                 1.17.2\n","kaggle                                   1.7.4.5\n","kagglehub                                0.3.12\n","keras                                    3.8.0\n","keras-hub                                0.18.1\n","keras-nlp                                0.18.1\n","keyring                                  25.6.0\n","keyrings.google-artifactregistry-auth    1.1.2\n","kiwisolver                               1.4.8\n","kubernetes                               33.1.0\n","langchain                                0.3.26\n","langchain-chroma                         0.2.4\n","langchain-community                      0.3.27\n","langchain-core                           0.3.67\n","langchain-google-genai                   2.1.6\n","langchain-huggingface                    0.3.0\n","langchain-text-splitters                 0.3.8\n","langcodes                                3.5.0\n","langsmith                                0.4.4\n","language_data                            1.3.0\n","launchpadlib                             1.10.16\n","lazr.restfulclient                       0.14.4\n","lazr.uri                                 1.0.6\n","lazy_loader                              0.4\n","libclang                                 18.1.1\n","libcudf-cu12                             25.2.1\n","libcugraph-cu12                          25.2.0\n","libcuml-cu12                             25.2.1\n","libcuvs-cu12                             25.2.1\n","libkvikio-cu12                           25.2.1\n","libpysal                                 4.13.0\n","libraft-cu12                             25.2.0\n","librosa                                  0.11.0\n","libucx-cu12                              1.18.1\n","libucxx-cu12                             0.42.0\n","lightgbm                                 4.5.0\n","linkify-it-py                            2.0.3\n","llvmlite                                 0.43.0\n","locket                                   1.0.0\n","logical-unification                      0.4.6\n","lxml                                     5.4.0\n","Mako                                     1.1.3\n","marisa-trie                              1.2.1\n","Markdown                                 3.8.2\n","markdown-it-py                           3.0.0\n","MarkupSafe                               3.0.2\n","marshmallow                              3.26.1\n","matplotlib                               3.10.0\n","matplotlib-inline                        0.1.7\n","matplotlib-venn                          1.1.2\n","mdit-py-plugins                          0.4.2\n","mdurl                                    0.1.2\n","miniKanren                               1.0.3\n","missingno                                0.5.2\n","mistune                                  3.1.3\n","mizani                                   0.13.5\n","mkl                                      2025.0.1\n","ml-dtypes                                0.4.1\n","mlxtend                                  0.23.4\n","mmh3                                     5.1.0\n","more-itertools                           10.7.0\n","moviepy                                  1.0.3\n","mpmath                                   1.3.0\n","msgpack                                  1.1.1\n","multidict                                6.6.3\n","multipledispatch                         1.0.0\n","multiprocess                             0.70.15\n","multitasking                             0.0.11\n","murmurhash                               1.0.13\n","music21                                  9.3.0\n","mypy_extensions                          1.1.0\n","namex                                    0.1.0\n","narwhals                                 1.45.0\n","natsort                                  8.4.0\n","nbclassic                                1.3.1\n","nbclient                                 0.10.2\n","nbconvert                                7.16.6\n","nbformat                                 5.10.4\n","ndindex                                  1.10.0\n","nest-asyncio                             1.6.0\n","networkx                                 3.5\n","nibabel                                  5.3.2\n","nltk                                     3.9.1\n","notebook                                 6.5.7\n","notebook_shim                            0.2.4\n","numba                                    0.60.0\n","numba-cuda                               0.2.0\n","numexpr                                  2.11.0\n","numpy                                    2.0.2\n","nvidia-cublas-cu12                       12.5.3.2\n","nvidia-cuda-cupti-cu12                   12.5.82\n","nvidia-cuda-nvcc-cu12                    12.5.82\n","nvidia-cuda-nvrtc-cu12                   12.5.82\n","nvidia-cuda-runtime-cu12                 12.5.82\n","nvidia-cudnn-cu12                        9.3.0.75\n","nvidia-cufft-cu12                        11.2.3.61\n","nvidia-curand-cu12                       10.3.6.82\n","nvidia-cusolver-cu12                     11.6.3.83\n","nvidia-cusparse-cu12                     12.5.1.3\n","nvidia-cusparselt-cu12                   0.6.2\n","nvidia-ml-py                             12.575.51\n","nvidia-nccl-cu12                         2.21.5\n","nvidia-nvcomp-cu12                       4.2.0.11\n","nvidia-nvjitlink-cu12                    12.5.82\n","nvidia-nvtx-cu12                         12.4.127\n","nvtx                                     0.2.12\n","nx-cugraph-cu12                          25.2.0\n","oauth2client                             4.1.3\n","oauthlib                                 3.3.1\n","omegaconf                                2.3.0\n","onnxruntime                              1.22.0\n","openai                                   1.93.0\n","opencv-contrib-python                    4.11.0.86\n","opencv-python                            4.11.0.86\n","opencv-python-headless                   4.11.0.86\n","openpyxl                                 3.1.5\n","opentelemetry-api                        1.34.1\n","opentelemetry-exporter-otlp-proto-common 1.34.1\n","opentelemetry-exporter-otlp-proto-grpc   1.34.1\n","opentelemetry-proto                      1.34.1\n","opentelemetry-sdk                        1.34.1\n","opentelemetry-semantic-conventions       0.55b1\n","opt_einsum                               3.4.0\n","optax                                    0.2.5\n","optree                                   0.16.0\n","orbax-checkpoint                         0.11.16\n","orjson                                   3.10.18\n","osqp                                     1.0.4\n","overrides                                7.7.0\n","packaging                                24.2\n","pandas                                   2.2.2\n","pandas-datareader                        0.10.0\n","pandas-gbq                               0.29.1\n","pandas-stubs                             2.2.2.240909\n","pandocfilters                            1.5.1\n","panel                                    1.7.2\n","param                                    2.2.1\n","parso                                    0.8.4\n","parsy                                    2.1\n","partd                                    1.4.2\n","pathlib                                  1.0.1\n","patsy                                    1.0.1\n","pdfminer.six                             20250506\n","pdfplumber                               0.11.7\n","peewee                                   3.18.1\n","peft                                     0.15.2\n","pexpect                                  4.9.0\n","pickleshare                              0.7.5\n","pillow                                   11.2.1\n","pip                                      24.1.2\n","platformdirs                             4.3.8\n","plotly                                   5.24.1\n","plotnine                                 0.14.6\n","pluggy                                   1.6.0\n","ply                                      3.11\n","polars                                   1.21.0\n","pooch                                    1.8.2\n","portpicker                               1.5.2\n","posthog                                  5.4.0\n","preshed                                  3.0.10\n","prettytable                              3.16.0\n","proglog                                  0.1.12\n","progressbar2                             4.5.0\n","prometheus_client                        0.22.1\n","promise                                  2.3\n","prompt_toolkit                           3.0.51\n","propcache                                0.3.2\n","prophet                                  1.1.7\n","proto-plus                               1.26.1\n","protobuf                                 5.29.5\n","psutil                                   5.9.5\n","psycopg2                                 2.9.10\n","ptyprocess                               0.7.0\n","py-cpuinfo                               9.0.0\n","py4j                                     0.10.9.7\n","pyarrow                                  18.1.0\n","pyasn1                                   0.6.1\n","pyasn1_modules                           0.4.2\n","pybase64                                 1.4.1\n","pycairo                                  1.28.0\n","pycocotools                              2.0.10\n","pycparser                                2.22\n","pycryptodomex                            3.23.0\n","pydantic                                 2.11.7\n","pydantic_core                            2.33.2\n","pydantic-settings                        2.10.1\n","pydata-google-auth                       1.9.1\n","pydot                                    3.0.4\n","pydotplus                                2.0.2\n","PyDrive                                  1.3.1\n","PyDrive2                                 1.21.3\n","pydub                                    0.25.1\n","pyerfa                                   2.0.1.5\n","pygame                                   2.6.1\n","pygit2                                   1.18.0\n","Pygments                                 2.19.2\n","PyGObject                                3.42.0\n","PyJWT                                    2.10.1\n","pylibcudf-cu12                           25.2.1\n","pylibcugraph-cu12                        25.2.0\n","pylibraft-cu12                           25.2.0\n","pymc                                     5.23.0\n","pymystem3                                0.2.0\n","pynndescent                              0.5.13\n","pynvjitlink-cu12                         0.7.0\n","pynvml                                   12.0.0\n","pyogrio                                  0.11.0\n","pyomo                                    6.9.2\n","PyOpenGL                                 3.1.9\n","pyOpenSSL                                24.2.1\n","pyparsing                                3.2.3\n","pypdfium2                                4.30.1\n","pyperclip                                1.9.0\n","PyPika                                   0.48.9\n","pyproj                                   3.7.1\n","pyproject_hooks                          1.2.0\n","pyshp                                    2.3.1\n","PySocks                                  1.7.1\n","pyspark                                  3.5.1\n","pytensor                                 2.31.5\n","pytest                                   8.3.5\n","python-apt                               0.0.0\n","python-box                               7.3.2\n","python-dateutil                          2.9.0.post0\n","python-dotenv                            1.1.1\n","python-louvain                           0.16\n","python-multipart                         0.0.20\n","python-slugify                           8.0.4\n","python-snappy                            0.7.3\n","python-utils                             3.9.1\n","pytz                                     2025.2\n","pyviz_comms                              3.0.6\n","PyWavelets                               1.8.0\n","PyYAML                                   6.0.2\n","pyzmq                                    24.0.1\n","raft-dask-cu12                           25.2.0\n","rapids-dask-dependency                   25.2.0\n","ratelim                                  0.1.6\n","referencing                              0.36.2\n","regex                                    2024.11.6\n","requests                                 2.32.3\n","requests-oauthlib                        2.0.0\n","requests-toolbelt                        1.0.0\n","requirements-parser                      0.9.0\n","rich                                     13.9.4\n","rmm-cu12                                 25.2.0\n","roman-numerals-py                        3.1.0\n","rpds-py                                  0.26.0\n","rpy2                                     3.5.17\n","rsa                                      4.9.1\n","ruff                                     0.12.1\n","safehttpx                                0.1.6\n","safetensors                              0.5.3\n","scikit-image                             0.25.2\n","scikit-learn                             1.6.1\n","scipy                                    1.15.3\n","scooby                                   0.10.1\n","scs                                      3.2.7.post2\n","seaborn                                  0.13.2\n","SecretStorage                            3.3.3\n","semantic-version                         2.10.0\n","Send2Trash                               1.8.3\n","sentence-transformers                    4.1.0\n","sentencepiece                            0.2.0\n","sentry-sdk                               2.32.0\n","setproctitle                             1.3.6\n","setuptools                               75.2.0\n","shap                                     0.48.0\n","shapely                                  2.1.1\n","shellingham                              1.5.4\n","simple-parsing                           0.1.7\n","simplejson                               3.20.1\n","simsimd                                  6.4.9\n","six                                      1.17.0\n","sklearn-compat                           0.1.3\n","sklearn-pandas                           2.2.0\n","slicer                                   0.0.8\n","smart_open                               7.3.0\n","smmap                                    5.0.2\n","sniffio                                  1.3.1\n","snowballstemmer                          3.0.1\n","sortedcontainers                         2.4.0\n","soundfile                                0.13.1\n","soupsieve                                2.7\n","soxr                                     0.5.0.post1\n","spacy                                    3.8.7\n","spacy-legacy                             3.0.12\n","spacy-loggers                            1.0.5\n","spanner-graph-notebook                   1.1.7\n","Sphinx                                   8.2.3\n","sphinxcontrib-applehelp                  2.0.0\n","sphinxcontrib-devhelp                    2.0.0\n","sphinxcontrib-htmlhelp                   2.1.0\n","sphinxcontrib-jsmath                     1.0.1\n","sphinxcontrib-qthelp                     2.0.0\n","sphinxcontrib-serializinghtml            2.0.0\n","SQLAlchemy                               2.0.41\n","sqlglot                                  25.20.2\n","sqlparse                                 0.5.3\n","srsly                                    2.5.1\n","stanio                                   0.5.1\n","starlette                                0.46.2\n","statsmodels                              0.14.4\n","stringzilla                              3.12.5\n","stumpy                                   1.13.0\n","sympy                                    1.13.1\n","tables                                   3.10.2\n","tabulate                                 0.9.0\n","tbb                                      2022.2.0\n","tblib                                    3.1.0\n","tcmlib                                   1.4.0\n","tenacity                                 8.5.0\n","tensorboard                              2.18.0\n","tensorboard-data-server                  0.7.2\n","tensorflow                               2.18.0\n","tensorflow-datasets                      4.9.9\n","tensorflow_decision_forests              1.11.0\n","tensorflow-hub                           0.16.1\n","tensorflow-io-gcs-filesystem             0.37.1\n","tensorflow-metadata                      1.17.2\n","tensorflow-probability                   0.25.0\n","tensorflow-text                          2.18.1\n","tensorstore                              0.1.74\n","termcolor                                3.1.0\n","terminado                                0.18.1\n","text-unidecode                           1.3\n","textblob                                 0.19.0\n","tf_keras                                 2.18.0\n","tf-slim                                  1.1.0\n","thinc                                    8.3.6\n","threadpoolctl                            3.6.0\n","tifffile                                 2025.6.11\n","tiktoken                                 0.9.0\n","timm                                     1.0.16\n","tinycss2                                 1.4.0\n","tokenizers                               0.21.2\n","toml                                     0.10.2\n","tomlkit                                  0.13.3\n","toolz                                    0.12.1\n","torch                                    2.6.0+cu124\n","torchao                                  0.10.0\n","torchaudio                               2.6.0+cu124\n","torchdata                                0.11.0\n","torchsummary                             1.5.1\n","torchtune                                0.6.1\n","torchvision                              0.21.0+cu124\n","tornado                                  6.4.2\n","tqdm                                     4.67.1\n","traitlets                                5.7.1\n","traittypes                               0.2.1\n","transformers                             4.53.0\n","treelite                                 4.4.1\n","treescope                                0.1.9\n","triton                                   3.2.0\n","tsfresh                                  0.21.0\n","tweepy                                   4.15.0\n","typeguard                                4.4.4\n","typer                                    0.16.0\n","types-pytz                               2025.2.0.20250516\n","types-setuptools                         80.9.0.20250529\n","typing_extensions                        4.14.0\n","typing-inspect                           0.9.0\n","typing-inspection                        0.4.1\n","tzdata                                   2025.2\n","tzlocal                                  5.3.1\n","uc-micro-py                              1.0.3\n","ucx-py-cu12                              0.42.0\n","ucxx-cu12                                0.42.0\n","umap-learn                               0.5.8\n","umf                                      0.11.0\n","uritemplate                              4.2.0\n","urllib3                                  2.4.0\n","uvicorn                                  0.35.0\n","uvloop                                   0.21.0\n","vega-datasets                            0.9.0\n","wadllib                                  1.3.6\n","wandb                                    0.20.1\n","wasabi                                   1.1.3\n","watchfiles                               1.1.0\n","wcwidth                                  0.2.13\n","weasel                                   0.4.1\n","webcolors                                24.11.1\n","webencodings                             0.5.1\n","websocket-client                         1.8.0\n","websockets                               15.0.1\n","Werkzeug                                 3.1.3\n","wheel                                    0.45.1\n","widgetsnbextension                       3.6.10\n","wordcloud                                1.9.4\n","wrapt                                    1.17.2\n","wurlitzer                                3.1.1\n","xarray                                   2025.3.1\n","xarray-einstats                          0.9.1\n","xgboost                                  2.1.4\n","xlrd                                     2.0.2\n","xxhash                                   3.5.0\n","xyzservices                              2025.4.0\n","yarl                                     1.20.1\n","ydf                                      0.12.0\n","yellowbrick                              1.5\n","yfinance                                 0.2.64\n","zict                                     3.0.0\n","zipp                                     3.23.0\n","zstandard                                0.23.0\n"]}]},{"cell_type":"markdown","source":["## 구글 드라이브 연결"],"metadata":{"id":"GQklFlSAFthI"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m7rjxmA8FT7t","executionInfo":{"status":"ok","timestamp":1751799151651,"user_tz":-540,"elapsed":21050,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"c3ac530a-eec9-46d7-d9f9-5e83b44f91b6"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import os\n","\n","os.getcwd()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"TrFOsmHdI56Y","executionInfo":{"status":"ok","timestamp":1751799154797,"user_tz":-540,"elapsed":16,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"c8ac4293-70b8-46e6-d198-3966bf6c3e5f"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["os.listdir()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2piW2XghJYSA","executionInfo":{"status":"ok","timestamp":1751799155485,"user_tz":-540,"elapsed":24,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"409d1779-ff41-4191-aeb3-d68a59732e9a"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['.config', 'drive', 'sample_data']"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["%pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"KYtxtzuqGUnf","executionInfo":{"status":"ok","timestamp":1751799156116,"user_tz":-540,"elapsed":3,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"e11e3e69-e037-4e45-fb6f-a4b2becb9b7d"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["%cd drive/MyDrive/250707/corpus"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XFlvhbv-JbMl","executionInfo":{"status":"ok","timestamp":1751799157908,"user_tz":-540,"elapsed":1118,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"4cd9fe16-12bf-4f1d-f81f-198e7b7c804f"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/250707/corpus\n"]}]},{"cell_type":"markdown","source":["## 모듈화 아닌 버전"],"metadata":{"id":"-mmARD6XFLm4"}},{"cell_type":"markdown","source":["### Langsmith 를 이용한 응답 추적"],"metadata":{"id":"oO1FmGLJbnre"}},{"cell_type":"code","source":["from google.colab import userdata\n","import os\n","\n","os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GOOGLE_API_KEY')\n","os.environ[\"LANGCHAIN_TRACING\"] = userdata.get('LANGSMITH_TRACING')\n","os.environ[\"LANGCHAIN_ENDPOINT\"] = userdata.get('LANGSMITH_ENDPOINT')\n","os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGSMITH_API_KEY')\n","os.environ[\"LANGCHAIN_PROJECT\"] = userdata.get('LANGSMITH_PROJECT')"],"metadata":{"id":"CuctB6Eyb6Ii","executionInfo":{"status":"ok","timestamp":1751799170193,"user_tz":-540,"elapsed":2036,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["### 질의응답 시스템에 사용할 문서 읽기"],"metadata":{"id":"msATlMQ5KV6H"}},{"cell_type":"code","source":["from langchain_community.document_loaders import PDFPlumberLoader\n","\n","docs = PDFPlumberLoader(\"거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf\").load()"],"metadata":{"id":"znNEqfazFOxn","executionInfo":{"status":"ok","timestamp":1751799186307,"user_tz":-540,"elapsed":12801,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["print(docs)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NiXqVbVXLfWf","executionInfo":{"status":"ok","timestamp":1751799186560,"user_tz":-540,"elapsed":250,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"ca54ba4c-2d17-4805-966e-c2204e6d8089"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["[Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 0, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='공 학 석 사 학 위 논 문\\n거대언어모델(LLM) 기반 질의응답\\n시스템의 표 데이터 이해도를\\n높이는 전처리 기법\\n지 도 교 수 박 유 현\\n공 동 지 도 교 수 이 정 훈\\n2025년 2월\\n동 의 대 학 교 대 학 원\\n컴 퓨 터 소 프 트 웨 어 공 학 과\\n정 민 수\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 1, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='공 학 석 사 학 위 논 문\\n거대언어모델(LLM) 기반 질의응답\\n시스템의 표 데이터 이해도를\\n높이는 전처리 기법\\n지 도 교 수 박 유 현\\n공 동 지 도 교 수 이 정 훈\\n이 논문을 공학 석사학위논문으로 제출함\\n2024년 12월\\n동 의 대 학 교 대 학 원\\n컴 퓨 터 소 프 트 웨 어 공 학 과\\n정 민 수\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 2, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 3, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='거대언어모델(LLM) 기반 질의응답 시스템의\\n표 데이터 이해도를 높이는 전처리 기법\\n정 민 수\\n동의대학교 대학원 컴퓨터소프트웨어공학과\\n요 약\\n거대언어모델(Large Language Model, LLM)은 자연어와 같은 비정형 데\\n이터 처리에서 높은 성능을 보이지만, 표와 같은 정형화된 데이터 처리에서\\n는 성능이 저하되는 문제가 있다. 표 데이터는 개별 셀의 값만으로는 의미\\n를 충분히 파악하기 어려우며, 표 전체의 맥락에서 행과 열의 관계를 해석\\n해야 정확한 이해가 가능하다. 본 논문에서는 거대언어모델의 표 데이터 처\\n리 성능을 높이기 위한 새로운 접근법으로, 표 데이터를 자연어로 변환하는\\n전처리 기법을 제안한다. 첫 번째로, 구분자 기반 전처리 기법은 속성의 깊\\n이에 따라 구분자를 사용하고, 중첩된 속성을 괄호로 묶어 계층 구조를 표\\n현한다. 두 번째로, 한국어 조사 체계 기반 전처리 기법은 표 제목에 부사격\\n조사 \"~에서\"를 사용하고, 속성에 주격 조사 \"~은\"을, 셀 값에 서술격 조사\\n\"~이다\"를 붙여 자연어 문장으로 전환한다.\\n이러한 전처리 기법으로 구축된 말뭉치를 활용하여 검색 증강 생성 기반의\\n질의응답 시스템을 구현하였으며, GPT 4o mini와 Gemma 2 it 9B 거대언\\n어모델을 사용하여 실험을 진행하였다. 평가 데이터셋으로는 표 데이터에 대\\n한 100개의 질문-응답 쌍을 사용하였고, 청크 크기와 오버랩 크기를 다양하\\n게 조정하여 성능 변화를 분석하였다. 응답 성능 평가는 BLEU, ROUGE,\\nMETEOR, Sem Score, GPT Score, 그리고 G-Eval 지표를 사용하였다.\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 4, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='실험 결과, 전처리를 적용하지 않은 JSON 형식의 표 데이터보다 제안한\\n두 가지 전처리 기법을 적용한 경우가 더 높은 성능을 보인다. 특히, 한국어\\n조사 체계 기반 전처리 기법은 모든 평가 지표에서 우수한 성능을 나타냈으\\n며, 청크와 오버랩 크기의 변화에도 강건한 결과를 보인다. 이는 거대언어모\\n델이 자연어 형태로 전처리 된 데이터를 처리할 때 더 효율적임을 시사한다.\\n따라서, 한국어 조사 체계 기반 전처리 기법을 적용한 말뭉치를 질의응답\\n에 활용하면, 검색 증강 생성 질의응답 시스템에서 높은 성능을 유지하면서\\n도 초매개변수 조정에 대한 민감도를 줄일 수 있을 것으로 판단된다. 향후\\n연구에서는 이 전처리 기법을 고도화하여 상황에 적합하고 자연스러운 한국\\n어 문장을 생성하고, 다양한 조사의 활용을 통해 거대언어모델의 성능을 더\\n욱 높일 계획이다.\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 5, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='목 차\\n1. 서론 ··························································································································1\\n1.1 연구 배경··········································································································1\\n1.2 논문 구성··········································································································2\\n2. 관련 연구 ···············································································································3\\n2.1 검색 증강 생성(Retrieval-Augmented Generation)·····························3\\n2.2 표 질의응답(Table QA) 연구······································································4\\n2.3 언어모델 응답 평가 지표··············································································5\\n2.3.1 BLEU(Bilingual Evaluation Understudy)········································5\\n2.3.2 ROUGE(Recall-Oriented Understudy for Gisting Evaluation)····5\\n2.3.3 METEOR(Metric for Evaluation of Translation with Explicit ORdering)··6\\n2.3.4 Sem Score·······························································································6\\n2.3.5 GPT Score, G-Eval··············································································6\\n2.3.6 LLM-as-a-Judge···················································································7\\n2.4 선행 연구··········································································································7\\n2.4.1 표 데이터 전처리 기법···········································································7\\n2.4.2 검색 증강 생성 질의응답 시스템·························································7\\n2.4.3 검색기 실험·······························································································7\\n2.4.4 한국어 형태소 분석기 성능 실험 연구···············································8\\n2.4.5 응답 성능 평가 연구···············································································8\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 6, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='2.4.6 초매개변수 조합 도출 실험···································································9\\n2.4.7 선행 연구와 연관성·················································································9\\n3. 표 데이터 변환 방법론····················································································10\\n3.1 배경··················································································································10\\n3.2 표 유형 분류 방법························································································11\\n3.3 표 데이터 변환 방법론················································································12\\n3.3.1 데이터 상세 정보··················································································12\\n3.3.2 표 속성 깊이 기반 변환 방법····························································13\\n4. 표 데이터 전처리 기법····················································································15\\n4.1 구분자 기반 전처리 기법············································································15\\n4.1.1 전처리 기법 개요 및 절차··································································15\\n4.1.2 기법 적용 결과······················································································16\\n4.1.3 한계점······································································································16\\n4.2 한국어 조사 체계 기반 전처리 기법························································17\\n4.2.1 전처리 기법 개요 및 절차··································································17\\n4.2.2 기법 적용 결과······················································································18\\n4.2.3 문제점······································································································18\\n5. 질의응답 시스템 구축 ······················································································19\\n5.1 시스템 동작 과정··························································································19\\n5.2 시스템 구현····································································································20\\n5.2.1 개발 환경································································································20\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 7, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='5.2.2 시스템 상세 내용··················································································21\\n6. 실험 ·······················································································································23\\n6.1 질의응답 평가 데이터··················································································23\\n6.2 질의응답 정확도 성능 평가 지표······························································23\\n6.2.1 BLEU, ROUGE, METEOR·································································23\\n6.2.2 Sem Score·····························································································23\\n6.2.3 GPT Score + G-Eval········································································24\\n6.3 실험 결과 및 분석························································································28\\n6.3.1 BLEU·······································································································28\\n6.3.2 METEOR·································································································30\\n6.3.3 ROUGE····································································································32\\n6.3.4 Sem Score·····························································································38\\n6.3.5 GPT Score + G-Eval········································································40\\n6.3.6 실험 결과 분석······················································································58\\n7. 결론 및 향후 연구 ····························································································62\\n8. 부록 ·······················································································································64\\n9. 참고문헌 ···············································································································66\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 8, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='표 목차\\n<표 5.1> 시스템 개발 환경 및 버전··································································21\\n<표 6.1> GPT Score 21개 평가 측면 원본····················································24\\n<표 6.2> 표 질의응답 평가 측면········································································26\\n<표 6.3> GPT 4o mini - 전처리기법적용여부에따른평균응답성능증감률······58\\n<표 6.4> Gemma 2 it 9B - 전처리기법적용여부에따른평균응답성능증감률·········60\\n<표 A> 평가 프롬프트 예시·················································································64\\n<표 B> 평가 출력 형식 유도 프롬프트 예시····················································65\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 9, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='그림 목차\\n<그림 3.1> 표유형분류 ························································································11\\n<그림 3.2> 표 속성 최대 깊이 기반 분류 예시 ···················································11\\n<그림 3.3> 2024학년도 동의대학교 정시 입시 모집 요강 문서 ···················12\\n<그림 3.4> 표 속성 최대 깊이가 1일 때, JSON 변환 방법론·····················13\\n<그림 3.5> 표 속성 최대 깊이가 2일 때, JSON 변환 방법론·····················14\\n<그림 3.6> 표 속성 최대 깊이가 3일 때, JSON 변환 방법론·····················14\\n<그림 4.1> 표 데이터 변환 방법론 및 구분자 기반 전처리 기법 예시 ··15\\n<그림 4.2> 구분자 기반 전처리 기법 적용 결과············································16\\n<그림 4.3> 한국어 조사 체계 기반 전처리 기법 적용 결과 ······················18\\n<그림 5.1> 검색 증강 생성 기반의 질의응답 시스템 구조도······················19\\n<그림 5.2> 시스템 프롬프트················································································22\\n<그림 6.1> GPT Score + G-Eval 평가 프로토콜········································27\\n<그림 6.2> GPT 4o mini BLEU Score···························································28\\n<그림 6.3> Gemma BLEU Score······································································29\\n<그림 6.4> GPT 4o mini METEOR Score·····················································30\\n<그림 6.5> Gemma METEOR Score································································31\\n<그림 6.6> GPT 4o mini ROUGE-1 Score···················································32\\n<그림 6.7> GPT 4o mini ROUGE-2 Score···················································33\\n<그림 6.8> GPT 4o mini ROUGE-L Score···················································34\\n<그림 6.9> Gemma ROUGE-1 Score······························································35\\n<그림 6.10> Gemma ROUGE-2 Score····························································36\\n<그림 6.11> Gemma ROUGE-L Score···························································37\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 10, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 6.12> GPT 4o mini Sem Score····························································38\\n<그림 6.13> Gemma SEM Score······································································39\\n<그림 6.14> GPT 4o mini GPT Score + G-Eval - Factuality·············40\\n<그림 6.15> GPT 4o mini GPT Score + G-Eval - Consistency········41\\n<그림 6.16> GPT 4o mini GPT Score + G-Eval - Relevance············42\\n<그림 6.17> GPT 4o mini GPT Score + G-Eval - Fluency················43\\n<그림 6.18> GPT 4o mini GPT Score + G-Eval - Coherence···········44\\n<그림 6.19> GPT 4o mini GPT Score + G-Eval - Accuracy··············45\\n<그림 6.20> GPT 4o mini GPT Score + G-Eval – Multidimensional Quality····46\\n<그림 6.21> GPT 4o mini GPT Score + G-Eval – Semantic Appropriateness· 47\\n<그림 6.22> GPT 4o mini GPT Score + G-Eval - Understandability····48\\n<그림 6.23> Gemma GPT Score + G-Eval - Factuality························49\\n<그림 6.24> Gemma GPT Score + G-Eval - Consistency···················50\\n<그림 6.25> Gemma GPT Score + G-Eval - Relevance·······················51\\n<그림 6.26> Gemma GPT Score + G-Eval - Fluency···························52\\n<그림 6.27> Gemma GPT Score + G-Eval - Coherence······················53\\n<그림 6.28> Gemma GPT Score + G-Eval - Accuracy·························54\\n<그림 6.29> Gemma GPT Score + G-Eval – Multidimensional Quality····55\\n<그림 6.30> Gemma GPT Score + G-Eval – Semantic Appropriateness···56\\n<그림 6.31> Gemma GPT Score + G-Eval - Understandability·········57\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 11, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='1. 서론\\n1.1 연구 배경\\n최근 몇 년간 거대언어모델(Large Language Model, LLM)의 급속한 발\\n전은 자연어 처리(Natural Language Processing, NLP) 분야에 큰 진전을\\n가져왔다. 거대언어모델은 비정형 데이터를 처리할 때 우수한 성능을 보이\\n며, 사용자의 질의를 이해하고 그에 맞는 응답을 생성하는 데 특화되어 있\\n다[1-4]. 하지만 실제 업무에서는 비정형 데이터뿐만 아니라 표(Table) 형\\n태의 정형 데이터도 중요한 비중을 차지한다.\\n업무 문서에서 정형 데이터의 대표적 예시인 표는 행과 열의 구조를 통해\\n정보를 효율적으로 압축하고 체계적으로 관리할 수 있다는 장점이 있다. 표\\n형식을 사용하면 데이터가 구조화되어 있기 때문에, 사용자 입장에서 쉽게\\n이해하고 분석하기에 용이하다. 이러한 이유로 통계 분석이나 정보 요약이\\n필요한 다양한 문서에서 표가 적극 활용된다. 그러나 표는 개별 셀 단위의\\n값만으로 전체적 의미를 파악하기 어려우며, 표 전체의 맥락에서 행과 열의\\n관계를 종합적으로 해석해야만 정확한 정보를 추출할 수 있다[5-6]. 하지만\\nGPT[7], Llama[8], Gemma[9], Qwen[10], Mistral[11], Phi[12] 등 주\\n요 거대언어모델은 주로 비정형 텍스트 데이터에 초점을 맞추어 학습되었기\\n때문에, 속성과 개별 셀 단위의 값으로 구조적인 형태를 가진 표를 다루는\\n데에는 상대적으로 낮은 성능을 보인다. 그런데도 실제 업무 환경에서도 중\\n요한 통계나 요약된 정보를 담고 있는 표를 기반으로 질의응답을 수행해야\\n하는 사례가 많다. 이러한 환경에서 표 데이터를 정밀하게 처리하는 능력은\\n실무에 필수적이나, 거대언어모델은 주로 비정형 텍스트를 중심으로 학습되\\n어 있어 구조적인 정보가 필요한 표 기반 질의응답에 그대로 적용하기에는\\n한계가 분명하다[13]. 따라서 거대언어모델의 표 데이터 처리 성능을 높이\\n기 위한 새로운 접근 방식이 요구된다.\\n더불어 거대언어모델에는 공통적인 문제점들이 존재한다. 첫째, 정보 접\\n근 제한이다. 학습 시점 이후에 생성된 최신 정보를 즉각적으로 반영하지\\n못하기 때문에, 새로운 정보나 최근 변화와 관련된 질의에 대해 정확한 답\\n- 1 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 12, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='변을 제공하기 어렵다. 둘째, 입출력 토큰 길이 제한으로 인해 긴 문맥을 처\\n리하는 데 어려움이 있다. 셋째, 잘못된 정보나 허구의 내용을 사실처럼 응\\n답하는 작화(Confabulation) 또는 환각(Hallucination) 현상이 발생할 수 있\\n으며, 이는 사용자 신뢰를 저해할 위험 요인으로 지적된다[14-16].\\n이러한 문제점을 해결하기 위한 방안으로 검색 증강 생성(Retrieval-Augmented\\nGeneration)[17] 시스템이 최근 주목받고 있다. 검색 증강 생성 시스템은\\n거대언어모델과 정보 검색 기술을 결합하여 최신 정보를 반영하고 긴 문맥\\n을 처리하는 한편, 작화와 환각 현상을 완화할 방법을 제공한다.\\n그러나 작화와 환각 현상이 완전히 해소되지 않는 이상, 거대언어모델이\\n생성한 응답을 평가 및 검증하는 작업은 필수적이다. 이를 위해 거대언어모\\n델의 응답 정확도를 자동으로 측정하거나, 품질을 평가하는 다양한 기법이\\n연구되고 있다. 가장 확실한 평가는 인간 전문가가 직접 수행하는 방법이지\\n만, 시간과 비용이 많이 드는 한계가 따른다. 이러한 이유로 효율적인 평가\\n방법의 필요성이 부각되고 있으며, 최근에는 인간 평가자의 역할을 거대언어\\n모델에 부여해 거대언어모델 자체를 활용한 자동 평가를 수행하는 자동 평가\\n방법이 주목받고 있다[18].\\n본 논문은 거대언어모델의 표 데이터 처리 성능을 높이기 위한 전처리 기\\n법에 초점을 맞추고자 한다. 표 데이터를 거대언어모델이 잘 처리할 수 있는\\n자연어 형태로 변환하는 전처리 기법을 제안하며, 변환된 말뭉치와 원본 표\\n데이터를 JSON 형식으로 제공하는 말뭉치 두 가지를 활용하여 거대언어모델\\n기반의 질의응답 시스템에서의 질의응답 정확도 성능을 다양한 평가 지표로\\n비교 분석하고자 한다. 이를 통해 표 데이터 전처리가 거대언어모델의 질의응\\n답 성능 향상에 어떠한 영향을 미치는지를 실험 결과를 통해 다루고자 한다.\\n1.2 논문 구성\\n본 논문에서는 거대언어모델 기반 질의응답 시스템의 표 데이터 이해도를\\n높이는 전처리 기법을 제안한다. 이를 위해 2장에서 관련 연구를 검토하고,\\n3장에서 표 데이터 전처리 방법론을 설명한다. 4장과 5장에서는 각각 표 데\\n이터 전처리 기법과 검색 증강 생성 기반 질의응답 시스템을 소개한다. 6장\\n에서는 다양한 평가 방식을 활용하여 거대언어모델이 생성한 응답과 참조 응답\\n의 성능을 평가하며, 마지막으로 7장에서 결론 및 향후 연구 방향을 제시한다.\\n- 2 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 13, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='2. 관련 연구\\n2.1 검색 증강 생성(Retrieval-Augmented Generation)[17]\\n검색 증강 생성은 거대언어모델과 정보 검색 기술을 결합한 구조이다. 검\\n색 증강 생성은 사전 학습된 언어모델이 보유한 내재적 지식과 외부 데이터\\n베이스나 문서에서 실시간으로 검색한 정보를 결합하여 정확하고 신뢰성 있\\n는 결과를 생성하도록 한다. 최근에는 검색 증강 생성을 통해 거대언어모델\\n의 공통적인 문제인 정보 접근 제한, 입출력 토큰 제한, 그리고 작화 및 환\\n각 현상을 개선하기 위해 주목받고 있으며 문제점 개선 방법은 다음과 같다.\\n첫 번째로, 정보 접근 제한 문제는 거대언어모델이 학습한 시점 이후에\\n발생한 정보에 대해 정확한 응답을 생성하지 못하는 현상을 의미한다. 이\\n문제를 해결하기 위해, 검색 증강 생성 방식에서는 사용자가 질의응답에 필\\n요한 문서를 업로드하여 수치화한 후 벡터저장소에 저장한다. 거대언어모델\\n은 사용자의 질문에 대한 응답을 생성할 때, 이 저장된 벡터 데이터를 참조\\n함으로써 최신 정보에 대한 접근성을 확보할 수 있다.\\n두 번째로, 입출력 토큰 제한 문제는 거대언어모델마다 최대 입출력 토큰\\n길이에 제한이 있기 때문에 발생한다. 입력 토큰의 길이가 너무 길어지면,\\n생성할 수 있는 응답 토큰이 한정되어 충분한 정보를 제공하지 못하는 경우\\n가 발생할 수 있다. 이러한 문제를 완화하기 위해, 검색 증강 생성 기반의\\n질의응답 시스템은 문서를 특정 청크 및 오버랩 크기로 분할하고, 사용자의\\n질문과 유사도가 높은 상위 k개의 문서만을 선택하여 응답을 생성하도록 한\\n다. 이를 통해 거대언어모델의 토큰 제한 문제를 개선할 수 있다.\\n마지막으로, 작화 또는 환각 현상은 거대언어모델이 실제와 다른 허구의\\n정보를 마치 사실인 것처럼 응답을 생성하여 사용자에게 잘못된 정보를 제\\n공하는 문제이다. 이를 개선하기 위해, 검색 증강 생성 기반 질의응답 시스\\n템에서는 거대언어모델이 질문과 높은 유사도를 가진 문서의 내용을 기반으\\n로만 응답을 생성하도록 유도한다. 또한, 거대언어모델이 제공받지 않은 정\\n보에 관한 질문에 대해서는 불확실한 응답을 피하고 \"정보 없음\"과 같은 명\\n확한 응답을 제공하도록 시스템 프롬프트를 설계하여, 응답의 신뢰성을 높\\n- 3 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 14, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content=\"인다. 더불어, 잘못된 응답이 생성될 때 사용자가 참조한 문서에 접근하여\\n사실 여부를 빠르게 검증할 수 있도록, 응답 생성 시 참조한 문서의 출처\\n정보를 함께 제공함으로써 이러한 문제점을 개선할 수 있다.\\n2.2 표 질의응답(Table QA) 연구\\n표 데이터는 대표적인 구조화된 데이터로, 이를 활용한 질의응답(Table\\nQA) 분야에서 활발한 연구가 이루어지고 있다. 이러한 연구는 주로 표에 담\\n긴 정보를 기반으로 질의응답을 수행하거나, 표를 텍스트 문서의 한 형태로\\n간주하여 기계독해를 수행하는 방향으로 진행되고 있다[19-21]. 최근에는\\n언어모델의 표 질의응답 성능을 높이기 위한 전처리 기법, 표 요약 기법 등\\n다양한 접근법이 제안되고 있다.\\n표 질의응답에서 전처리는 표의 구조와 언어모델 간의 간극을 줄이는 핵\\n심 요소로 작용한다. 해당 연구로는 특정 셀에 대한 설명 생성을 목표로 칸\\n위치 인식, 행 정보 인식, 열 정보 인식, 표 구조 재배열 등 네 가지 하위\\n태스크를 설계하고, 각 태스크를 위한 합성 데이터셋을 구축하여 언어모델\\n이 표 구조를 명확하게 인식하도록 설계한 연구가 있다[23]. 이러한 접근법\\n은 표 구조를 명시적으로 언어모델에 제공함으로써 높은 정확도를 기대할\\n수 있다는 장점이 있다.\\n표 요약 기법에 관한 연구에서는 특정 셀을 중심으로 표 데이터를 키-값\\n쌍의 사전 형태로 전처리한 후, 해당 데이터 유형에 적합한 분석을 수행하\\n도록 유도하는 프롬프트와 '기자 페르소나(persona)'를 언어모델에 부여하여\\n요약 문장을 생성하는 파이프라인이 제안되었다. 이 연구는 주제어를 부사\\n구로, 설명을 서술절로 구성하여 명확하고 구조화된 요약 문장을 생성하는\\n연구이다[22].\\n이러한 연구 이외에도 복잡한 표 데이터의 추론을 위해 Chain-of-Thought\\n기법을 확장한 Chain-of-Table이라는 표 특화 프레임워크도 제안되었다. 이\\n프레임워크는 표 내 데이터를 정렬, 추출, 삭제하여 필요한 정보만 남긴 후 이\\n를 표 형태로 통합함으로써 결과 도출 과정을 단순화하는 연구가 적용된 프레\\n임워크이다[24, 25].\\n- 4 -\\n\"), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 15, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='기존 표 질의응답에 관한 연구를 분석 결과, 대부분의 연구는 키-값 쌍으\\n로 이루어진 JSON 형태의 표 데이터를 사용하며, 언어모델에 칸의 위치, 행\\n정보, 열 정보 등을 명시적으로 제공해 표 인식률을 높이는 방식을 채택한\\n다. 그러나 이러한 접근법은 복잡한 표 구조를 정확히 반영하지 못할 경우\\n성능 저하가 발생할 수 있다. 또한 언어모델이 정형화된 데이터에 대해 낮\\n은 성능을 보이기 때문에, 표 구조에 대한 정보를 제공하더라도 질의응답\\n과정에서 근본적인 문제가 해결되지 않을 가능성이 있다.\\n본 논문의 연구 내용은 기존 표 질의응답 연구 범주 중에서 전처리 기법\\n에 속하며, 거대언어모델이 낮은 성능을 보이는 표 데이터를 높은 성능을\\n보이는 자연어로 변환하여 말뭉치를 구축하는 전처리 기법을 제안한다.\\n2.3 언어모델 응답 평가 지표\\n2.3.1 BLEU(Bilingual Evaluation Understudy)[27]\\nBLEU는 기계 번역 및 자연어 생성 모델의 성능을 평가하는 데 널리 사용\\n되는 대표적인 자동 평가 지표이다. BLEU는 모델이 생성한 문장과 인간이 작\\n성한 참조 문장 간의 n-gram 일치를 기반으로 정확도를 평가한다. 일반적으\\n로 1-gram부터 4-gram까지의 n-gram을 사용하여 단어 선택뿐만 아니라 구\\n문 구조까지 평가하며, 이를 통해 생성된 텍스트의 문맥적 일치도를 판단한다.\\n그러나 BLEU에는 몇 가지 한계가 있는데, 대표적으로 의미를 고려하지 않고\\n단순 문자열 일치만 확인하며, 단어의 중요도를 구분하지 않는다는 점이다.\\n2.3.2 ROUGE(Recall-Oriented Understudy for Gisting Evaluation)[26]\\nROUGE는 자동 요약 및 기계번역의 품질을 평가하는 데 사용되는 대표적인\\n평가 지표이다. ROUGE는 언어모델이 생성한 응답과 참조 응답(reference)\\n간의 겹치는 단어, n-gram, 또는 문장 구조를 기반으로 품질을 평가한다.\\nROUGE 지표에는 여러 변형이 있으며, 그 중 ROUGE-1, ROUGE-2,\\nROUGE-L이 주로 사용된다. ROUGE-1은 단어 단위의 유사도를 평가하는\\n지표로, 두 텍스트 간의 단어 일치를 평가한다. ROUGE-2는 n-gram 단위에\\n서 문맥 정보를 반영하여 두 텍스트 간의 짧은 구문 일치를 평가하는 데 사\\n용된다. ROUGE-L은 최장 공통부분 문자열(Longest Common\\n- 5 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 16, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='Subsequence, LCS)을 기반으로 유사도를 평가하며, 단순한 n-gram 기반\\n지표와 달리 문장 수준에서 단어 순서를 고려하여 더 긴 구문 또는 문장 구\\n조의 일치를 평가할 수 있다.\\n2.3.3 METEOR(Metric for Evaluation of Translation with Explicit ORdering)[28]\\nMETEOR는 기계 번역 및 자연어 생성 모델의 성능을 평가하기 위한 자\\n동 평가 지표로, BLEU의 한계를 보완하기 위해 개발되었다. METEOR는\\n단어의 일치뿐만 아니라 어근화, 동의어 매핑, 그리고 단어 순서 등을 고려\\n하여 평가를 수행한다. 이를 통해 단순한 표면적 단어 일치에 의존하는\\nBLEU와 달리, 의미적 유사도를 더 정확하게 반영할 수 있다.\\n2.3.4 Sem Score[29]\\nSem Score는 거대언어모델의 성능을 자동으로 평가하기 위해 개발된 평\\n가 지표이다. 이 지표는 거대언어모델이 생성한 응답과 참조 응답 간의 의\\n미적 유사도를 측정하여 평가한다. 의미적 유사도를 평가할 때는 사전 학습\\n된 언어모델을 사용하여 생성된 응답과 참조 응답을 임베딩 한 다음 코사인\\n유사도를 통해 두 벡터 사이의 의미적 유사도를 계산함으로써 단순한 단어\\n일치가 아닌 문장의 의미적 일치를 자동으로 평가할 수 있다.\\n2.3.5 GPT Score[30], G-Eval[31]\\nGPT Score는 GPT 계열 거대언어모델을 활용하여, 언어모델이 생성한\\n응답을 자동으로 평가하기 위한 지표로, 최근 자연어 처리 분야에서 주목받\\n고 있다. 이 지표는 높은 성능을 보이는 거대언어모델의 자연어 이해 및 평\\n가 능력을 활용하여, 생성된 응답과 참조 응답 간의 의미적 유사도와 품질\\n을 정량적으로 평가한다. 이를 통해 의미, 문법적 정확성, 일관성, 유창성\\n등의 다양한 측면에서 종합적인 평가가 가능하다.\\nG-Eval도 GPT Score와 동일하게 GPT 계열의 거대언어모델을 활용하여 생성\\n된 응답을 평가하는 자동 평가 방법이다. 두 방법 모두 평가 기준에 따라 적절한\\n프롬프트를 GPT 모델에 제공하여 평가 작업을 수행하도록 지시함으로써, 응답을\\n다차원적으로 평가할 수 있다. 이를 통해 기존 평가 방식인 BLEU, ROUGE,\\nMETEOR, 그리고 Sem Score보다 더 정교한 자연어 처리 평가가 가능하다.\\n- 6 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 17, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='2.3.6 LLM-as-a-Judge[32]\\nLLM-as-a-Judge는 거대언어모델을 평가자로 활용하여 언어모델이 생성한\\n응답 중 어느 것이 더 나은지를 결정하거나 동점을 선언하는 방법이다. 또한,\\n단일 응답에 대해 거대언어모델이 직접 점수를 부여하거나, 특정 경우 적용\\n가능한 참조 응답을 제공하여 참조 기반 평가를 수행하도록 할 수 있다. 이\\n방법은 평가 방식을 프롬프트로 작성하여 거대언어모델에 전달함으로써 판사\\n역할을 수행하게 하여, 생성된 응답들의 품질을 비교 평가하는 방식이다.\\n2.4 선행 연구\\n2.4.1 표 데이터 전처리 기법[13]\\n선행 연구에서는 거대언어모델이 비정형 데이터에 비해 정형화된 표 데이\\n터 처리에서 성능이 저하되는 문제를 해결하기 위해 표 속성 깊이 기반 전\\n처리 기법을 제안하였다. 이 전처리 기법은 표 데이터의 속성 깊이에 따라\\n표 구조를 자연어로 변환하여 거대언어모델이 표 구조를 잘 인식할 수 있도\\n록 한다. 그러나 이 전처리 기법은 속성 깊이가 깊어질수록 새로운 함수를\\n구현해야 한다는 일반화의 한계를 가지고 있다. 본 논문에서는 이 기법을\\n구분자 기반 전처리 기법으로 명명한다.\\n2.4.2 검색 증강 생성 질의응답 시스템[14]\\n선행 연구는 표 데이터 기반 문서인 동의대학교 2024학년도 정시 모집\\n요강 및 입시 결과 문서를 활용하여 검색 증강 생성 질의응답 시스템을 구\\n축하고, 해당 문서를 HTML 형식으로 전처리하여 GPT-3.5-Turbo 모델에\\n미세조정한 Dudu와 질의응답 정확도 성능을 비교 실험하였다. 실험 결과 검\\n색 증강 생성 기반 질의응답 시스템이 60% 더 높은 응답 정확도를 보였다.\\n2.4.3 검색기 실험[33, 34]\\n선행 연구[33]는 질의응답 시스템의 성능을 높이기 위해 밀집 검색기(Dense\\nRetriever)와 희소 검색기(Sparse Retriever)를 단일 검색기로 사용했을 때와\\n밀집 검색기와 희소 검색기를 결합한 앙상블 검색기의 성능을 비교하였다. 실험\\n결과, 앙상블 검색기가 단일 검색기보다 높은 성능을 보이는 것으로 나타났다.\\n- 7 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 18, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='선행 연구[34]는 일반적으로 앙상블 검색기의 희소 검색기로 BM25 검색\\n기가 사용되는데, BM25의 한계점을 보완하고자 개발된 BM42와 표 데이터\\n기반의 검색 증강 생성 시스템에서 성능을 비교 실험한 연구이다. 실험 결\\n과, BM25가 BM42보다 약 8% 높은 성능을 보였다.\\n2.4.4 한국어 형태소 분석기 성능 실험 연구[35]\\n한국어는 굴절어이며, 한 단어 내에서도 여러 형태소가 결합하여 다양한\\n의미와 문법적 기능을 나타내기 때문에 형태소 분석기를 사용하는 것이 필\\n수적이다. 이러한 이유로 다양한 한국어 형태소 분석기를 표 데이터 기반의\\n검색 증강 생성 질의응답 시스템에 적용하여, 형태소 분석기의 성능을 비교\\n한 연구이다. 이 연구에서는 띄어쓰기 단위로 문장을 분리하는 기본 BM25\\n검색기와 한국어 형태소 분석기인 Kiwi, Kkma, Okt, Komoran,\\nHannanum, Mecab을 각각 BM25에 결합하여 성능을 비교하였다. 실험 결\\n과, Okt 형태소 분석기를 사용했을 때 가장 우수한 성능을 보였다.\\n2.4.5 응답 성능 평가 연구[36]\\n해당 연구에서는 거대언어모델 기반의 질의응답 시스템에서 발생하는 대\\n표적인 문제점인 거짓 정보를 사실인 것처럼 생성하는 환각 및 작화 현상으\\n로 인해, 거대언어모델이 생성한 응답을 검증하는 작업이 중요하다는 점에\\n서 시작된 연구이다. 이를 위해 해당 연구에서는 거대언어모델이 생성한 응\\n답을 자동으로 평가할 수 있는 GPT Score를 적용하여, 기존에 코사인 유\\n사도를 통해 평가하던 방식과 비교하였다. 실험은 GPT Score에서 제공하\\n는 21개의 평가 측면 중, 표 데이터 기반의 질의응답 시스템 응답 평가에\\n필수적이라 판단되는 9개의 측면만 사용하였으며, 문장의 흥미나 매력도를\\n평가하는 항목은 부가적인 요소라 판단하여 제외하였다. 실험 결과, 코사인\\n유사도 기반 평가에서는 응답의 유사도는 높게 평가되었으나, 실제로는 오\\n답인 경우가 다수 존재했다. 반면, GPT Score를 활용한 평가 방법을 적용\\n했을 때 이러한 문제점이 개선되는 결과를 보였다.\\n- 8 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 19, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='2.4.6 초매개변수 조합 도출 실험[37]\\n검색 증강 생성 기반 질의응답 시스템에서 표 데이터 인식 성능을 높이기\\n위한 최적의 초매개변수 조합을 도출하는 데 초점을 맞추었다. 이 연구에서\\n는 OpenAI의 GPT 3.5, 야놀자의 EEVE, Google의 Gemini 1.5 Pro, 마음\\nAI의 Llama 3 MAAL 8B 등 네 가지 거대언어모델을 사용하여 청크와 오\\n버랩 크기를 조정하며 최적의 성능을 나타내는 조합을 찾았다. 실험 결과,\\n거대언어모델마다 최적의 초매개변수 조합이 다른 결과를 보였다.\\n2.4.7 선행 연구와 연관성\\n앞서 소개한 모든 선행 연구는 표 데이터 기반 검색 증강 생성 시스템에\\n서 질의응답 정확도를 높이는 데 집중해 왔다. 본 논문에서는 선행 연구에\\n서 제안한 구분자 기반 전처리 기법의 한계를 극복하고, 거대언어모델의 표\\n기반 질의응답 정확도를 높이기 위한 새로운 전처리 기법을 제안한다. 구체\\n적으로는 표 데이터를 한국어 조사 체계를 활용해 완전한 자연어 문장으로\\n변환함으로써 말뭉치를 구축하는 전처리 기법을 소개하며, 이를 \"한국어 조\\n사 체계 기반 전처리 기법\"으로 명명한다.\\n본 연구에서는 전처리 기법이 적용되지 않은 말뭉치, 구분자 기반 전처리\\n기법이 적용된 말뭉치, 그리고 한국어 조사 체계 기반 전처리 기법이 적용\\n된 말뭉치를 각각 검색 증강 생성 질의응답 시스템에서 다양한 평가 지표를\\n통해 평가한다. 이 시스템은 선행 연구의 실험 결과를 토대로 가장 높은 성\\n능을 보인 설정을 적용하고, 사용자 질문과 유사도가 높은 문서를 찾기 위\\n해 밀집 검색기와 희소 검색기를 결합한 앙상블 검색기를 사용한다. 밀집\\n검색기는 벡터저장소 기반 검색기를 사용하고, 희소 검색기로는 BM25 검색\\n기에 Okt 형태소 분석기를 결합해 사용한다.\\n- 9 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 20, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='3. 표 데이터 변환 방법론\\n3.1 배경\\n서론에서 언급한 바와 같이, 거대언어모델은 비정형 데이터로 학습되어 있\\n어 자연어로 구성된 비정형 데이터에 대해서는 높은 성능을 보이지만, 구조\\n적인 정보를 포함한 표 형태의 데이터에 대해서는 성능이 현저히 떨어진다.\\n본 논문에서는 거대언어모델의 낮은 표 데이터 기반 질의응답 정확도 성\\n능을 개선하기 위해, 본 장에서 표 데이터 변환 방법론을 제시한다. 이어 4\\n장에서는 이 방법론에 기반하여 자연어 형태로 전처리를 수행하는 구분자 기\\n반 전처리 기법과 한국어 조사 체계 기반 전처리 기법을 상세히 설명한다.\\n먼저 본 장에서 소개하는 표 데이터 변환 방법론은 다양한 형태의 표 유\\n형을 분류한 뒤, 표 구조와 값을 일관된 JSON 형식으로 변환하는 절차를\\n제공한다. JSON 형식을 도입하는 이유는, JSON이 최근 표 데이터 배포에\\n널리 활용되는 형식이기 때문이다. 예를 들어, 국립국어원의 \"언어 정보 나\\n눔터[38]\"에서 배포하는 데이터나 구글의 표 기반 문장 생성 데이터\\nToTTO[39] 등을 참고하여, \"2022년 유사 문장 생성 말뭉치 연구 및 구축\"\\n사업을 통해 HTML 형식의 표 구조를 유지하면서 JSON으로 변환한 한국어\\n데이터셋 KoToTTo가 구축된 사례가 있다. 또한 LG AI Research에서 공\\n개한 KorWikiTableQuestions[40] 데이터 역시 한국어로 이루어진 140만\\n개의 표와 이 표들을 대상으로 한 7만 개의 질의응답 쌍을 JSON 형식으로\\n제공하고 있다. 이러한 사례들에서 드러나듯, 표 데이터를 JSON으로 변환해\\n배포하는 방식이 사용되고 있으므로, 본 논문에서도 표 데이터를 JSON 형\\n식으로 변환하는 방식을 채택한다.\\n- 10 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 21, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='3.2 표 유형 분류 방법\\n(a) (b) (c)\\n<그림 3.1> 표 유형 분류\\n(a) 가로 고정형 (b) 세로 고정형 (c) 가로 및 세로 고정형\\n본 논문에서는 그림 3.1과 같이 문서에서 사용되는 표 유형을 크게 세 가\\n지로 분류한다. 첫 번째 유형인 (a)는 표의 속성이 가로 방향으로 고정된 경\\n우로, 가로 속성에 따라 특정 셀의 값을 기반으로 표를 해석할 수 있다. 두\\n번째 유형인 (b)는 표의 속성이 세로 방향으로 고정된 경우로, 세로 속성을\\n통해 특정 셀의 값을 해석할 수 있다. 마지막으로, 세 번째 유형인 (c)는 가\\n로와 세로 양쪽에 속성이 고정된 경우로, (a)와 (b) 유형과 달리 두 방향의\\n속성 모두를 고려해야 특정 셀의 값을 기반으로 표를 해석할 수 있는 복잡\\n한 구조를 지닌다. (a)와 (b) 유형은 가장 일반적인 형태로, 가로 또는 세로\\n방향의 고정된 속성을 통해 쉽게 해석할 수 있으며, 전처리 시에도 동일한\\n방식으로 처리할 수 있다. 반면, (c) 유형은 가로와 세로 속성을 모두 유지\\n해야 하는 복잡한 구조이므로 (a)와 (b) 유형과는 다른 전처리 방식이 필요\\n하다. 따라서 본 논문에서는 (a)와 (b) 유형의 일반적인 표를 대상으로 한\\n전처리 방법론을 제안한다. (c) 유형에 대한 처리는 향후 연구에서 다룰 예\\n정이며, 본 연구에서는 우선 일반적인 형태의 표에 초점을 맞춘다.\\n(a) (b) (c)\\n<그림 3.2> 표 속성 최대 깊이 기반 분류 예시\\n(a) 표 속성 최대 깊이 1 (b) 표 속성 최대 깊이 2 (c) 표 속성 최대 깊이 3\\n- 11 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 22, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='표는 실제 문서에서 주로 그림 3.2와 같이 속성 내에 하위 속성으로 분할\\n된 형태로 표현한다. 본 논문에서는 이러한 구조를 표 속성 최대 깊이라고 명\\n명하며, 속성의 계층 구조에 따라 최대 깊이를 측정한다. 예를 들어, (a) 유형\\n은 표 속성 깊이가 1인 경우, (b) 유형은 깊이가 2인 경우, (c) 유형은 깊이가\\n3인 경우에 해당한다. 표 속성의 깊이는 필요에 따라 무한히 늘어날 수 있다.\\n3.3 표 데이터 변환 방법론\\n3.3.1 데이터 상세 정보\\n특정 문서에서 표 데이터를 추출하여 JSON 형식으로 변환하고 이를 데이터\\n셋으로 구축한다. 본 논문에서 사용한 문서는 선행 연구에서 사용한 동의대학\\n교의 2024학년도 정시 입시 모집 요강과 입시 결과 문서로, 총 75개의 표로\\n구성되어 있다. 각 표는 평균적으로 3.84개의 속성과 6.76개의 행을 포함한다.\\n(a)\\n(b)\\n(c)\\n<그림 3.3> 2024학년도 동의대학교 정시 입시 모집 요강 문서\\n(a) 표 속성 최대 깊이 1 (b) 표 속성 최대 깊이 2 (c) 표 속성 최대 깊이 3\\n- 12 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 23, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='그림 3.3은 본 논문에서 사용하는 문서 내 표의 일부를 3.2절에서 소개한\\n표 유형 분류 방법을 통해 분류했을 때 예시다. 가장 단순한 형태인 표 속\\n성 최대 깊이 1의 경우는 (a), 표 속성 최대 깊이가 2인 경우는 (b), 그리고\\n표 속성 최대 깊이가 3인 경우는 (c)이다.\\n3.3.2 표 속성 깊이 기반 변환 방법\\n본 논문에서 제안하는 방법론은 표 데이터를 JSON 형식으로 변환하여 1차\\n전처리 작업을 수행하는 것이다. 이때, 일관된 JSON 형식을 유지하기 위해\\n그림 3.4, 3.5, 3.6과 같이 표 속성 깊이에 따라 JSON 형식으로 표현한다.\\n표 데이터를 JSON 형식으로 전처리하는 방식은 다음과 같다. 표 제목을\\n최상위 키(Key)로 설정하고, 그 값(Value)은 리스트 형식으로 선언한다. 리\\n스트 내부에는 각 열(Row)을 나타내는 사전(Dictionary) 형식의 항목들이\\n포함된다. 각 열의 상세 내용은 표 속성 이름을 키로, 해당 셀의 값을 그 키\\n에 해당하는 값으로 작성한다. 예를 들어, 그림 3.4는 표 속성 깊이가 1인\\n경우를, 그림 3.5는 깊이가 2인 경우를, 그림 3.6은 깊이가 3인 경우를 나\\n타낸다. 표 속성 깊이가 증가할수록, JSON 구조 내에서 해당 속성에 대해\\n중첩된 사전 형식으로 표현하여 복잡한 구조를 유연하게 반영할 수 있다.\\n<그림 3.4> 표 속성 최대 깊이가 1일 때, JSON 변환 방법론\\n- 13 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 24, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 3.5> 표 속성 최대 깊이가 2일 때, JSON 변환 방법론\\n<그림 3.6> 표 속성 최대 깊이가 3일 때, JSON 변환 방법론\\n- 14 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 25, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content=\"4. 표 데이터 전처리 기법\\n4.1 구분자 기반 전처리 기법\\n4.1.1 전처리 기법 개요 및 절차\\n구분자 기반 전처리 기법은 3장에서 소개한 표 데이터를 JSON 형식으로\\n변환하는 표 데이터 변환 방법론에 기반하여, 표 속성 깊이에 따라 구분자\\n기호를 사용해 표의 구조를 거대언어모델이 높은 성능을 보이는 자연어 텍\\n스트로 표현한다. 표 속성 깊이가 1인 단순한 구조에서는 각 속성을 '/'로\\n구분해 나열한다. 표 속성 깊이가 2인 경우, 중첩된 하위 속성을 중괄호로\\n묶고 각 속성과 계층을 '/'로 구분한다. 표 속성 깊이가 3인 복잡한 구조에\\n서는 중첩된 속성을 대괄호와 중괄호로 묶어 계층을 구분한 후, 각 속성을\\n'/'로 나누어 표의 구조를 표현한다. 이 전처리 기법의 예시는 그림 4.1에 제\\n시되어 있으며, 표 속성 최대 깊이가 3일 때까지만 제공한다. 이는 해당 문\\n서에서 표 속성 깊이가 3을 초과한 경우, 표 속성이 중복된 것이 존재했기\\n때문이다. 또한, 앞서 설명한 전처리 방법론에 따라 리스트에 표 구조를 문\\n자열로 추가하여, 거대언어모델이 표 구조를 더 잘 인식할 수 있도록 한다.\\n(a)\\n(b)\\n<그림 4.1> 표 데이터 변환 방법론 및 구분자 기반 전처리 기법 예시\\n(a) 표 속성 깊이 기반 변환 방법론 적용 예시 (b) 구분자 기반 전처리 기법 적용 예시\\n- 15 -\\n\"), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 26, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='4.1.2 기법 적용 결과\\n<그림 4.2> 구분자 기반 전처리 기법 적용 결과\\n본 연구에서는 전처리 기법을 프로그램으로 자동화하여, JSON 파일을 입\\n력하면 표 데이터를 자연어 텍스트로 변환할 수 있도록 구현하였다. 구분자\\n기반 전처리 기법을 적용한 결과는 그림 4.2와 같다. 이 과정에서 거대언어\\n모델의 문맥 이해력을 높이기 위해, 태그와 기호를 통해 프롬프트 요소를\\n전략적으로 삽입하여 표 구조를 표현하였다.\\n4.1.3 한계점\\n해당 전처리 기법의 명확한 한계점은 현재 시스템은 사용한 문서에서 가장\\n복잡한 형태의 표가 속성 최대 깊이가 3인 점에 착안하여 프로토타입으로 구\\n현된 상태이다. 하지만 다른 문서에서 표 속성 최대 깊이가 4 이상인 표가\\n존재할 수도 있다. 그렇다면 해당 시스템은 표 속성 최대 깊이마다 새로운 구\\n분자를 추가하고 이를 처리할 수 있는 함수를 구현해야 한다는 점에서 기존\\n시스템을 계속 수정해야 하므로 완전 자동화가 어렵다는 한계점이 있다.\\n- 16 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 27, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='4.2 한국어 조사 체계 기반 전처리 기법\\n4.2.1 전처리 기법 개요 및 절차\\n이 기법은 3장에서 소개한 표 데이터 변환 방법론을 바탕으로 하되, 구분\\n자 기반 전처리 기법과는 달리 완전한 자연어 문장으로 변환한다. 거대언어\\n모델이 자연어에 대해 높은 성능을 보인다는 점을 고려하여, 표 구조를 셀\\n위치나 구분자 기호로 전달하지 않고, 사람이 타인에게 표를 설명하는 방식\\n처럼 자연어 문장으로 변환하는 방식을 통해 일반화된 문장으로 전처리하는\\n기법이다.\\n표 설명을 자연어로 구성하기 위해 한국어의 조사 체계를 활용한다. 구체\\n적으로, 장소나 출발점을 나타내는 부사격 조사 \"~에서\"를 표 제목에 사용\\n하고, 명사 뒤에 붙어 주어임을 나타내는 주격 조사 \"~은\"을 표 속성에 붙\\n여 주어로 지정한 후, 명사 뒤에 붙어 그 명사의 의미를 설명하는 서술격\\n조사 \"~이다\"를 셀 값에 붙여 표의 내용을 표현한다.\\n표 속성 깊이가 1인 경우, 각 속성에 바로 주격 조사를 붙여 셀 값을 서\\n술격 조사로 마무리하는 방식으로 문장을 구성한다. 예를 들어, \"속성은 값\\n이다\"와 같은 형식이 된다. 표 속성 깊이가 2 이상이면 중첩된 속성들을 명\\n사 뒤에 붙어 소유나 관계를 나타내는 관형격 조사 \"~의\"로 연결하고, 마지\\n막 속성에 주격 조사를 붙인 후 셀 값에 서술격 조사를 사용하여 자연스러\\n운 문장을 완성한다. 예를 들어, 중첩된 속성이 있는 경우 \"A의 B의 값은 C\\n이다\"와 같은 형식으로 문장을 구성한다.\\n- 17 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 28, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='4.2.2 기법 적용 결과\\n(a)\\n고교유형별 지원자격에서 모집군은 가군이며, 전형명은 수능 (일반\\n학생전형)이며, 고교유형별 지원자격의 일반고은 지원 가능이며, 고\\n교유형별 지원자격의 자율고은 지원 가능이며, 고교유형별 지원자격\\n의 특수목적고의 과학고, 국제고, 외국어고은 지원 가능이며, 고교유\\n형별 지원자격의 특수목적고의 예술고, 체육고은 지원 가능이며, 고\\n교유형별 지원자격의 특수목적고의 마이스터고은 지원 가능이며, 고\\n(b) 교유형별 지원자격의 특성화고의 특성(직업)은 지원 가능이며, 고교\\n유형별 지원자격의 특성화고의 특성(대안)은 지원 가능이며, 고교유\\n형별 지원자격의 영재학교은 지원 가능이며, 고교유형별 지원자격의\\n기타의 학력인정고은 지원 가능이며, 고교유형별 지원자격의 기타의\\n방송통신고은 지원 가능이며, 고교유형별 지원자격의 기타의 각종학\\n교은 지원 가능이며, 고교유형별 지원자격의 검정고시은 지원 가능\\n이며, 고교유형별 지원자격의 외국고은 지원 가능이다.\\n<그림 4.3> 한국어 조사 체계 기반 전처리 기법 적용 결과\\n(a) 표 원본 (b) 한국어 조사 체계 기반 전처리 기법으로 변환된 자연어 문장\\n한국어 조사 체계 기반 전처리 기법을 적용한 결과는 그림 4.3과 같다.\\n4.2.3 문제점\\n이 기법의 주요 문제점 중 하나는 많은 토큰을 소모한다는 점이다. 그림\\n4.3의 (b) 문장은 236개 토큰으로 구성된 문장이다. 본 논문에서 사용하는\\n데이터를 기준으로 가장 짧은 문장은 50개의 토큰을 사용하며, 가장 긴 문\\n장은 622개의 토큰을 사용한다. 평균적으로는 약 215개의 토큰이 필요하다.\\n또 다른 문제점은 현재 시스템에서 주격 조사로 \"~은\"만을 사용하고 있\\n- 18 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 29, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='다는 점이다. 한국어 문장의 자연스러움을 위해서는 명사의 마지막 음절이\\n받침이 있는지에 따라 \"~은\" 또는 \"~는\"을 선택해야 하지만, 현재는 이러한\\n점을 고려하지 않아 모든 문장에서 \"은\"으로 작성되고 있다. 이에 따라 일부\\n문장이 부자연스럽게 표현되는 경우가 발생한다.\\n5. 질의응답 시스템 구축\\n5.1 시스템 동작 과정\\n<그림 5.1> 검색 증강 생성 기반의 질의응답 시스템 구조도\\n앞서 언급한 바와 같이, 거대언어모델은 정보 접근 제한, 입출력 토큰 제\\n한, 작화 및 환각 현상과 같은 공통적인 문제점이 존재한다. 본 논문에서는\\n이 문제점을 개선하기 위해 검색 증강 생성 기반의 질의응답 시스템을 구축\\n- 19 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 30, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='한다. 검색 증강 생성 기반의 질의응답 시스템에서 벡터저장소를 사용하여\\n정보 접근 제한 문제를, 문서 분할기를 통해 입출력 토큰 제한을, 마지막으\\n로 벡터저장소와 프롬프트를 통해 작화 및 환각 현상을 개선한다.\\n본 논문에서 구축하는 질의응답 시스템의 구조도는 그림 5.1과 같다. 이\\n는 대표적인 검색 증강 생성 기반의 질의응답 시스템 구조이며, 동작 과정\\n은 다음과 같다. 먼저, 그림 5.1의 Vector Upload 단계에서 사용자로부터\\n질의응답에 사용할 문서를 업로드 받는다. 이후, 해당 문서를 특정 청크 및\\n오버랩 크기로 나눈다. 그런 다음, 임베딩 모델을 사용하여 분할된 문서를\\n벡터 형태로 변환하고 이를 벡터저장소에 저장한다.\\n사용자가 문서에 대해 질문을 입력하면, 시스템은 문서를 수치화할 때 사용\\n했던 임베딩 모델을 이용해 사용자 질문도 수치화한다. 이후, 벡터저장소에서\\n수치화된 질문과 가장 높은 유사도를 보이는 문서 k개를 검색하여 반환한다.\\n다음으로, 시스템은 프롬프트 템플릿을 구성한다. 프롬프트 템플릿은 시\\n스템 프롬프트, 인간 프롬프트, 그리고 인공지능 프롬프트로 구성된다. 이때\\n시스템 프롬프트는 거대언어모델에 수행할 명령을 전달하는 내용으로 구성\\n되며, 인간 프롬프트는 사용자의 질문을 의미한다. 인공지능 프롬프트는 거\\n대언어모델이 출력할 응답을 의미하지만, 본 시스템에서는 시스템 프롬프트\\n와 인간 프롬프트만을 사용하여 프롬프트 템플릿을 구성하였다.\\n이렇게 구성된 프롬프트 템플릿을 거대언어모델에 전달하여, 모델이 사용\\n자 질문에 대한 응답을 생성하는 방식으로 시스템이 동작한다.\\n5.2 시스템 구현\\n5.2.1 개발 환경\\n개발 환경은 Windows 10 Pro 운영체제를 사용하였으며, 하드웨어 사양\\n은 AMD Ryzen 5 5600X 6-Core Processor, 48GB RAM, 그리고 RTX\\n3090 그래픽 카드 1대를 사용한다. 개발 도구는 PyCharm Professional\\n2024.2.4 버전과 Python 3.11을 사용한다. 검색 증강 생성 기반의 질의응\\n답 시스템 구축을 위한 프레임워크로는 LangChain 0.2.11 버전을, 벡터저장\\n소로는 Chroma DB 0.5.11 버전을 사용한다. 해당 내용은 표 5.1과 같다.\\n- 20 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 31, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<표 5.1> 시스템 개발 환경 및 버전\\nOS Windows 10 Pro\\nCPU AMD Ryzen 5 5600X 6-Core Processor\\nGPU NVIDIA GeForce RTX 3090 1set\\nRAM 48GB\\nPython Version 3.11.x\\nLangChain Version 0.2.x\\nVector Store Chroma DB 0.5.x\\nIDE PyCharm Professional 2024.2.x\\n5.2.2 시스템 상세 내용\\n본 시스템의 검색 증강 생성 기반 질의응답 시스템에서는 문서를 분할하\\n기 위해 재귀적 문서 분할기(RecursiveCharacterTextSplitter)를 사용하였\\n다. 이 분할기를 선택한 이유는, 청크 생성 시 토큰 문제가 발생하지 않도록\\n하기 위함이다. 재귀적 문서 분할기의 특징은 구분자(Separators)를 리스트\\n에 저장하고, 청크 크기에 맞춰 재귀적으로 분할하는 방식으로 작동한다. 본\\n시스템에서는 구분자로 [\"\\\\n\\\\n\", \"\\\\n\", \" \"]를 사용하여 문서를 재귀적으\\n로 분할하였고, 분할 과정에서 토큰 단위로 분할이 이루어지도록 설정하였\\n다. 한국어 형태소 분석기로는 선행 연구[35] 및 AutoRAG[41]의 한국어\\n형태소 분석기 벤치마크[42]에서 우수한 성능을 보인 Okt를 채택하였다.\\n문서 임베딩은 OpenAI의 text-embedding-3-small[43] 모델을 API로\\n호출하여 사용하였다.\\n본 시스템에서 유료 API 호출을 통해 사용할 수 있는 거대언어모델\\n(Large Language Model, LLM)로는 GPT, Claude, Gemini 계열 모델이\\n있으며, 무료로 사용할 수 있는 허깅페이스(Hugging Face) 오픈소스 모델\\n로는 Gemma, Llama, Qwen, Mistral, Phi 모델을 지원한다. 오픈소스 모델\\n을 구동하기 위해서는 고사양 그래픽카드가 필요하다. 이러한 자원 문제로\\n인해, 본 시스템에서는 오픈소스 모델을 8비트로 양자화한 버전을 LM\\nStudio[44]를 통해 구동하도록 구현하였다. 또한, 시스템은 거대언어모델의\\n종류를 추가할 수 있도록 확장 가능성을 고려하여 설계하였다.\\n- 21 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 32, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='\\ue004\\ue0f2\\ue0f7\\ue0e9\\ue0f1\\ue0e6\\ue0f0\\ue0e9\\ue011\\ue0e9\\ue0f8\\ue0f6\\ue0ed\\ue0e9\\ue0fa\\ue0e9\\ue0f6 \\ue047 \\ue0a7×\\ue003\\ue0e9\\ue0f2\\ue0f7\\ue0e9\\ue011\\ue0e9\\ue0f8\\ue0f6\\ue0ed\\ue0e9\\ue0fa\\ue0e9\\ue0f6\\ue048\\ue044\\ue034\\ue046\\ue0a7\\ue045×\\ue012\\ue0f4\\ue0e5\\ue0f6\\ue0f7\\ue0e9\\ue011\\ue0e9\\ue0f8\\ue0f6\\ue0ed\\ue0e9\\ue0fa\\ue0e9\\ue0f6 (5-1)\\n검색 증강 생성 시스템에서는 질문과 유사도가 높은 문서를 찾기 위해 검\\n색기를 활용한다. 본 논문에서는 의미적 유사도를 기반으로 한 밀집 검색기\\n와, 단어 기반 검색에서 우수한 성능을 보이는 희소 검색기를 특정 가중치\\n로 결합한 앙상블 검색기를 사용하여 질문과 연관성이 높은 문서를 효과적\\n으로 검색한다. 식 5-1은 이러한 앙상블 검색기의 수식을 나타내며, \\ue0a7의 범\\n위는 \\ue0a7∈\\ue049\\ue03d\\ue052\\ue034\\ue04a이다. 앙상블 검색기는 밀집 검색기로는 벡터저장소 기반 검색\\n기를 사용하고, 희소 검색기로는 Okt 형태소 분석기를 사용하는 BM25 검\\n색기를 0.5:0.5의 가중치로 결합하여 사용한다.\\n다음으로 검색기를 통해 질문과 유사도가 높은 문서를 기반으로 프롬프트\\n템플릿을 생성한다. 프롬프트 템플릿은 시스템, 인간, 그리고 인공지능 프롬\\n프트로 구성된다. 시스템 프롬프트는 거대언어모델에 한국어로 답변을 제공\\n하고, 주어진 문맥을 바탕으로 응답하도록 설정하며, 만약 정확한 답변이 어\\n려운 경우 특정 사이트에 문의하라는 명령문을 포함하여 환각 또는 작화 현\\n상을 줄이도록 구성하였다.\\nYou are a helpful AI Assistant. Please answer in Korean.\\nPlease provide responses based on the context provided if unsure,\\ndirect inquiries to \"https://ipsi.deu.ac.kr/main.do\".\\n**Context**\\n{context}\\n<그림 5.2> 시스템 프롬프트\\n시스템 프롬프트의 구체적인 내용은 그림 5.2와 같다. 인간 프롬프트에는\\n사용자 질문이 작성되며, 인공지능 프롬프트는 거대언어모델이 생성한 응답\\n이므로 별도로 설정하지 않는다. 이렇게 구성된 프롬프트 템플릿을 기반으\\n로 거대언어모델이 최종 응답을 생성한다.\\n- 22 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 33, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='6. 실험\\n6.1 질의응답 평가 데이터\\n질의응답 정확도 성능 평가 데이터는 총 100개의 질문-응답 쌍으로 구성\\n한다. 평가 데이터의 질문-응답 쌍에서 질문은 입학처 직원, 재학생, 고등학\\n생, 대학 정보 커뮤니티, 그리고 거대언어모델이 생성한 질문 100개로, 각\\n각 20개로 구성한다. 응답 데이터는 각 질문에 대해 적절한 답변을 제공하\\n기 위해, 해당 문서에서 질문에 해당하는 정답을 추출하고 이를 거대언어모\\n델을 통해 문장으로 변환하여 작성한다.\\n6.2 질의응답 정확도 성능 평가 지표\\n관련 연구에서 소개한 평가 지표 중에서 언어모델을 사용하지 않고 평가\\n하는 지표인 BLEU, METEOR, ROUGE와 언어모델을 사용하여 평가하는\\n지표인 Sem Score, GPT Score, 그리고 G-Eval을 통해 질의응답 정확도\\n성능을 평가한다.\\n6.2.1 BLEU, ROUGE, METEOR\\n표 데이터를 대상으로 거대언어모델이 생성한 응답과 참조 응답 간의 유\\n사도를 평가하기 위해, 기계 번역 품질 평가에 주로 사용되는 BLEU,\\nROUGE-1, ROUGE-2, ROUGE-L, 그리고 METEOR 지표를 활용한다. 이\\n러한 지표들은 각 거대언어모델이 생성한 응답이 참조 응답과 얼마나 유사\\n한지를 정량적으로 평가하며, 이를 통해 응답의 품질을 자동으로 평가한다.\\n6.2.2 Sem Score\\n표 데이터 기반의 질문에 대해 거대언어모델이 생성한 응답과 참조 응답\\n간의 의미적 유사도를 평가하기 위해 Sem Score를 사용한다. 이 실험에서\\n는 SentenceTransformer 모델을 활용하여 문장을 임베딩하고, 생성된 응답\\n과 참조 응답 간의 코사인 유사도를 계산한다. 임베딩에는 Sem Score에서\\n사용한 all-mpnet-base-v2 모델을 사용하여 유사도를 측정한다.\\n- 23 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 34, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='6.2.3 GPT Score + G-Eval\\n6.1절에서 설명한 평가 데이터셋을 5장에서 구축한 질의응답 시스템을\\n사용하여, 거대언어모델이 생성한 응답을 참조 응답과 비교하여 평가한다.\\n<표 6.1> GPT Score[30] 21개 평가 측면 원본\\n평가 측면 작업 정의\\n의미적 포괄성\\n생성된 텍스트가 원본 텍스트의 의미적 콘텐츠\\n(Semantic 텍스트 요약\\n단위를 얼마나 많이 포함하고 있는가?\\nCoverage)\\n사실성 생성된 텍스트가 원본 텍스트의 사실적 진술을\\n텍스트 요약\\n(Factuality) 얼마나 잘 유지하고 있는가?\\n일관성 텍스트 요약, 생성된 텍스트가 제공하는 정보는 얼마나 일\\n(Consistency) 응답 생성 관성이 있는가?\\n텍스트 요약,\\n유용성 생성된 텍스트가 원본 텍스트의 핵심 아이디어\\n데이터 텍스트\\n(Informativeness) 를 얼마나 잘 포착하고 있는가?\\n변환, 응답 생성\\n응집성 텍스트 요약, 생성된 텍스트가 얼마나 논리적이고 이해하기 쉬\\n(Coherence) 응답 생성 운가?\\n관련성 텍스트 요약, 생성된 텍스트가 원본 텍스트와 얼마나 관련성\\n(Relevance) 응답 생성 이 있는가?\\n응답 생성,\\n텍스트 요약,\\n유창성 생성된 텍스트가 얼마나 잘 쓰였으며 문법적으\\n데이터텍스트\\n(Fluency) 로 정확한가?\\n변환,\\n기계번역\\n정확성 생성된 텍스트에 부정확하거나 누락되거나 사실\\n기계번역\\n(Accuracy) 과 다른 내용이 있는가?\\n다차원적 품질\\n(Multidimensional 기계번역 생성된 텍스트의 전반적인 품질은 어떠한가?\\nQuality)\\n흥미로움\\n응답 생성 생성된 텍스트가 흥미로운가?\\n(Interest)\\n몰입도\\n응답 생성 생성된 텍스트가 몰입감을 주는가?\\n(Engagement)\\n구체성 생성된 텍스트가 일반적인가, 아니면 원본 텍\\n응답 생성\\n(Specific) 스트에 대해 구체적인가?\\n- 24 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 35, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='정확성 생성된 텍스트가 정확한가, 아니면 원본 텍스\\n응답 생성\\n(Correctness) 트를 오해했는가?\\n의미적 적합성\\n생성된 응답이 원문 맥락에 맞게 적절한 의미\\n(Semantic 응답 생성\\n를 얼마나 잘 전달하고 있는가?\\nAppropriateness)\\n이해 가능성\\n응답 생성 생성된 응답을 이해하기 얼마나 쉬운가요?\\n(Understandability)\\n오류 복구 능력 시스템이 스스로 발생시킨 오류를 얼마나 잘\\n응답 생성\\n(Error Recovery) 복구할 수 있는가?\\n다양성\\n응답 생성 응답에 다양성이 있는가?\\n(Diversity)\\n깊이\\n응답 생성 주제를 깊이 있게 다루는가?\\n(Depth)\\n호감도\\n응답 생성 호감 가는 성격을 보여주는가?\\n(Likeability)\\n유연성 사용자와 그들의 관심사에 얼마나 유연하게 적\\n응답 생성\\n(Flexibility) 응하는가?\\n호기심\\n응답 생성 대화 내내 호기심을 보이는가?\\n(Inquisitiveness)\\n이 평가는 GPT Score 원문에 제시된 21개 평가 측면을 나타내는 표\\n6.1을 기반으로, 사용자의 질문에 해당하는 표의 특정 셀 값을 정확하게 응\\n답하는 것이 핵심인 표 질의응답 관련 9개 측면을 우선으로 채택하였으며,\\n채택된 9개 평가 측면은 표 6.2와 같다.\\n생성된 응답의 흥미로움, 몰입도, 구체성, 정확성(Correctness), 오류 복\\n구 능력, 다양성, 깊이, 호감도, 호기심 등 총 11개 평가 측면은 일반적인\\n대화형 응답에서는 동시에 고려되어야 하는 요소들이다. 그러나 표 질의응\\n답에서는 특정 셀 값을 기반으로 한 정확한 응답 생성이 가장 중요한 요소\\n라 판단하였으며, 평가 과정에서 GPT 계열 언어모델인 GPT 4o mini 거대\\n언어모델을 사용함에 따라 토큰당 비용이 발생하므로 9개 평가 측면을 우선\\n으로 채택하였다.\\n따라서 이 평가에서는 정확성을 중심으로 9개 평가 측면을 우선적으로\\n평가하고, 필요에 따라 제외된 11개 평가 측면을 추가적으로 평가할 계획이\\n다. 또한, 정확성(Correctness) 평가 측면이 제외된 이유는 채택된 9개 평\\n가 측면 중 정확성(Accuracy) 평가 측면이 이미 포함되어 있기 때문이다.\\n- 25 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 36, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<표 6.2> 표 질의응답 평가 측면\\n평가 측면 작업 정의\\n사실성 생성된 텍스트가 원본 텍스트의 사실적 진술을\\n텍스트 요약\\n(Factuality) 얼마나 잘 유지하고 있는가?\\n일관성 텍스트 요약, 생성된 텍스트가 제공하는 정보는 얼마나 일관\\n(Consistency) 응답 생성 성이 있는가?\\n응집성 텍스트 요약, 생성된 텍스트가 얼마나 논리적이고 이해하기 쉬\\n(Coherence) 응답 생성 운가?\\n관련성 텍스트 요약, 생성된 텍스트가 원본 텍스트와 얼마나 관련성\\n(Relevance) 응답 생성 이 있는가?\\n응답 생성,\\n텍스트 요약,\\n유창성 생성된 텍스트가 얼마나 잘 쓰였으며 문법적으\\n데이터텍스트\\n(Fluency) 로 정확한가?\\n변환,\\n기계번역\\n정확성 생성된 텍스트에 부정확하거나 누락되거나 사실\\n기계번역\\n(Accuracy) 과 다른 내용이 있는가?\\n다차원적 품질\\n(Multidimensional 기계번역 생성된 텍스트의 전반적인 품질은 어떠한가?\\nQuality)\\n의미적 적합성\\n생성된 응답이 원문 맥락에 맞게 적절한 의미를\\n(Semantic 응답 생성\\n얼마나 잘 전달하고 있는가?\\nAppropriateness)\\n이해 가능성\\n응답 생성 생성된 응답을 이해하기 얼마나 쉬운가요?\\n(Understandability)\\nGPT Score 논문에 소개된 기존 평가 프로토콜은 평가 기준, 평가 측면,\\n생성된 응답, 문장 요약으로 구성된 프롬프트 템플릿을 거대언어모델에 입\\n력하여 평가 결과를 얻는 방식이다. 그러나 기존 GPT Score 프로토콜을\\n그대로 사용할 경우, 거대언어모델을 이용한 평가 과정이 일관되지 않거나\\n결과 도출의 근거가 명확하지 않아 평가 결과의 신뢰도가 낮아질 수 있다는\\n문제가 있다. 이러한 문제를 해결하기 위해, 본 논문에서는 GPT Score와\\nG-Eval[31] 방식을 결합하여 새로운 평가 프로토콜을 구성한다.\\n- 26 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 37, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 6.1> GPT Score + G-Eval 평가 프로토콜\\n새로운 평가 프로토콜은 그림 6.1과 같으며, 기존의 평가 기준, 평가 측면,\\n생성된 응답, 참조 응답을 그대로 유지하면서, 몇 가지 개선 사항을 추가한\\n다. 첫째, 본 연구에서는 G-Eval 방식을 적용하여 각 평가 측면에 대해 단계\\n별 평가를 도입함으로써, 거대언어모델이 각 측면을 단계적으로 평가하도록\\n한다. 둘째, G-Eval 논문에 제시된 예제 프롬프트를 활용하여, 각 평가 측면\\n을 1에서 5점 사이의 점수로 평가하고, 평가 기준을 명확하게 제시한다. 이를\\n통해 거대언어모델이 일관된 기준으로 응답을 평가할 수 있도록 지원한다. 마지\\n막으로, 거대언어모델이 일관된 형식으로 응답을 생성하도록 출력 예시를 제공\\n하여, 평가 결과 계산을 자동화할 수 있도록 한다. 이러한 개선을 통해 기존\\nGPT Score 프로토콜을 보완하고, 신뢰성 있는 평가 결과를 도출하도록 한다.\\n(6-1)\\n수식 6-1은 평가 점수를 환산하는 방법을 나타낸다. 해당 식에서 n은 사\\n용자 질문 수, m은 각 질문에 대해 평가하는 평가 측면의 수, k는 평가 점\\n수를 의미한다. 이 수식은 각 질문의 모든 측면에 대한 평가 점수의 평균을\\n구한 후, 이를 100점 만점으로 환산한다. 평가에 사용한 프롬프트 일부 예\\n시는 부록에 제시되어 있다. 본 실험에서 n은 100, m은 9, k는 1~5점이다.\\n- 27 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 38, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='6.3 실험 결과 및 분석\\n본 절에서는 각 거대언어모델을 사용하여 청크 크기를 1,500에서 3,500\\n까지 500단위로, 오버랩 크기를 0에서 500까지 100단위로 조정에 따른 표\\n질의응답 성능 평가 지표 점수 중 가장 높은 점수, 낮은 점수, 그리고 평균\\n점수의 청크 및 오버랩 크기 조합을 나타낸다.\\n실험 결과를 나타내는 그림의 x축은 전처리 기법을 적용하지 않은 JSON 형\\n식의 표 데이터를 기반으로 질의응답 한 결과이며 그림에서는 \"Basic\"의 약어\\n\"BSC\"라 표현한다. 구분자 기반 전처리 기법을 적용한 말뭉치를 사용하여\\n질의응답한 결과는 그림에서 \"Preprocessing Based on Separator\"의 약어\\n\"PBS\"로 표현하며, 한국어 조사 체계 기반 전처리 기법을 적용한 말뭉치를\\n사용한 질의응답 결과는 그림에서 \"Preprocessing Based on Korean\\nParticles\"의 약어 \"PBK\"로 표현한다.\\n6.3.1 BLEU\\n6.3.1.1 GPT 4o mini\\n<그림 6.2> GPT 4o mini BLEU Score\\n- 28 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 39, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='그림 6.2는 GPT 4o mini 모델로 BLEU 점수를 측정한 결과이다. 전처리\\n기법을 적용하지 않았을 때, 최고 점수 0.341은 청크 크기 2,000, 오버랩\\n크기 300에서 얻었으며, 최저 점수 0.28은 청크 크기 2,000에서 오버랩 없\\n이 기록되었다. 평균 점수는 0.311이다. 구분자 기반 전처리 기법을 적용한\\n경우, 청크 크기 3,000, 오버랩 크기 100에서 최고 점수 0.366을 보였고,\\n청크 크기 1,500, 오버랩 크기 500에서 최저 점수 0.323을 나타내며 평균\\n은 0.344이다. 한국어 조사 체계 기반 전처리 기법에서는 청크 크기 3,500,\\n오버랩 크기 500에서 최고 0.362를 기록했고, 청크 크기 1,500, 오버랩 크\\n기 500에서 최저 0.323을 보여 평균 점수는 0.343이다.\\n6.3.1.2 Gemma\\n<그림 6.3> Gemma BLEU Score\\n그림 6.3은 Google Gemma 2 it 9B 모델의 BLEU 점수 결과이다. 전처\\n리 기법을 적용하지 않았을 때, 최고 점수 0.268은 청크 크기 1,500, 오버\\n랩 크기 300에서, 최저 점수 0.116은 청크 크기 3,500, 오버랩 크기 400에\\n서 얻어졌다. 평균 점수는 0.205이다. 구분자 기반 전처리 기법을 적용한\\n- 29 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 40, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='경우, 청크 크기 2,000, 오버랩 크기 200에서 최고 0.299, 청크 크기 3,500, 오\\n버랩 크기 400에서 최저 0.174를 보여 평균은 0.241이다. 한국어 조사 체계 기\\n반 전처리 기법에서는 청크 크기 1,500, 오버랩 크기 500에서 최고 0.296, 청\\n크 크기 3,000, 오버랩 없이 최저 0.178을 기록하며 평균 점수는 0.243이다.\\n6.3.2 METEOR\\n6.3.2.1 GPT 4o mini\\n<그림 6.4> GPT 4o mini METEOR Score\\n그림 6.4는 GPT 4o mini 모델의 METEOR 점수이다. 전처리 기법을 적\\n용하지 않았을 때, 최고 0.413은 청크 크기 2,000, 오버랩 크기 300에서,\\n최저 0.366은 청크 크기 2,000에서 오버랩 없이 얻어졌으며 평균은 0.391\\n이다. 구분자 기반 전처리 기법을 적용한 경우, 청크 크기 3,000, 오버랩 크\\n기 100에서 최고 0.435, 청크 크기 1,500, 오버랩 없이 최저 0.388을 보여\\n평균 점수는 0.413이다. 한국어 조사 체계 기반 전처리 기법에서는 청크 크\\n기 2,500, 오버랩 크기 200에서 최고 0.414, 청크 크기 2,500, 오버랩 크\\n기 100에서 최저 0.387을 기록하여 평균은 0.402이다.\\n- 30 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 41, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='6.3.2.2 Gemma\\n<그림 6.5> Gemma METEOR Score\\n그림 6.5는 Gemma 2 it 9B 모델의 METEOR 점수 결과이다. 전처리 기\\n법을 적용하지 않았을 때, 최고 0.293은 청크 크기 2,000, 오버랩 크기\\n300에서, 최저 0.143은 청크 크기 3,500에서 오버랩 400에서 얻어졌으며\\n평균은 0.226이다. 구분자 기반 전처리 기법을 적용한 경우, 청크 크기\\n1,500, 오버랩 크기 200에서 최고 0.323, 청크 크기 3,500, 오버랩 400에\\n서 최저 0.188을 보여 평균 점수는 0.263이다. 한국어 조사 체계 기반 전처\\n리 기법에서는 청크 크기 1,500, 오버랩 크기 200에서 최고 0.317, 청크\\n크기 3,000, 오버랩 크기 0에서 최저 0.196을 기록하여 평균은 0.262이다.\\n- 31 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 42, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='6.3.3 ROUGE\\n6.3.3.1 GPT 4o mini\\n<그림 6.6> GPT 4o mini ROUGE-1 Score\\n그림 6.6은 GPT 4o mini 모델의 ROUGE-1 점수를 보여준다. 전처리 기\\n법을 적용하지 않았을 때, 최고 점수 0.405는 청크 크기 2,500에서 오버랩\\n없이, 최저 점수 0.353은 청크 크기 2,000에서 오버랩 없이 얻어졌으며 평\\n균은 0.384이다. 구분자 기반 전처리 기법을 적용한 경우, 청크 크기\\n3,000, 오버랩 크기 100에서 최고 0.429, 청크 크기 2,000, 오버랩 없이\\n최저 0.381을 기록하여 평균은 0.408이다. 한국어 조사 체계 기반 전처리\\n기법에서는 청크 크기 3,500, 오버랩 크기 500에서 최고 0.429, 청크 크기\\n1,500, 오버랩 크기 500에서 최저 0.4를 보여 평균은 0.417이다.\\n- 32 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 43, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 6.7> GPT 4o mini ROUGE-2 Score\\nROUGE-2 점수는 그림 6.7에 나타나 있다. 전처리 기법을 적용하지 않\\n았을 때, 최고 0.274는 청크 크기 2,500에서 오버랩 없이, 최저 0.226은 청\\n크 크기 2,000에서 오버랩 없이 기록되었고 평균은 0.252이다. 구분자 기반\\n전처리 기법을 적용한 경우, 청크 크기 3,000, 오버랩 크기 100에서 최고\\n0.296, 청크 크기 2,000, 오버랩 없이 최저 0.261을 보여 평균은 0.278이\\n다. 한국어 조사 체계 기반 전처리 기법에서는 청크 크기 3,500, 오버랩 크\\n기 500에서 최고 0.296, 청크 크기 1,500, 오버랩 크기 500에서 최저\\n0.265를 기록하여 평균은 0.282이다.\\n- 33 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 44, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 6.8> GPT 4o mini ROUGE-L Score\\n그림 6.8은 ROUGE-L 점수를 보여준다. 전처리 기법을 적용하지 않았을\\n때, 최고 점수 0.359는 청크 크기 2,500에서 오버랩 없이, 최저 점수 0.311\\n은 청크 크기 2,000에서 오버랩 없이 얻어졌으며 평균은 0.339이다. 구분자\\n기반 전처리 기법을 적용한 경우, 청크 크기 3,000, 오버랩 크기 100에서\\n최고 0.378, 청크 크기 2,000, 오버랩 없이 최저 0.333을 기록하여 평균은\\n0.358이다. 한국어 조사 체계 기반 전처리 기법에서는 청크 크기 3,500, 오\\n버랩 크기 500에서 최고 0.376, 청크 크기 1,500, 오버랩 크기 500에서 최\\n저 0.344를 보여 평균은 0.362이다.\\n- 34 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 45, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='6.3.3.2 Gemma\\n<그림 6.9> Gemma ROUGE-1 Score\\n그림 6.9는 Gemma 2 it 9B 모델의 ROUGE-1 점수를 나타낸다. 전처리\\n기법을 적용하지 않았을 때, 최고 점수 0.342는 청크 크기 2,000, 오버랩 크\\n기 300에서, 최저 점수 0.212는 청크 크기 3,500, 오버랩 크기 400에서 얻\\n어졌으며 평균은 0.291이다. 구분자 기반 전처리 기법을 적용한 경우, 청크\\n크기 1,500, 오버랩 크기 400에서 최고 0.362, 청크 크기 3,500, 오버랩 크\\n기 400에서 최저 0.267을 기록하여 평균은 0.322이다. 한국어 조사 체계 기\\n반 전처리 기법에서는 청크 크기 1,500, 오버랩 크기 200에서 최고 0.358,\\n청크 크기 3,000에서 오버랩 없이 최저 0.271을 보여 평균은 0.318이다.\\n- 35 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 46, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 6.10> Gemma ROUGE-2 Score\\nROUGE-2 점수는 그림 6.10에 표시되어 있다. 전처리 기법을 적용하지\\n않았을 때, 최고 점수 0.183은 청크 크기 2,000, 오버랩 크기 300에서, 최\\n저 점수 0.09는 청크 크기 3,500, 오버랩 크기 400에서 얻어졌으며 평균은\\n0.138이다. 구분자 기반 전처리 기법을 적용한 경우, 청크 크기 1,500, 오\\n버랩 크기 200에서 최고 0.203, 청크 크기 3,500, 오버랩 크기 400에서 최\\n저 0.111을 기록하여 평균은 0.16이다. 한국어 조사 체계 기반 전처리 기법\\n에서는 청크 크기 1,500, 오버랩 크기 500에서 최고 0.192, 청크 크기\\n3,000에서 오버랩 없이 최저 0.119를 보여 평균은 0.16이다.\\n- 36 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 47, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 6.11> Gemma ROUGE-L Score\\n그림 6.11은 ROUGE-L 점수를 보여준다. 전처리 기법을 적용하지 않았\\n을 때, 최고 점수 0.279는 청크 크기 2,000, 오버랩 크기 300에서, 최저 점\\n수 0.16은 청크 크기 3,500, 오버랩 크기 400에서 얻어졌으며 평균은\\n0.228이다. 구분자 기반 전처리 기법을 적용한 경우, 청크 크기 1,500, 오\\n버랩 크기 300에서 최고 0.299, 청크 크기 3,500, 오버랩 크기 400에서 최\\n저 0.199를 기록하여 평균은 0.255이다. 한국어 조사 체계 기반 전처리 기\\n법에서는 청크 크기 1,500, 오버랩 크기 500에서 최고 0.298, 청크 크기\\n3,000에서 오버랩 없이 최저 0.205를 보여 평균은 0.257이다.\\n- 37 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 48, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='6.3.4 Sem Score\\n6.3.4.1 GPT 4o mini\\n<그림 6.12> GPT 4o mini Sem Score\\n그림 6.12는 GPT 4o mini 모델의 Sem Score 결과를 보여준다. 전처리\\n기법을 적용하지 않았을 때, 최고 점수 0.796은 청크 크기 3,500, 오버랩\\n크기 300에서, 최저 점수 0.767은 청크 크기 1,500, 오버랩 크기 100에서\\n기록되었으며, 평균은 0.781이다. 구분자 기반 전처리 기법을 적용한 경우,\\n최고 0.806을 청크 크기 3,000, 오버랩 크기 100에서, 최저 0.767을 청크\\n크기 2,000, 오버랩 없이 얻어 평균은 0.791이다. 한국어 조사 체계 기반\\n전처리 기법을 적용한 경우, 최고 점수 0.81은 청크 크기 2,000, 오버랩 크\\n기 200에서, 최저 0.791은 청크 크기 1,500, 오버랩 크기 500에서 기록되\\n었으며, 평균은 0.799이다.\\n- 38 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 49, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='6.3.4.2 Gemma\\n<그림 6.13> Gemma SEM Score\\n그림 6.13은 Gemma 2 it 9B 모델의 Sem Score 결과이다. 전처리 기법\\n을 적용하지 않았을 때, 최고 점수 0.79는 청크 크기 1,500, 오버랩 크기\\n300에서, 최저 점수 0.648은 청크 크기 3,500, 오버랩 크기 400에서 기록\\n되었으며, 평균은 0.755이다. 구분자 기반 전처리 기법을 적용한 경우, 최고\\n0.807을 청크 크기 1,500, 오버랩 크기 300에서, 최저 0.756을 청크 크기\\n3,500, 오버랩 크기 200에서 얻어 평균은 0.776이다. 한국어 조사 체계 기\\n반 전처리 기법을 적용했을 때, 최고 점수 0.797은 청크 크기 1,500, 오버\\n랩 크기 200에서, 최저 0.755는 청크 크기 3,500, 오버랩 크기 500에서 기\\n록되었으며, 평균은 0.776이다.\\n- 39 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 50, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='6.3.5 GPT Score + G-Eval\\n6.3.5.1 GPT 4o mini\\n<그림 6.14> GPT 4o mini GPT Score + G-Eval - Factuality\\n그림 6.14는 GPT Score와 G-Eval 방식으로 사실성을 평가한 결과이다.\\n전처리 기법을 적용하지 않았을 때, 최고 점수 70점은 청크 크기 3,500, 오\\n버랩 크기 300에서, 최저 61.4점은 청크 크기 1,500, 오버랩 없이 기록되었\\n으며, 평균은 66.487점이다. 구분자 기반 전처리 기법을 적용한 경우, 최고\\n74.8점을 청크 크기 3,000, 오버랩 크기 100에서, 최저 65.2점을 청크 크\\n기 2,000, 오버랩 없이 얻어 평균은 70.847점이다. 한국어 조사 체계 기반\\n전처리 기법을 적용한 경우, 최고 점수 73.6점은 청크 크기 1,500, 오버랩\\n크기 100에서, 최저 70점은 청크 크기 2,500, 오버랩 크기 100에서 기록되\\n었으며, 평균은 72.06점이다.\\n- 40 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 51, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 6.15> GPT 4o mini GPT Score + G-Eval - Consistency\\n그림 6.15는 일관성을 평가한 결과이다. 전처리 기법을 적용하지 않았을\\n때, 최고 점수 66.6점은 청크 크기 3,000, 오버랩 크기 500에서, 최저 58.8\\n점은 청크 크기 2,000, 오버랩 없이 기록되었으며, 평균은 63.487점이다.\\n구분자 기반 전처리 기법을 적용한 경우, 최고 68.8점을 청크 크기 3,000,\\n오버랩 크기 500에서, 최저 61.4점을 청크 크기 2,000, 오버랩 없이 얻어\\n평균은 66.013점이다. 한국어 조사 체계 기반 전처리 기법을 적용한 경우,\\n최고 점수 69.4점은 청크 크기 3,500, 오버랩 없이, 최저 65.2점은 청크 크\\n기 2,500, 오버랩 크기 100에서 기록되었으며, 평균은 67.067점이다.\\n- 41 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 52, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 6.16> GPT 4o mini GPT Score + G-Eval - Relevance\\n그림 6.16은 관련성을 평가한 결과이다. 전처리 기법을 적용하지 않았을\\n때, 최고 점수 86.4점은 청크 크기 2,500, 오버랩 없이, 최저 79점은 청크\\n크기 1,500, 오버랩 없이 기록되었으며, 평균은 83.093점이다. 구분자 기반\\n전처리 기법을 적용한 경우, 최고 91.8점을 청크 크기 3,000, 오버랩 크기\\n100에서, 최저 82.8점을 청크 크기 2,000, 오버랩 없이 얻어 평균은 87.68\\n점이다. 한국어 조사 체계 기반 전처리 기법을 적용한 경우, 최고 점수\\n91.2점은 청크 크기 2,000, 오버랩 없이, 최저 87.2점은 청크 크기 2,500,\\n오버랩 크기 100에서 기록되었으며, 평균은 89.24점이다.\\n- 42 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 53, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 6.17> GPT 4o mini GPT Score + G-Eval - Fluency\\n그림 6.17은 유창성을 평가한 결과이다. 전처리 기법을 적용하지 않았을\\n때, 최고 점수 92.6점은 청크 크기 3,000, 오버랩 없이, 최저 89.8점은 청\\n크 크기 1,500, 오버랩 없이 기록되었으며, 평균은 91.467점이다. 구분자\\n기반 전처리 기법을 적용한 경우, 최고 93.2점을 청크 크기 1,500, 오버랩\\n크기 300에서, 최저 88.8점을 청크 크기 3,000, 오버랩 크기 100에서 얻어\\n평균은 90.727점이다. 한국어 조사 체계 기반 전처리 기법을 적용한 경우,\\n최고 점수 91.2점은 청크 크기 3,500, 오버랩 없이, 최저 88점을 청크 크기\\n1,500, 오버랩 없이 기록되었으며, 평균은 89.887점이다.\\n해당 측면에서는 전처리 기법을 적용하지 않았을 때보다 두 가지 전처리\\n기법을 적용했을 때 평균적으로 질의응답 정확도 성능이 낮아지는 결과를 보\\n인다. 이러한 결과가 나온 이유를 분석한 결과, 거대언어모델이 생성한 응답\\n은 질문에 대한 특정 데이터를 정확하게 추출하여 언급하였으나, 참조 응답\\n처럼 다양한 표현을 사용하여 문장을 생성하지는 않은 것으로 확인되었다.\\n- 43 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 54, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 6.18> GPT 4o mini GPT Score + G-Eval - Coherence\\n그림 6.18은 응집성을 평가한 결과이다. 전처리 기법을 적용하지 않았을\\n때, 최고 점수 83.6점은 청크 크기 1,500, 오버랩 크기 500에서, 최저 78.6\\n점은 청크 크기 2,000, 오버랩 없이 기록되었으며, 평균은 81.067점이다.\\n구분자 기반 전처리 기법을 적용한 경우, 최고 84점을 청크 크기 2,000, 오\\n버랩 크기 200에서, 최저 78.6점을 청크 크기 2,000, 오버랩 없이 얻어 평\\n균은 82.547점이다. 한국어 조사 체계 기반 전처리 기법을 적용한 경우, 최\\n고 점수 84.4점은 청크 크기 3,500, 오버랩 없이, 최저 82점은 청크 크기\\n2,500, 오버랩 크기 100에서 기록되었으며, 평균은 83.367점이다.\\n- 44 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 55, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 6.19> GPT 4o mini GPT Score + G-Eval - Accuracy\\n그림 6.19는 정확성을 평가한 결과이다. 전처리 기법을 적용하지 않았을\\n때, 최고 점수 69.8점은 청크 크기 3,000, 오버랩 크기 500에서, 최저 61.4\\n점은 청크 크기 1,500, 오버랩 없이 기록되었으며, 평균은 66.187점이다. 구\\n분자 기반 전처리 기법을 적용한 경우, 최고 74.8점을 청크 크기 3,000, 오버\\n랩 크기 100에서, 최저 65.2점을 청크 크기 2,000, 오버랩 없이 얻어 평균은\\n70.633점이다. 한국어 조사 체계 기반 전처리 기법을 적용한 경우, 최고 점\\n수 73.4점은 청크 크기 1,500, 오버랩 크기 100에서, 최저 69.8점은 청크 크\\n기 2,500, 오버랩 크기 100에서 기록되었으며, 평균은 71.807점이다.\\n- 45 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 56, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 6.20> GPT 4o mini GPT Score + G-Eval – Multidimensional Quality\\n그림 6.20은 다차원적 품질을 평가한 결과이다. 전처리 기법을 적용하지\\n않았을 때, 최고 점수 71.8점은 청크 크기 3,500, 오버랩 크기 300에서, 최\\n저 63.2점은 청크 크기 1,500, 오버랩 없이 기록되었으며, 평균은 68.493점\\n이다. 구분자 기반 전처리 기법을 적용한 경우, 최고 76.2점을 청크 크기\\n3,000, 오버랩 크기 100에서, 최저 67점을 청크 크기 2,000, 오버랩 없이\\n얻어 평균은 72.873점이다. 한국어 조사 체계 기반 전처리 기법을 적용한\\n경우, 최고 점수 74.8점은 청크 크기 3,500, 오버랩 크기 300에서, 최저\\n71.4점은 청크 크기 2,500, 오버랩 크기 100에서 기록되었으며, 평균은\\n73.667점이다.\\n- 46 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 57, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 6.21> GPT 4o mini GPT Score + G-Eval – Semantic Appropriateness\\n그림 6.21은 의미적 적합성을 평가한 결과이다. 전처리 기법을 적용하지\\n않았을 때, 최고 점수 79.6점은 청크 크기 3,000, 오버랩 크기 500에서, 최\\n저 73점은 청크 크기 1,500, 오버랩 없이 기록되었으며, 평균은 76.333점이\\n다. 구분자 기반 전처리 기법을 적용한 경우, 최고 82점을 청크 크기 3,000,\\n오버랩 크기 100에서, 최저 75점을 청크 크기 2,000, 오버랩 없이 얻어 평\\n균은 79.4점이다. 한국어 조사 체계 기반 전처리 기법을 적용한 경우, 최고\\n점수 81.4점은 청크 크기 3,000, 오버랩 크기 100에서, 최저 78점은 청크\\n크기 2,500, 오버랩 크기 100에서 기록되었으며, 평균은 80.233점이다.\\n- 47 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 58, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 6.22> GPT 4o mini GPT Score + G-Eval - Understandability\\n그림 6.22는 이해 가능성을 평가한 결과이다. 전처리 기법을 적용하지 않\\n았을 때, 최고 점수 91점은 청크 크기 2,500 및 3,000, 오버랩 없이, 그리\\n고 청크 크기 3,000, 오버랩 크기 500에서 기록되었으며, 최저 87.6점은 청\\n크 크기 1,500, 오버랩 없이 얻어졌고, 평균은 89.7점이다. 구분자 기반 전\\n처리 기법을 적용한 경우, 최고 91.4점을 청크 크기 1,500, 오버랩 크기\\n300과 400에서, 최저 87.4점을 청크 크기 3,500, 오버랩 크기 100에서 기\\n록하여 평균은 89.487점이다. 한국어 조사 체계 기반 전처리 기법을 적용한\\n경우, 최고 점수 90.6점은 청크 크기 3,500, 오버랩 없이, 최저 87.4점은\\n청크 크기 1,500, 오버랩 없이 얻어졌으며, 평균은 89.06점이다.\\n해당 측면은 전처리 기법을 적용하지 않았을 때보다 두 가지 전처리 기법\\n을 적용했을 때 평균적으로 질의응답 정확도 성능이 소폭 감소하는 결과를\\n보였다. 이러한 결과를 분석한 결과, 이는 유창성 측면과 동일한 이유에서\\n발생한 것으로 판단되며, 유창성 측면과 다른 점은 거대언어모델의 기본적\\n인 문장 생성 능력이 높아 생성된 문장의 이해 가능성이 전반적으로 높게\\n나타난다는 점이다.\\n- 48 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 59, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='6.3.5.2 Gemma\\n<그림 6.23> Gemma GPT Score + G-Eval - Factuality\\n그림 6.23은 Gemma 2 it 9B 모델의 사실성 평가 결과이다. 전처리 기법\\n을 적용하지 않았을 때, 최고 점수 58.4점은 청크 크기 2,500, 오버랩 크기\\n300에서, 최저 40.6점은 청크 크기 3,500, 오버랩 크기 400에서 기록되었\\n으며, 평균은 52.113점이다. 구분자 기반 전처리 기법을 적용한 경우, 최고\\n63.6점을 청크 크기 2,000, 오버랩 크기 200에서, 최저 49.4점을 청크 크\\n기 3,000, 오버랩 크기 500에서 얻어 평균은 55.973점이다. 한국어 조사\\n체계 기반 전처리 기법을 적용한 경우, 최고 점수 60점은 청크 크기 1,500,\\n오버랩 없이, 최저 48.6점은 청크 크기 3,500, 오버랩 없이 기록되었으며,\\n평균은 55.34점이다.\\n- 49 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 60, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 6.24> Gemma GPT Score + G-Eval - Consistency\\n그림 6.24는 일관성 평가 결과이다. 전처리 기법을 적용하지 않았을 때,\\n최고 점수 55.4점은 청크 크기 1,500, 오버랩 크기 300에서, 최저 39.4점\\n은 청크 크기 3,500, 오버랩 크기 400에서 기록되었으며, 평균은 49.947점\\n이다. 구분자 기반 전처리 기법을 적용한 경우, 최고 60.4점을 청크 크기\\n2,000, 오버랩 크기 200에서, 최저 47.2점을 청크 크기 3,000, 오버랩 크기\\n500에서 얻어 평균은 53.667점이다. 한국어 조사 체계 기반 전처리 기법을\\n적용한 경우, 최고 점수 57.8점은 청크 크기 1,500, 오버랩 없이 및 오버랩\\n크기 200에서, 최저 47.2점은 청크 크기 3,500, 오버랩 크기 100에서 기록\\n되었으며, 평균은 53.193점이다.\\n- 50 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 61, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 6.25> Gemma GPT Score + G-Eval - Relevance\\n그림 6.25는 관련성 평가 결과이다. 전처리 기법을 적용하지 않았을 때,\\n최고 점수 75.6점은 청크 크기 2,500, 오버랩 크기 300에서, 최저 62.6점\\n은 청크 크기 3,500, 오버랩 크기 400에서 기록되었으며, 평균은 70.52점\\n이다. 구분자 기반 전처리 기법을 적용한 경우, 최고 79.4점을 청크 크기\\n2,000, 오버랩 크기 200에서, 최저 68.6점을 청크 크기 3,000, 오버랩 크기\\n300과 청크 크기 3,500, 오버랩 크기 400에서 얻어 평균은 74.067점이다.\\n한국어 조사 체계 기반 전처리 기법을 적용한 경우, 최고 점수 77.4점은 청\\n크 크기 2,500, 오버랩 크기 300에서, 최저 68점을 청크 크기 3,000, 오버\\n랩 크기 300에서 기록되었으며, 평균은 73.513점이다.\\n- 51 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 62, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 6.26> Gemma GPT Score + G-Eval - Fluency\\n그림 6.26은 유창성 평가 결과이다. 전처리 기법을 적용하지 않았을 때,\\n최고 점수 87.4점은 청크 크기 1,500, 오버랩 크기 300에서, 최저 83점은\\n청크 크기 3,500, 오버랩 크기 400에서 기록되었으며, 평균은 85.68점이다.\\n구분자 기반 전처리 기법을 적용한 경우, 최고 88.6점을 청크 크기 1,500,\\n오버랩 크기 400에서, 최저 85.6점을 청크 크기 3,000, 오버랩 크기 400에\\n서 얻어 평균은 86.7점이다. 한국어 조사 체계 기반 전처리 기법을 적용한\\n경우, 최고 점수 88.6점은 청크 크기 2,000, 오버랩 없이, 최저 84.2점은 청\\n크 크기 3,000, 오버랩 크기 300에서 기록되었으며, 평균은 86.593점이다.\\n- 52 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 63, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 6.27> Gemma GPT Score + G-Eval - Coherence\\n그림 6.27은 응집성 평가 결과이다. 전처리 기법을 적용하지 않았을 때,\\n최고 점수 77.2점은 청크 크기 1,500, 오버랩 크기 500에서, 최저 69.8점\\n은 청크 크기 3,500, 오버랩 크기 400에서 기록되었으며, 평균은 74.047점\\n이다. 구분자 기반 전처리 기법을 적용한 경우, 최고 79.6점을 청크 크기\\n2,000, 오버랩 크기 200에서, 최저 72.4점을 청크 크기 3,500, 오버랩 크기\\n300에서 얻어 평균은 75.953점이다. 한국어 조사 체계 기반 전처리 기법을\\n적용한 경우, 최고 점수 78.2점은 청크 크기 1,500, 오버랩 크기 500에서,\\n최저 72.6점은 청크 크기 3,000, 오버랩 크기 300에서 기록되었으며, 평균\\n은 75.567점이다.\\n- 53 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 64, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 6.28> Gemma GPT Score + G-Eval - Accuracy\\n그림 6.28은 정확성 평가 결과이다. 전처리 기법을 적용하지 않았을 때,\\n최고 점수 58.4점은 청크 크기 2,500, 오버랩 크기 300에서, 최저 40.6점은\\n청크 크기 3,500, 오버랩 크기 400에서 기록되었으며, 평균은 52.033점이\\n다. 구분자 기반 전처리 기법을 적용한 경우, 최고 63.6점을 청크 크기\\n2,000, 오버랩 크기 200에서, 최저 49.2점을 청크 크기 3,500, 오버랩 크기\\n400에서 얻어 평균은 55.92점이다. 한국어 조사 체계 기반 전처리 기법을\\n적용한 경우, 최고 점수 59.8점은 청크 크기 1,500, 오버랩 없이, 최저 48.6\\n점은 청크 크기 3,500, 오버랩 없이 기록되었으며, 평균은 55.227점이다.\\n- 54 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 65, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 6.29> Gemma GPT Score + G-Eval – Multidimensional Quality\\n그림 6.29는 다차원적 품질 평가 결과이다. 전처리 기법을 적용하지 않았을\\n때, 최고 점수 60.4점은 청크 크기 2,500, 오버랩 크기 300에서, 최저 42점은\\n청크 크기 3,500, 오버랩 크기 400에서 기록되었으며, 평균은 54.293점이다.\\n구분자 기반 전처리 기법을 적용한 경우, 최고 65.2점을 청크 크기 2,000, 오\\n버랩 크기 200에서, 최저 51.8점을 청크 크기 3,500, 오버랩 크기 400에서\\n얻어 평균은 58.54점이다. 한국어 조사 체계 기반 전처리 기법을 적용한 경우,\\n최고 점수 62.6점은 청크 크기 2,500, 오버랩 크기 300에서, 최저 50.6점은\\n청크 크기 3,500, 오버랩 없이 기록되었으며, 평균은 57.4점이다.\\n- 55 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 66, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 6.30> Gemma GPT Score + G-Eval – Semantic Appropriateness\\n그림 6.30은 의미적 적합성 평가 결과이다. 전처리 기법을 적용하지 않았을\\n때, 최고 점수 69.8점은 청크 크기 2,500, 오버랩 크기 300에서, 최저 56.6점\\n은 청크 크기 3,500, 오버랩 크기 400에서 기록되었으며, 평균은 64.347점이\\n다. 구분자 기반 전처리 기법을 적용한 경우, 최고 73점을 청크 크기 2,000,\\n오버랩 크기 200에서, 최저 62.2점을 청크 크기 3,000, 오버랩 크기 400에서\\n얻어 평균은 67.353점이다. 한국어 조사 체계 기반 전처리 기법을 적용한 경\\n우, 최고 점수 71점은 청크 크기 1,500, 오버랩 없이, 최저 61.6점은 청크 크\\n기 3,500, 오버랩 없이 기록되었으며, 평균은 66.907점이다.\\n- 56 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 67, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='<그림 6.31> Gemma GPT Score + G-Eval - Understandability\\n그림 6.31은 이해 가능성 평가 결과이다. 전처리 기법을 적용하지 않았을\\n때, 최고 점수 86.2점은 청크 크기 2,000, 오버랩 크기 300에서, 최저 81.6\\n점은 청크 크기 3,500, 오버랩 크기 100에서 기록되었으며, 평균은 84.333\\n점이다. 구분자 기반 전처리 기법을 적용한 경우, 최고 87.4점을 청크 크기\\n1,500, 오버랩 크기 400에서, 최저 83.8점을 청크 크기 2,500, 오버랩 없이\\n및 청크 크기 3,000, 오버랩 크기 300에서 얻어 평균은 85.167점이다. 한\\n국어 조사 체계 기반 전처리 기법을 적용한 경우, 최고 점수 87.2점은 청크\\n크기 1,500, 오버랩 크기 500에서, 최저 82.6점은 청크 크기 3,000, 오버랩\\n크기 300에서 기록되었으며, 평균은 85.513점이다.\\n- 57 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 68, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='6.3.6 실험 결과 분석\\n6.3.6.1 GPT 4o mini\\n<표 6.3> GPT 4o mini - 전처리 기법 적용 여부에 따른 평균 응답 성능 증감률\\n증감률(%)\\n평가 방식\\n기본 한국어 조사\\n구분자\\n(Baseline) 체계\\nBLEU 0.311 0.344(↑ 10.61%) 0.343(↑ 10.29%)\\n1 0.384 0.408(↑ 6.25%) 0.417(↑ 8.59%)\\nROUGE 2 0.252 0.278(↑ 10.32%) 0.282(↑ 11.9%)\\nL 0.339 0.358(↑ 5.6%) 0.362(↑ 6.78%)\\nMETEOR 0.391 0.413(↑ 5.63%) 0.402(↑ 2.81%)\\nSem Score 0.781 0.791(↑ 1.28%) 0.799(↑ 2.3%)\\nFactuality 66.487 70.847(↑ 6.56%) 72.06(↑ 8.38%)\\nConsistency 63.28 66.013(↑ 4.32%) 67.067(↑ 5.98%)\\nRelevance 83.093 87.68(↑ 5.52%) 89.24(↑ 7.40%)\\nFluency 91.467 90.727(↓ 0.81%) 89.887(↓ 1.73%)\\nGPT Score Coherence 81.067 82.547(↑ 1.83%) 83.367(↑ 2.84%)\\n+ Accuracy 66.187 70.633(↑ 6.72%) 71.087(↑ 7.40%)\\nG-Eval\\nMultidimensional\\n68.493 72.873(↑ 6.39%) 73.667(↑ 7.55%)\\nQuality\\nSemantic\\n76.333 79.4(↑ 4.02%) 80.233(↑ 5.11%)\\nAppropriateness\\nUnderstandability 89.7 89.487(↓ 0.24%) 89.06(↓ 0.71%)\\n표 6.3은 전처리 기법 적용 여부에 따른 평균 응답 성능 증감률을 나타낸다.\\n6.3.1부터 6.3.5까지의 실험 결과와 표 6.3을 종합하면, 전처리 기법을\\n적용하지 않은 JSON 형식의 표 데이터보다 자연어로 변환한 전처리 기법을\\n- 58 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 69, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='적용한 말뭉치를 사용할 때 질의응답 성능이 향상됨을 알 수 있다. 이는 거\\n대언어모델이 구조화된 데이터보다 자연어 형태의 텍스트를 처리할 때 더\\n높은 성능을 보인다는 것을 시사한다.\\n청크 및 오버랩 크기 조정에 따른 실험 결과를 분석한 결과, 전처리 기법\\n을 적용하지 않은 경우 청크 크기가 커지거나 오버랩 크기가 적절하지 않으\\n면 성능 변동 폭이 크게 나타났다. 이는 질문에 필요한 모든 정보를 포함하\\n지 못하거나, 청크가 커질수록 중요도가 낮은 정보가 포함되어 작화 및 환\\n각 현상이 발생한 것으로 분석된다.\\n반면, 전처리 기법을 적용했을 때는 전반적으로 전처리 기법을 적용하지\\n않았을 때보다 성능이 안정적이다. 그러나 구분자 기반 전처리 기법은 청크\\n크기와 오버랩 크기에 따라 여전히 변동 폭이 비교적 크게 발생하며, 이는\\n문서 분할 과정에서 중요한 정보가 청크 내에 포함되지 않거나 오버랩 설정\\n에 따라 문맥 단절로 발생하는 문제로 보인다. 한국어 조사 체계 기반 전처\\n리 기법은 열의 정보를 문장으로 변환하여 정보 단절 문제를 완화하였기 때\\n문에, 청크 및 오버랩 크기 조정에 따른 응답 성능 변동 폭이 상대적으로\\n작으며, 모든 실험 조건과 평가 방식에서 높은 성능을 유지한다.\\n본 실험 결과에서 BLEU, ROUGE, METEOR 그리고 Sem Score 모두\\n전처리 기법을 적용했을 때 성능이 증가하였다. Sem Score는 오답임에도\\n불구하고 의미적 유사도가 높게 나타나는 문제가 발견되었다. 이는 거대언\\n어모델이 작화 또는 환각 현상으로 잘못된 응답을 생성했을 때 치명적이므\\n로, 질의응답 시스템 평가에는 적합하지 않다고 판단된다.\\n이러한 문제를 개선하기 위해 GPT Score의 21개 평가 측면 중 표 질의\\n응답에 우선적으로 고려해야 할 9개 측면을 채택하였다. 각 평가 측면의 정\\n의와 G-Eval 방식을 결합해 평가 기준과 단계를 명확하게 설계한 뒤, 이를\\n프롬프트로 거대언어모델에 전달함으로써 일관된 평가가 이루어지도록 하였\\n다. 이를 통해 앞서 언급한 Sem Score의 문제점이 개선된 것을 확인하였다.\\nGPT Score와 G-Eval 방식을 결합하여 측정한 결과, 유창성(Fluency)과\\n이해 가능성(Understandability) 측면의 성능이 전처리 기법을 적용하지 않\\n았을 때보다 소폭 감소한 결과를 보인다. 앞서 언급한 바와 같이, 거대언어\\n- 59 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 70, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='모델이 생성한 응답은 질문에 대한 특정 데이터를 정확하게 추출하여 언급\\n하였으나, 참조 응답처럼 다양한 표현을 사용하여 문장을 생성하지는 않은\\n것으로 확인되었다. 따라서 해당 실험 결과를 기반으로 이 평가 측면들은\\n특정 데이터를 정확하게 추출하고 이를 문장으로 구성해야 하는 표 질의응\\n답에서는 필수적인 평가 측면이 아니라고 판단된다. 따라서 향후 연구에서\\n는 해당 평가 측면을 제외한 7개 평가 측면으로 평가하고자 한다.\\n6.3.6.2 Gemma\\n<표 6.4> Gemma 2 it 9B - 전처리 기법 적용 여부에 따른 평균 응답 성능 증감률\\n증감률(%)\\n평가 방식 기본 한국어 조사\\n구분자\\n(Baseline) 체계\\nBLEU 0.205 0.241(↑ 17.56%) 0.243(↑ 18.54%)\\n1 0.291 0.322(↑ 10.65%) 0.318(↑ 9.28%)\\nROUGE 2 0.138 0.16(↑ 15.94%) 0.16(↑ 15.94%)\\nL 0.228 0.255(↑ 11.84%) 0.257(↑ 12.72%)\\nMETEOR 0.226 0.263(↑ 16.37%) 0.262(↑ 15.93%)\\nSem Score 0.755 0.776(↑ 2.78%) 0.776(↑ 2.78%)\\nFactuality 52.113 55.973(↑ 7.41%) 55.34(↑ 6.19%)\\nConsistency 49.947 53.667(↑ 7.45%) 53.193(↑ 6.50%)\\nRelevance 70.52 74.067(↑ 5.03%) 73.513(↑ 4.24%)\\nFluency 85.68 86.7(↑ 1.19%) 86.593(↑ 1.07%)\\nGPT Score Coherence 74.047 75.953(↑ 2.57%) 75.567(↑ 2.05%)\\n+ Accuracy 52.033 55.92(↑ 7.47%) 55.227(↑ 6.14%)\\nG-Eval\\nMultidimensional\\n54.293 58.54(↑ 7.82%) 57.4(↑ 5.72%)\\nQuality\\nSemantic\\n64.347 67.353(↑ 4.67%) 66.907(↑ 3.98%)\\nAppropriateness\\nUnderstandability 84.333 85.167(↑ 0.99%) 85.513(↑ 1.40%)\\n- 60 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 71, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='표 6.4는 Gemma 2 it 9B 모델에서 전처리 기법 적용 여부에 따른 평균\\n응답 성능 증감률이다.\\n실험 결과를 분석한 결과, Gemma 2 it 9B는 GPT 4o mini와 달리 다수\\n의 평가 측면에서 청크 크기가 2,500 이상일 때 성능이 급격히 저하되는\\n현상을 보였다. 이러한 현상은 전처리 기법 적용 여부와 상관없이 나타났으\\n며, 이는 매개변수가 적은 언어모델의 낮은 제로샷(Zero-Shot) 성능과 청크\\n크기 증가로 인한 중요도가 낮은 정보의 과도한 포함으로 발생하는 작화 및\\n환각 현상이 복합적으로 작용한 결과로 해석된다. 또한, 유창성과 이해 가능\\n성 측면에서 GPT 4o mini와는 달리 성능이 소폭 증가하였다. 생성된 응답\\n은 문장 구성은 참조 응답처럼 잘 구성되어 있어 유창성과 이해 가능성 측\\n면에서는 높은 점수를 받았지만, 특정 셀 값을 기반으로 정확한 응답을 생\\n성하는 것이 핵심인 사실성과 같은 다른 측면에서는 낮은 점수를 받은 응답\\n들이 존재하였다. 이러한 이유로 전체적인 평균 성능이 소폭 증가한 것으로\\n해석된다.\\n이러한 분석을 통해 앞서 언급한 GPT 4o mini 결과와 마찬가지로, 유창\\n성과 이해 가능성 평가 측면은 표 질의응답을 평가할 때 필수적인 요소가\\n아니라고 판단되므로 향후 연구에서는 해당 평가 측면들을 제외하고 평가를\\n진행할 예정이다.\\n- 61 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 72, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='7. 결론 및 향후 연구\\n본 논문에서는 거대언어모델이 표 데이터와 같은 정형화된 데이터에서 낮\\n은 성능을 보이는 문제를 개선하기 위해, 표 데이터를 자연어로 변환하는\\n전처리 방법론과 전처리 기법을 제안한다. 전처리 방법론은 표 데이터를 정\\n제 카테고리에 따라 분류하고, 표 데이터를 표 속성 깊이에 따라 JSON 형\\n식으로 일관되게 변환할 수 있도록 하는 것이다. 이 방법론을 기반으로 표\\n데이터를 자연어로 변환하는 두 가지 전처리 기법을 제안한다. 첫 번째 전\\n처리 기법인 구분자 기반 전처리 기법은 \\'/\\'를 사용하여 표 속성을 구분하\\n고, 하위 속성은 중괄호 또는 대괄호로 묶어 표 구조를 자연어로 변환하는\\n기법이다. 두 번째는 한국어 조사 체계 기반 전처리 기법이다. 이 전처리 기\\n법은 표 제목에 장소나 출발점을 나타내는 부사격 조사 \"~에서\"를, 표 속성\\n에는 명사 뒤에 붙어 주어임을 나타내는 주격 조사 \"~은\"을, 표 속성 깊이를\\n표현하기 위해 명사 뒤에 붙어 소유나 관계를 나타내는 관형격 조사 \"~의\"를, 마\\n지막으로 명사 뒤에 붙어 그 명사의 의미를 설명하는 서술격 조사 \"~이다\"를\\n사용하여 표의 열(Row) 값을 하나의 문장으로 변환하는 기법이다. 그리고\\n이러한 전처리 방법론과 전처리 기법을 통해 구축된 말뭉치로, 거대언어모델\\n기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법을 제안한다.\\n본 실험에서는 전처리 기법을 적용하지 않은 말뭉치, 구분자 기반 전처리\\n기법을 적용한 말뭉치, 그리고 한국어 조사 체계 기반 전처리 기법을 적용한\\n말뭉치 등 세 종류를 대상으로 청크 및 오버랩 크기를 조정하여 응답을 생성\\n하였다. 성능 평가는 언어모델을 사용하지 않는 BLEU, ROUGE, METEOR\\n와 언어모델을 활용하는 Sem Score, GPT Score, G-Eval을 통해 진행하였\\n다. 특히 GPT Score에서는 21개 평가 측면 중 표 질의응답에서 핵심인 사\\n실성, 관련성, 정확성 등 9개 항목을 우선적으로 채택하였고, 여기에 거대언\\n어모델에 일관된 평가 기준과 단계를 프롬프트로 제공하는 G-Eval 방식을\\n결합하여, 총 100개의 질문-응답 쌍을 기반으로 평가를 수행하였다.\\n실험 결과, GPT 4o mini와 Gemma 2 it 9B 모델 모두 전처리 기법을\\n적용하지 않은 말뭉치보다 전처리 기법을 적용한 말뭉치를 사용할 때 질의\\n응답 성능이 향상된 결과를 보인다. 이는 거대언어모델이 구조화된 데이터\\n- 62 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 73, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='보다는 자연어 형태의 말뭉치를 처리할 때 더 높은 성능을 보인다는 점을\\n시사한다. 한편, GPT Score와 G-Eval을 결합한 평가 지표를 통해 분석한\\n결과, GPT 4o mini 모델은 전처리 기법을 적용했을 때 실제로 표 특정 셀\\n에 대한 정확한 응답을 생성했음에도 불구하고, 유창성과 이해 가능성 측면\\n에서의 평가 점수가 소폭 감소하였다. 이는 참조 응답처럼 자연스럽게 문장\\n을 구성하지 않아 해당 항목의 점수가 낮아진 것으로 보이며, 따라서 유창\\n성과 이해 가능성은 표 질의응답 정확도 성능을 우선적으로 평가하는 요소\\n로서 적절치 않다고 판단되어 향후 실험에서는 유창성과 이해 가능성 평가\\n측면을 제외한 총 7개의 측면을 평가할 계획이다.\\n종합적으로 분석한 결과, 전처리 기법을 적용하지 않은 경우에는 청크 및\\n오버랩 크기 조정에 따라 성능 변동 폭이 크게 나타났다. 구분자 기반 전처\\n리 기법을 적용했을 경우, 전체적인 성능이 높아졌으며 특정 청크 및 오버\\n랩 크기 조합에서 최고 성능을 보였다. 그러나, 여전히 청크 및 오버랩 크기\\n조정에 따라 성능이 크게 변동하는 경향을 보인다. 이는 말뭉치가 변경되었\\n을 때 성능이 잘 나오는 초매개변수 조합을 찾는 실험을 추가로 진행해야\\n할 가능성이 존재한다. 한편, 한국어 조사 체계 기반 전처리 기법을 사용하\\n면 모든 평가 방식에서 높은 성능을 보이며, 청크 및 오버랩 크기 조정에\\n대해서도 높은 성능을 강건하게 유지하는 결과를 보였다. 따라서 말뭉치가\\n변경되더라도 별도의 초매개변수 조합을 찾는 실험 없이 기본적으로 높은\\n정확도를 유지할 수 있을 것으로 기대된다.\\n향후 연구에서는 한국어 조사 체계 기반 전처리 기법을 고도화하여 상황\\n에 더 적절하고 자연스러운 한국어 문장을 생성하고, 다양한 한국어 조사를\\n통해 거대언어모델이 표 데이터에서 높은 성능을 보이도록 전처리 기법을\\n개선할 계획이다. 나아가 다양한 도메인의 표 데이터를 수집한 후 평가함으\\n로써 전처리 기법의 일반화 여부를 추가로 실험할 예정이다.\\n- 63 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 74, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='8. 부록\\n# GPTScore Prompt Template\\n## Factuality\\nEvaluate Factuality in the Generated Response\\nYou will be given a source text and a generated response. Your\\ntask is to evaluate the factuality of the generated response by\\ncomparing it to the source text.\\n**Evaluation Criteria**:\\n- Factuality (1-5): Does the generated response accurately reflect\\nthe factual statements found in the source text? A score of 1\\nmeans that the response contains multiple inaccuracies or\\nfabricated information, while a score of 5 means that the response\\nis entirely accurate and preserves all factual details from the\\nsource text.\\n**Evaluation Steps**:\\n1. Carefully read the source text to identify key factual\\nstatements and details.\\n2. Review the generated response and compare it to the source\\ntext, focusing on the accuracy and integrity of the facts\\npresented.\\n3. Assign a score for factuality on a scale of 1 to 5 based on the\\nEvaluation Criteria.\\n**Important**: Ensure that all responses, including explanations\\nand scores, are generated in Korean.\\n<표 A> 평가 프롬프트 예시\\n- 64 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 75, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='# GPTScore Prompt Template\\n## Output Score\\n**Example**:\\nQuestion:\\n{question}\\nSource Text:\\n{source_text}\\nGenerated Response:\\n{generated_response}\\n1. Factuality Score (1-5):\\n2. Consistency Score (1-5):\\n3. Relevance Score (1-5):\\n4. Fluency Score (1-5):\\n5. Coherence Score (1-5):\\n6. Accuracy Score (1-5):\\n7. Multidimensional Quality Score (1-5):\\n8. Semantic Appropriateness Score (1-5):\\n9. Understandability Score (1-5):\\n{{\\n\"Factuality Score\": 4,\\n\"Consistency Score\": 3,\\n\"Relevance Score\": 5,\\n\"Fluency Score\": 4,\\n\"Coherence Score\": 4,\\n\"Accuracy Score\": 4,\\n\"Multidimensional Quality Score\": 4,\\n\"Semantic Appropriateness Score\": 4,\\n\"Understandability Score\": 4\\n}}\\n<표 B> 평가 출력 형식 유도 프롬프트 예시\\n- 65 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 76, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='9. 참고문헌\\n[1] J. M. Shin, J. W. Lee, K. M. Kim, T. M. Lee, S. M. Ahn, J. B.\\nPark and H. S. Lim, “QA Pair Passage RAG-based LLM Korean\\nchatbot service,” In Proceedings of the 35th Annual Conference\\non Human & Cognitive Language Technology for Korean\\nInstitute of Information Scientists and Engineers, Jeju Saemaul\\nKumgo Training Center, pp. 683-689, 2023.\\n[2] J. M. Shin, S. R. Park, H. R. Kim and J. H. Lee, “Search-based\\nGeneration Techniques for Enhancing LLM Responses: A\\nComparative Study of GPT3.5 and GPT4 in Zero-shot and RAG,”\\nIn Proceedings of the Spring Conference of the Korea Institute\\nof Information and Communication Engineering, Hankyung\\nNational University Anseong Campus, pp. 350-352, 2023.\\n[3] H. J. Jin, J. E. Lee, and S. H. Park, \"Research Trends in\\nRetrieval Augmented Generation and Vector Database\\nOptimization for Artificial Intelligence Chatbots,\"\\nCommunications of the Korean Institute of Information\\nScientists and Engineers, vol. 42, no. 3, pp. 8-15, Mar. 2024.\\n[4] J. J. Nam, T. H. Lee, S. Y. Wang, and W. J. Kim, \"RGQA:\\nLeveraging Reasoning Guideline with LLM-based KGQA,\"\\nJournal of Intelligence and Information Systems, vol. 30, no. 2,\\npp. 225-237, Jun. 2024. DOI: 10.13088/jiis.2024.30.2.225.\\n[5] S. H. Cho, M. S. Jung, J. H. Lee, and H. C. Kwon,\\n“Generalization Performance of Table Question Answering\\nUsing Domain-Specific Data with Small LLM,” In Proceedings\\nof the 36th Annual Conference on Human and Cognitive\\nLanguage Technology, pp. 555-559(2024).\\n[6] S. Z. Oh, Y. K. Kho, Y. K. Lee, and P. S. Kang, “KOreaPAS:\\nTAPAS based Korean-Specific Table Question Answering Model,”\\n- 66 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 77, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='Journal of the Korean Institute of Industrial Engineers, vol. 49,\\nno. 6, pp. 502-513, 2023, doi: 10.7232/JKIIE.2023.49.6.502.\\n[7] N. R. Tom, B. Brown, B. Mann, et al., \"Language models are\\nfew-shot learners,\" arXiv preprint arXiv:2005.14165, Jul. 2020.\\nDOI: 10.48550/arXiv.2005.14165.\\n[8] A. Dubey, A. Jauhri, A. Pandey, et al., “The Llama 3 Herd of\\nModels,” arXiv preprint arXiv:2407.21783, Aug. 2024. DOI:\\n10.48550/arXiv.2407.21783.\\n[9] M. Riviere, S. Pathak, P. G. Sessa, et al., “Gemma 2: Improving\\nOpen Language Models at a Practical Size,” arXiv preprint\\narXiv:2408.00118, Oct. 2024. DOI: 10.48550/arXiv.2408.00118.\\n[10] A. Yang, B. Yang, B. Hui, et al., “Qwen2 Technical Report,” arXiv\\npreprint arXiv:2407.10671, Sep. 2024. DOI: 10.48550/arXiv.2407.10671.\\n[11] A. Q. Jiang, A. Sablayrolles, A. Mensch, et al., “Mistral 7B,” arXiv\\npreprint arXiv:2310.06825, Oct. 2023. DOI: 10.48550/arXiv.2310.06825.\\n[12] M. Abdin, J. Aneja, H. Awadalla, et al., “Phi-3 Technical\\nReport: A Highly Capable Language Model Locally on Your\\nPhone,” arXiv preprint arXiv:2404.14219, Aug. 2024. DOI:\\n10.48550/arXiv.2404.14219.\\n[13] M. S. Jung, S. J. Park, J. J. Bae, Y. H. Park, and J. H. Lee,\\n“Table Attribute Depth-Based Preprocessing Technique to\\nImprove the Recognition Rate of Table Data in Large Language\\nModel,” In Proceedings of the Spring Conference of the Korea\\nInstitute of Information and Communication Engineering,\\nIncheon Songdo ConvensiA Center, pp. 473-475, 2024.\\n[14] M. S. Jung, S. J. Park, J. J. Bae, Y. H. Park, and J. H. Lee,\\n“Question-and-Answer System Based on Large Language Model\\nUsing LangChain,” In Proceedings of the Spring Conference of the\\nKorea Institute of Information and Communication Engineering,\\n- 67 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 78, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='Incheon Songdo ConvensiA Center, pp. 330-332, 2024.\\n[15] J. Roh, and K. Bae, \"Research Trends on Enhancing the Reliability of\\nGenerative Models,\" Communications of the Korean Institute of\\nInformation Scientists and Engineers, vol. 42, no. 4, pp. 13-18, Apr. 2024.\\n[16] H. Y. Joo, H. Oh, and J. Yang, \"A Survey on Open Source based\\nLarge Language Models,\" Journal of Korea Institute of Information,\\nElectronics, and Communication Technology, vol. 16, no. 4, pp.\\n193-202, Aug. 2023. DOI: 10.17661/jkiiect.2023.16.4.193.\\n[17] P. Lewis, E. Perez, A. Karpukhin, V. Goyal, H. Küttler, M. Lewis,\\nW. Yih, T. Rocktäschel, S. Riedel, and D. Kiela, “Retrieval-Augmented\\nGeneration for Knowledge-Intensive NLP Tasks,” arXiv preprint\\narXiv:2005.11401, May. 2020. DOI: 10.48550/arXiv.2005.11401.\\n[18] A. Fortino, and Z. Yang, “Evaluating Large Language Model\\nAccuracy in Structured Academic Settings: Three Case Studies,”\\n2024 IEEE Integrated STEM Education Conference (ISEC), Princeton,\\nNJ, USA, 2024, pp. 1-7, DOI: 10.1109/ISEC61299.2024.10665280.\\n[19] F. Zhu, et al. “TAT-QA: A question answering benchmark on\\na hybrid of tabular and textual content in finance,” Proceedings\\nof the 59th Annual Meeting of the Association for\\nComputational Linguistics 2021, pp.3277-3287, 2021.\\n[20] W. Chen, et al. \"Open question answering over tables and\\ntext,\" arXiv preprint arXiv:2010.10439, 2020.\\n[21] H. M. Jung, M. S. Sim, K. K. Min, J. Y. Choi, M. J. Park, and J.\\nK. Choi, “Header Text Generation based on Structural Information\\nof Table,” In Proceedings of the 35th Annual Conference on\\nHuman and Cognitive Language Technology, pp. 415-418(2023).\\n[22] C. H. Kim, S. H. Kim, and T. E. Kim, “Learning Strategies to\\nImprove Table Understanding and Explanation in Korean,” In\\nProceedings of the 36th Annual Conference on Human and\\n- 68 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 79, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='Cognitive Language Technology, pp. 635-640(2024).\\n[23] T. Y. Kwack, J. S. Kim, K. Y. Jung, D. G. Lee, and H. S.\\nPark, “Tabular-TX: Theme-Explanation Structure-based Table\\nSummarization via In-Context Learning,” In Proceedings of the\\n36th Annual Conference on Human and Cognitive Language\\nTechnology, pp. 623-628(2024).\\n[24] Z. Wang, H. Zhang, C.-L. Li, J. M. Eisenschlos, V. Perot, Z.\\nWang, L. Miculicich, Y. Fujii, J. Shang, C.-Y. Lee, and T.\\nPfister, “Chain-of-table: Evolving tables in the reasoning chain\\nfor table understanding,” The Twelfth International Conference\\non Learning Representations, 2024.\\n[25] J. Wei, X. Wang, D. Schuurmans, M. Bosma, B. Ichter, F. Xia,\\nE. H. Chi, Q. V. Le, and D. Zhou, “Chain-ofthought prompting\\nelicits reasoning in large language models,” Advances in Neural\\nInformation Processing Systems 35, 2022.\\n[26] K. Papineni, S. Roukos, T. Ward, and W. J. Zhu, “BLEU: a\\nmethod for automatic evaluation of machine translation,” in\\nProceedings of the 40th Annual Meeting of the Association for\\nComputational Linguistics, pp. 311–318, 2002.\\n[27] C. Y, Lin, “ROUGE: A package for automatic evaluation of\\nsummaries,” Text Summarization Branches Out: Proceedings of\\nthe ACL-04 Workshop, vol. 8, pp. 74–81, 2004.\\n[28] A. Lavie and A. Agarwal, “METEOR: An automatic metric for\\nMT evaluation with improved correlation with human\\njudgments,” in Proceedings of the ACL Workshop on Intrinsic\\nand Extrinsic Evaluation Measures for Machine Translation\\nand/or Summarization, pp. 65–72, 2007.\\n[29] A. Aynetdinov, and A. Akbik, “SEMSCORE: Automated\\nEvaluation of Instruction-Tuned LLMs based on Semantic\\nTextual Similarity,” arXiv preprint arXiv:2401.17072, Feb. 2024.\\n- 69 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 80, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='DOI: 10.48550/arXiv.2401.17072.\\n[30] J. L. Fu, S. K. Ng, Z. B. Jiang, and P. F. Liu, \"GPTScore:\\nEvaluate as You Desire,\" arXiv preprint arXiv:2302.04166, Feb.\\n2023. DOI: 10.48550/arXiv.2302.04166.\\n[31] Y. Liu, D. Iter, Y. Xu, S. Wang, R. Xu, and C. Zhu, \"G-Eval: NLG\\nEvaluation using GPT-4 with Better Human Alignment,\" arXiv preprint\\narXiv:2303.16634, May. 2023. DOI: 10.48550/arXiv.2303.16634.\\n[32] L. Zheng, W. L. Chiang, et al., \"Judging LLM-as-a-Judge with\\nMT-Bench and Chatbot Arena,\" arXiv preprint\\narXiv:2306.05685, Dec. 2023. DOI: 10.48550/arXiv.2306.05685.\\n[33] M. S. Jung, and J. H. Lee, “Performance Comparison of\\nEnsemble Retrieval Techniques in Question and Answer (QnA)\\nSystems Based on Ratio Adjustment”, In Proceedings of the\\n2024 Artificial Intelligence and Applications Workshop of the\\nKorea Institute of Information and Communication Engineering,\\nBusan Haeundae Benikea, pp. 31-32, 2024.\\n[34] M. S. Jung, and J. H. Lee, “Performance Comparison of BM25\\nand BM42 in RAG System”, In Proceedings of the 2024\\nArtificial Intelligence and Applications Workshop of the Korea\\nInstitute of Information and Communication Engineering, Busan\\nHaeundae Benikea, pp. 45-46, 2024.\\n[35] M. S. Jung, S. H. Cho, and J. H. Lee, “Performance\\nComparison of Korean Part-of-Speech Taggers in\\nRetrieval-Augmented Generation (RAG)”, In Proceedings of the\\n2024 Artificial Intelligence and Applications Workshop of the\\nKorea Institute of Information and Communication Engineering,\\nBusan Haeundae Benikea, pp. 29-30, 2024.\\n[36] M. S. Jung, and J. H. Lee, “Response Evaluation of a\\nRetrieval-Augmented Generation (RAG) Question-Answering System\\nBased on Table Data Using GPTScore,” In Proceedings of the Fall\\n- 70 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 81, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='Conference of the Korea Institute of Information and Communication\\nEngineering, Inje University Gimhae Campus, pp. 89-91, 2024.\\n[37] M. S. Jung, and J. H. Lee, \"Optimal Hyperparameter\\nCombination for Improving Table Data Recognition Rate in\\nLarge Language Model based Retrieval-Augmented Generation\\nSystems,\" Journal of the Korea Institute of Information and\\nCommunication Engineering, vol. 28, no. 11, pp. 1282-1290, 2024.\\n(http://doi.org/10.6109/jkiice.2024.28.11.1282)\\n[38] National Institute of Korean Language, “국립국어원 언어정보 나\\n눔터,” https://kli.korean.go.kr, accessed: Sep. 12, 2024.\\n[39] A. P. Parikh, X. Wang, S. Gehrmann, M. Faruqui, B. Dhingra,\\nD. Yang, and D. Das, “Totto: A controlled table-to-text\\ngeneration dataset,” arXiv preprint arXiv:2004.14373, 2020.\\nDOI: 10.48550/arXiv.2004.14373.\\n[40] C. W. Jun, J. Y. Choi, M. S. Sim, H. Kim, H. S. Jang, and K.\\nK. Min, “Korean-Specific Dataset for Table Question\\nAnswering”, arXiv preprint arXiv:2201.06223v2, May. 2022.\\nDOI: 10.48550/arXiv.2201.06223.\\n[41] D. K. Kim, B. W. Kim, D. G. Han, and M. E. Predli,\\n“AutoRAG: Automated Framework for optimization of Retrieval\\nAugmented Generation Pipeline,” arXiv preprint\\narXiv:2410.20878, Oct. 2024. DOI: 10.48550/arXiv.2410.20878.\\n[42] AutoRAG, “AutoRAG-example-tokenizer-benchmark,”\\nhttps://github.com/Marker-Inc-Korea/AutoRAG-example-tokenize\\nr-benchmark, accessed: Sep. 12, 2024.\\n[43] OpenAI, “New embedding models and API updates,”\\nhttps://openai.com/index/new-embedding-models-and-api-update\\ns, accessed: Mar. 11, 2024.\\n[44] LM Studio, “LM Studio,” https://lmstudio.ai/, accessed: Mar. 11, 2024.\\n- 71 -\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 82, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='A Preprocessing Technique to Enhance Table\\nData Understanding in LLM-based\\nQuestion-Answering Systems\\nMin-su Jung\\nDept. of Computer Software Engineering, Graduate School,\\nDong Eui University\\nAbstract\\nLarge Language Models (LLMs) exhibit high performance in\\nprocessing unstructured data such as natural language but face\\nperformance degradation when handling structured data like tables.\\nIt\\'s challenging to fully comprehend the meaning of table data based\\nsolely on individual cell values; accurate understanding requires\\ninterpreting the relationships between rows and columns within the\\ncontext of the entire table. In this paper, we propose a\\npreprocessing technique that converts table data into natural language\\nto enhance the table data processing performance of LLMs.\\nFirst, the delimiter-based table attribute depth preprocessing\\ntechnique uses delimiters according to the depth of attributes and\\ngroups nested attributes with brackets to represent hierarchical\\nstructures. Second, the Korean case particle-based table attribute\\ndepth preprocessing technique converts table data into complete\\nnatural language sentences by applying the adverbial case particle \"~\\n에서\" (meaning \"from\" or \"at\") to table titles, attaching the nominative\\n'), Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 83, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='case particle \"~은\" (which indicates the subject) to attributes to\\ndesignate them as subjects, and adding the copula \"~이다\" (meaning\\n\"is\") to cell values to describe the meaning of the noun.\\nUtilizing corpora built with these preprocessing techniques, we\\nimplemented a search-augmented generation-based\\nquestion-answering system and conducted experiments using the GPT\\n4o mini and Gemma 2 it 9B LLMs. The evaluation dataset consisted\\nof 100 question-answer pairs related to table data. We analyzed\\nperformance changes by varying chunk sizes and overlap sizes.\\nResponse performance was evaluated using metrics such as BLEU,\\nMETEOR, ROUGE, Sem Score, GPT Score, and G-Eval.\\nThe experimental results showed that applying the two proposed\\npreprocessing techniques led to higher performance compared to\\nusing table data in JSON format without preprocessing. Notably, the\\nKorean case particle-based preprocessing technique demonstrated\\nsuperior performance across all evaluation metrics and exhibited\\nrobust results despite changes in chunk and overlap sizes. This\\nsuggests that LLMs process data more efficiently when it is\\npreprocessed into a natural language format.\\nTherefore, employing corpora constructed with the Korean case\\nparticle-based preprocessing technique for question-answering can\\nmaintain high performance in search-augmented generation\\nquestion-answering systems while reducing sensitivity to\\nhyperparameter adjustments. Future research will focus on refining\\nthis preprocessing technique to generate context-appropriate and\\nnatural Korean sentences and enhancing LLM performance through\\nthe utilization of various case particles.\\n')]\n"]}]},{"cell_type":"code","source":["print(len(docs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SE17kbi2KR_N","executionInfo":{"status":"ok","timestamp":1751799186615,"user_tz":-540,"elapsed":13,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"0a5d07ee-b614-4614-be1d-cd0bc4e8e5e0"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["84\n"]}]},{"cell_type":"code","source":["docs[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HJOiZx0Bxv00","executionInfo":{"status":"ok","timestamp":1751799186620,"user_tz":-540,"elapsed":4,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"b6e4e537-1718-48f6-d057-ed8f5cb3bc95"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 0, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='공 학 석 사 학 위 논 문\\n거대언어모델(LLM) 기반 질의응답\\n시스템의 표 데이터 이해도를\\n높이는 전처리 기법\\n지 도 교 수 박 유 현\\n공 동 지 도 교 수 이 정 훈\\n2025년 2월\\n동 의 대 학 교 대 학 원\\n컴 퓨 터 소 프 트 웨 어 공 학 과\\n정 민 수\\n')"]},"metadata":{},"execution_count":13}]},{"cell_type":"code","source":["print(type(docs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AMH7iBO8xqa_","executionInfo":{"status":"ok","timestamp":1751799186626,"user_tz":-540,"elapsed":5,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"d646aea3-1c92-45dd-8b5b-aad3e0ab03cd"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'list'>\n"]}]},{"cell_type":"markdown","source":["### 문서 분할"],"metadata":{"id":"R9dU3xU5KavQ"}},{"cell_type":"markdown","source":["#### 한국어 형태소 단위"],"metadata":{"id":"ClEl_JSSMRxi"}},{"cell_type":"code","source":["!python3 -m pip install konlpy"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iqfJakClwCsU","executionInfo":{"status":"ok","timestamp":1751799198215,"user_tz":-540,"elapsed":4848,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"b60e0e18-8eac-4ace-d064-084beb63f782"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting konlpy\n","  Downloading konlpy-0.6.0-py2.py3-none-any.whl.metadata (1.9 kB)\n","Collecting JPype1>=0.7.0 (from konlpy)\n","  Downloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.11/dist-packages (from konlpy) (5.4.0)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.11/dist-packages (from konlpy) (2.0.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from JPype1>=0.7.0->konlpy) (24.2)\n","Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/19.4 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jpype1-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (494 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m494.1/494.1 kB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: JPype1, konlpy\n","Successfully installed JPype1-1.5.2 konlpy-0.6.0\n"]}]},{"cell_type":"code","source":["from konlpy.tag import Kkma, Okt\n","\n","okt = Okt()\n","kkma = Kkma()"],"metadata":{"id":"xaDFKze-wbXN","executionInfo":{"status":"ok","timestamp":1751799200298,"user_tz":-540,"elapsed":2081,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["def len_okt(text):\n","    tokens = [token for token in okt.morphs(text)]\n","\n","    return len(tokens)"],"metadata":{"id":"DOoLvhLsMHe-","executionInfo":{"status":"ok","timestamp":1751799200301,"user_tz":-540,"elapsed":1,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["def okt_tokenize(text):\n","    return [token for token in okt.morphs(text)]"],"metadata":{"id":"jJDJGsaRX2Ae","executionInfo":{"status":"ok","timestamp":1751799200317,"user_tz":-540,"elapsed":14,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["def len_kkma(text):\n","    tokens = [token for token in kkma.morphs(text)]\n","\n","    return len(tokens)"],"metadata":{"id":"mSmb9KNdwHFk","executionInfo":{"status":"ok","timestamp":1751799200320,"user_tz":-540,"elapsed":1,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["def kkma_tokenize(text):\n","\n","    return [token for token in kkma.morphs(text)]"],"metadata":{"id":"T6KoAAlHX89x","executionInfo":{"status":"ok","timestamp":1751799200322,"user_tz":-540,"elapsed":1,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":["#### 분할기 생성"],"metadata":{"id":"zhvSU_RLMWSy"}},{"cell_type":"code","source":["from langchain_text_splitters import RecursiveCharacterTextSplitter\n","\n","# 텍스트 분할\n","text_splitter = RecursiveCharacterTextSplitter(\n","    separators=[\"\\n\\n\", \"\\n\", \" \"],\n","    chunk_size=1000,\n","    chunk_overlap=50,\n","    length_function=len_okt\n",")"],"metadata":{"id":"9j_wCAyWKgXn","executionInfo":{"status":"ok","timestamp":1751799209387,"user_tz":-540,"elapsed":58,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["texts = text_splitter.split_documents(docs)\n"],"metadata":{"id":"pDjAEj5HyyQJ","executionInfo":{"status":"ok","timestamp":1751799220209,"user_tz":-540,"elapsed":10611,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"execution_count":22,"outputs":[]},{"cell_type":"code","source":["texts[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AyxMUhPo4iws","executionInfo":{"status":"ok","timestamp":1751799220246,"user_tz":-540,"elapsed":12,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"1714d544-f9a1-43a4-c738-33d37926dc89"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Document(metadata={'source': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'file_path': '거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법.pdf', 'page': 0, 'total_pages': 84, 'CreationDate': \"D:20250106224410+09'00'\", 'Creator': 'PDF 2022 13.0.0.564', 'ModDate': \"D:20250106224430+09'00'\", 'Producer': 'PDF 2022 13.0.0.564'}, page_content='공 학 석 사 학 위 논 문\\n거대언어모델(LLM) 기반 질의응답\\n시스템의 표 데이터 이해도를\\n높이는 전처리 기법\\n지 도 교 수 박 유 현\\n공 동 지 도 교 수 이 정 훈\\n2025년 2월\\n동 의 대 학 교 대 학 원\\n컴 퓨 터 소 프 트 웨 어 공 학 과\\n정 민 수')"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["print(len(docs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t56s2Fb2LjH5","executionInfo":{"status":"ok","timestamp":1751799220246,"user_tz":-540,"elapsed":6,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"ba8d7650-b9a0-430d-8054-323dd90a7297"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["84\n"]}]},{"cell_type":"code","source":["print(len(texts))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rLgDoQbMLA_J","executionInfo":{"status":"ok","timestamp":1751799220252,"user_tz":-540,"elapsed":5,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"cbb39bef-c1f3-49e7-8129-13c4cb58476a"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["83\n"]}]},{"cell_type":"markdown","source":["### 임베딩 모델 생성"],"metadata":{"id":"qjTkqveqBTvF"}},{"cell_type":"markdown","source":["#### 허깅페이스 임베딩 모델"],"metadata":{"id":"_vcEBnigCN_2"}},{"cell_type":"code","source":["from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n","\n","model_name = \"nlpai-lab/KURE-v1\"  # 한국어 모델\n","# model_kwargs = {'device': 'cpu'}  # cpu 사용\n","model_kwargs = {'device': 'cuda'}  # gpu 사용\n","encode_kwargs = {'normalize_embeddings': True}\n","hf_embedding_model = HuggingFaceEmbeddings(\n","    model_name=model_name,\n","    model_kwargs=model_kwargs,\n","    encode_kwargs=encode_kwargs\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":466,"referenced_widgets":["d55a4dfd368e40b990f6dcfdd99289d8","f475ef1cba674ea2afcfe4e023466423","aa2e448de69a43c78aa6411902546c74","2ab73e37b32940479ea6985ed57f8587","17d58864859b49d6865b9efb0760f868","d32bbb4d46574807881b418e6b356910","e08930e8e63e4932823e1b52ad9e2ed4","1c537a19e10f480c8edcd8dae0f510b7","b711df6aca4f4b8b8a5ea0fc562087d1","231fa7a773a444d69090c21cf07c3e7c","4e7eaeff3aa24e8cb1287290864f1fb2","95bb875bf8cd4c838f4eac842726e4f8","cd4eec5186db45e3bdb94aba0ce0baab","fbac92b290f5491a834223ec1c58e4f0","05719c7d5f0a42c98fe580778910f35f","9489610210a44f369841b058e42fe7db","8876b6b590f64e37bdafcbb3d974b93e","28c2d90277354d8f99282de952fc1fec","5d6fe94e3561419d94cfd5a3c18d8f4a","dca5fed3fb4d47b8bb3498ecf29157c1","ee27f2c1b57348b68a5b340ba3c0ecac","dae8e96abf6943a8a4486853f53eadf6","9c2104c9ae414e43a74792bf093897f6","e36e0b1fadd1465fbd31592d1d55db5f","7bef92f52dec4020bc2d8c8da24343a8","01a84f219a754a9a8e0ac98478c455a2","29ff442fc0244f60a645ca375a0fabff","25cd8356c6984327b790062aea4570db","938eff52d7864d149d7ea4e1e2314114","523e8da5ee08462399304da6a646572b","dd1e8121bd5d4bf5816ad8fc53234a63","a9bc39d52bd347d18db806b0dd39f87d","e9b1672d12f94d9389f3396da3789611","1f94f392b03348d5b7a3a90a90189e4b","32293010d7584e29b5a1e435b186cdd4","f1452aa82d4249ecb94f115ee28b3b09","26544e38ad314aca8f19d5fe3280952c","43b6225ff6fa48968885f4df7696a18c","1b0895cd63ff45c6a0620208ecf09708","e6021e8f633c4317b42e75de8b7b317f","e47baab285dc44a1b6ded5239f7f0f46","a7c443c9ee6e422d81b9f69bd4c33813","9012ad287782499eb06c02b1df78ddaa","06aaf3bea78b4c1dbcdff1638d7a575f","40d5ba05a6bf4fd3b99884b5ccb6856c","45468b00689043a3b180d1811c2acd14","f2af2e521d7c4443b65678d2627ec7f6","98f64cf19bad4a079ebf6b30be869faf","08323d56341e4243aaae38876d949fbe","159b2be851a0483799e295585859fce7","6e4b12e8cf354aa2832b7e327c8fce64","2aa593034f5f492aa1fc582f4281673e","9465b61bf046416f8501e66ac68ebf3d","4539e3e971864d0fa1a645cb0fa9e35e","234edaf2fbe64afeadf7a79fa5b14c17","64b3ce222416479ebba44b7da990ed41","974f48d4a23d40db91fb90b26125f0e6","5ed90f7f919943f784b33b0c98edfce9","5fea0a53d3be4a8196bfb183eff05c54","1dda127ccacc4978973994997f611e18","7edfaabb9462433186a40d00f97305d8","a9f8a2e922e1435b85b4148591d2a916","b9d0cdc4f5ba451882861b67a6672f0d","91bcaaa6a78c41e4952d2981e8c16d26","ad0ba95b4a8c4739a838fc1de8816786","72e875e631044c5b971331c40f134f38","ccef6831aa864460b58e301e7fed1b13","650964019ff041c7a8994af4046fa2bc","f588953a5f6d486193bd7acefb2420ef","ab73a15a760842a0ab59edc899672bc7","daaf6dd95f7d49d6af20157b15c3e08f","baab81ad3e2e43d2af1cd8a7aaa1f2e7","b10f547221354b668c3b3e81107c08e9","97e7bf12318b4d8cbb8fcb9d5ceb9717","899fcb3a32d04f49b0551366d681398e","8766434cc15e458eb50135fc409ff6dc","8de6f72206a9490fab043f6e39ddd95d","4e2c9fbc0836455db8143b579a14a15a","0fd1f015aef243869e4d129edc20677c","5fb63c3b9f714c7fa31399bc331bd927","7d4a156e4dfb4844bf65a0efbd47bd28","d177f931d5214ac19227904921188833","f43164966e8c4de79d968048118942b1","fa019c4272cd442692fbd14ea104ed2a","1826db5c1b704d2996055385e07a23dc","239dcc8bcf7b4a939e58ab32bfdb642f","c42c2e7fc5a64e56ae420ace48a4981c","998894630a8943e8b39ac902ccb0263c","724bc2e8a3a34f6fbb10b3672c895d58","e97c1ccc3dbc4db79864df6fca2cb8cc","3f379e5730fd4302b78da00efcfce736","2fb031909a3f486fbc294220bd2433f5","689c03ad60714a309930c03e38a97965","abfa239b95ef4156931841445fbd1270","8879bc040be4411f9412731a48d7ecc7","547c8e890c8b44aa9e7bf7fc3c0ae84b","3cceb94973ff4bbbae9cd4201f1f4c0a","a4421f6e1ce04c2d8612e79baab81a5c","f06811329263477baf4d3a845cb3d37c","cfe1ae6f39684430ac9c3097e7c6889b","a1a81c05f1bb448e86267549f5724d10","f92a6dd6a74748a4b188ff3f9e226935","2a43654fdb4d4effa5bfbeb7204d62f3","8e7aae2b39ca4090b9e4dc819b25dd3f","d410fb28fbb443cc960d58410a068b9f","2276859db5d84bac971b14fa60015244","f6a950c843f44e4882b29b4406fd3e24","f4dfbf4c9a0d470a9ab47532624d6b6c","e58e2260db0a4c80a539779ef2365342","7dbe6553c7c144479689b61d110c96c2"]},"id":"gZmv5tq6BXUU","executionInfo":{"status":"ok","timestamp":1751799287584,"user_tz":-540,"elapsed":54851,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"6ad37132-cd78-439f-b9da-33f1c64c6f6a"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d55a4dfd368e40b990f6dcfdd99289d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config_sentence_transformers.json:   0%|          | 0.00/220 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95bb875bf8cd4c838f4eac842726e4f8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["README.md: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9c2104c9ae414e43a74792bf093897f6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["sentence_bert_config.json:   0%|          | 0.00/54.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f94f392b03348d5b7a3a90a90189e4b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/807 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40d5ba05a6bf4fd3b99884b5ccb6856c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/2.27G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64b3ce222416479ebba44b7da990ed41"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json: 0.00B [00:00, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ccef6831aa864460b58e301e7fed1b13"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e2c9fbc0836455db8143b579a14a15a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"724bc2e8a3a34f6fbb10b3672c895d58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/297 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cfe1ae6f39684430ac9c3097e7c6889b"}},"metadata":{}}]},{"cell_type":"code","source":["hf_embedding_test = hf_embedding_model.embed_query(\"안녕하세요.\")\n","\n","hf_embedding_test"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6vqgP4Q4DWjB","executionInfo":{"status":"ok","timestamp":1751799288307,"user_tz":-540,"elapsed":719,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"d7d1c54b-5dc9-47b3-c909-30360112d79c"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[-0.024604560807347298,\n"," 0.025116274133324623,\n"," -0.03335217386484146,\n"," -0.00202204124070704,\n"," -0.014855310320854187,\n"," -0.05262487009167671,\n"," -0.01889931783080101,\n"," -0.06538813561201096,\n"," 0.024237262085080147,\n"," 0.0011860248632729053,\n"," 0.00400763563811779,\n"," 0.0315011665225029,\n"," 0.016683271154761314,\n"," -0.014650936238467693,\n"," 0.02357589080929756,\n"," -0.033598393201828,\n"," 0.013595260679721832,\n"," -0.03999217972159386,\n"," 0.00567800784483552,\n"," -0.05042201653122902,\n"," -0.03937114030122757,\n"," 0.002800587099045515,\n"," -0.008931447751820087,\n"," -0.014998788945376873,\n"," 0.007617462892085314,\n"," 0.04348299279808998,\n"," -0.021915579214692116,\n"," 0.021404793485999107,\n"," 0.01784462481737137,\n"," -0.03360377252101898,\n"," 0.027148298919200897,\n"," 0.04266786202788353,\n"," -0.004230374936014414,\n"," -0.03646565601229668,\n"," -0.006372441072016954,\n"," -0.039430443197488785,\n"," -0.015058347955346107,\n"," -0.010653108358383179,\n"," -0.05758838355541229,\n"," 0.04578414559364319,\n"," 0.031237639486789703,\n"," 0.014935863204300404,\n"," 0.003296470735222101,\n"," -0.059383369982242584,\n"," 0.013401606120169163,\n"," -0.04492957890033722,\n"," -0.014995845034718513,\n"," -0.001989969750866294,\n"," 0.01570201851427555,\n"," -0.03391284495592117,\n"," 0.022216031327843666,\n"," -0.008058793842792511,\n"," 0.04683627188205719,\n"," 0.009523049928247929,\n"," -0.01266536582261324,\n"," -0.014247363433241844,\n"," -0.011590231209993362,\n"," -0.03678987920284271,\n"," -0.0344386100769043,\n"," -0.005933032371103764,\n"," -0.053911250084638596,\n"," 0.012175468727946281,\n"," -0.002497535664588213,\n"," -0.026264818385243416,\n"," -0.008672830648720264,\n"," 0.14121796190738678,\n"," 0.024333978071808815,\n"," -0.00713453209027648,\n"," -0.020316438749432564,\n"," -0.01909327507019043,\n"," -0.023369217291474342,\n"," -0.013196095824241638,\n"," -0.01282135397195816,\n"," 0.015611765906214714,\n"," -0.0575297586619854,\n"," 0.043313659727573395,\n"," 0.04355143383145332,\n"," -0.004892673809081316,\n"," -0.01205663476139307,\n"," 0.025931183248758316,\n"," 0.07582063972949982,\n"," -0.012430422939360142,\n"," 0.003176750149577856,\n"," 0.010427305474877357,\n"," 0.007686074823141098,\n"," 0.04211094602942467,\n"," -0.009128520265221596,\n"," 0.02723599411547184,\n"," -0.01853019744157791,\n"," -0.040274057537317276,\n"," -0.041041936725378036,\n"," -0.03506704419851303,\n"," 0.016798939555883408,\n"," -0.04039982706308365,\n"," -0.05463806539773941,\n"," -0.007121610455214977,\n"," -0.02147532068192959,\n"," 0.057313498109579086,\n"," -0.0005468108574859798,\n"," 0.03551065921783447,\n"," 0.03876706212759018,\n"," 0.01981012523174286,\n"," 0.013810600154101849,\n"," -0.004747449420392513,\n"," -0.023886574432253838,\n"," 0.01658402942121029,\n"," 0.03622825816273689,\n"," 0.03321526199579239,\n"," 0.027425428852438927,\n"," 0.004481685813516378,\n"," 0.03810294717550278,\n"," 0.029775461181998253,\n"," 0.012653828598558903,\n"," -0.007158883847296238,\n"," 0.017385726794600487,\n"," -0.01693151146173477,\n"," -0.0009792244527488947,\n"," -0.012459507212042809,\n"," -0.0067091044038534164,\n"," 0.002381018130108714,\n"," 0.002267226343974471,\n"," 0.0440300777554512,\n"," -0.026422062888741493,\n"," 0.011328370310366154,\n"," 0.004374399781227112,\n"," -0.022707924246788025,\n"," 0.012543534860014915,\n"," 0.03942394629120827,\n"," -0.005546168424189091,\n"," -0.030727699398994446,\n"," 0.037708815187215805,\n"," -0.011773488484323025,\n"," -0.0292974840849638,\n"," -0.00429909722879529,\n"," -0.013372823596000671,\n"," -0.05695140361785889,\n"," 0.020457416772842407,\n"," -0.018525980412960052,\n"," -0.004193771164864302,\n"," 0.0005016386858187616,\n"," 0.018079783767461777,\n"," 0.015742916613817215,\n"," 0.007399862632155418,\n"," -0.020294828340411186,\n"," 0.0200838390737772,\n"," -0.04203157126903534,\n"," 0.008600423112511635,\n"," 0.05219937860965729,\n"," 0.023182395845651627,\n"," -0.019218165427446365,\n"," 0.004903765860944986,\n"," -0.009584895335137844,\n"," 0.014945619739592075,\n"," 0.06440511345863342,\n"," 0.0029827114194631577,\n"," -0.002895100275054574,\n"," -0.03801504150032997,\n"," 0.014701923355460167,\n"," 0.0013869180111214519,\n"," 0.00021567587100435048,\n"," 0.0015036562690511346,\n"," 0.030916783958673477,\n"," -0.028566353023052216,\n"," -0.013367796316742897,\n"," -0.00326175126247108,\n"," -0.005402849987149239,\n"," 0.005311707500368357,\n"," -0.018644114956259727,\n"," 0.0004868765827268362,\n"," -0.007075151428580284,\n"," -0.005220657214522362,\n"," -0.0018557864241302013,\n"," 0.005313070956617594,\n"," -0.001229889690876007,\n"," 0.004551541525870562,\n"," 0.0037246679421514273,\n"," 0.04289346933364868,\n"," 0.020145339891314507,\n"," 0.02606246806681156,\n"," -0.03842776641249657,\n"," -0.02013823762536049,\n"," -0.03620906174182892,\n"," -0.002971873851493001,\n"," 0.002165368292480707,\n"," -0.021064480766654015,\n"," 0.0363929457962513,\n"," -0.017101475968956947,\n"," -0.029755687341094017,\n"," -0.0017133362125605345,\n"," 0.00605206610634923,\n"," -0.027107365429401398,\n"," -0.0280559454113245,\n"," 0.02293018437922001,\n"," -0.03951682150363922,\n"," 0.022441837936639786,\n"," 0.0005415191990323365,\n"," -0.0004095108015462756,\n"," 0.00021865636517759413,\n"," -0.00441190367564559,\n"," 0.0014595487155020237,\n"," 0.018430819734930992,\n"," 0.018135149031877518,\n"," -0.002819720422849059,\n"," 0.008492776192724705,\n"," -0.04631844162940979,\n"," -0.017870139330625534,\n"," -0.018277034163475037,\n"," -0.005598875228315592,\n"," 0.029757682234048843,\n"," -0.03387421742081642,\n"," -0.02613784186542034,\n"," 0.003013721201568842,\n"," 0.005329668056219816,\n"," -0.06214449554681778,\n"," -0.029575735330581665,\n"," 0.003770477371290326,\n"," -0.023466162383556366,\n"," 0.030553536489605904,\n"," 0.009780091233551502,\n"," -0.021841570734977722,\n"," -0.006343670189380646,\n"," -0.004841286223381758,\n"," 0.0014579955022782087,\n"," 0.024010365828871727,\n"," 0.011621179059147835,\n"," 0.0056524621322751045,\n"," 0.0016316449036821723,\n"," -0.0055468385107815266,\n"," 0.005353949964046478,\n"," 0.027033606544137,\n"," -0.009774521924555302,\n"," -0.00577958021312952,\n"," 0.03050816059112549,\n"," -0.028922006487846375,\n"," 0.010364694520831108,\n"," -0.03015991859138012,\n"," -0.034896381199359894,\n"," 0.00948560144752264,\n"," 0.0072771599516272545,\n"," -0.01425093412399292,\n"," -0.006377357058227062,\n"," -0.019844239577651024,\n"," 0.0008516633533872664,\n"," -0.003357731970027089,\n"," -0.03481219336390495,\n"," 0.005060484167188406,\n"," -0.012048336677253246,\n"," 0.003320937277749181,\n"," 0.019618136808276176,\n"," 0.021040644496679306,\n"," 0.004169106483459473,\n"," -0.022291937842965126,\n"," 0.014314117841422558,\n"," 0.017072396352887154,\n"," 0.051400329917669296,\n"," 0.0024325395934283733,\n"," 0.021914267912507057,\n"," 0.005182079505175352,\n"," -0.0060409558936953545,\n"," -0.01394687034189701,\n"," 0.01305162999778986,\n"," -0.06246796250343323,\n"," 0.042548324912786484,\n"," 0.05239561200141907,\n"," -0.010922434739768505,\n"," -0.003753580152988434,\n"," -0.004337907303124666,\n"," -0.021764183416962624,\n"," 0.01742091216146946,\n"," 0.023665986955165863,\n"," 0.02678324468433857,\n"," -0.04797983169555664,\n"," -0.008387062698602676,\n"," -0.018836727365851402,\n"," -0.043076250702142715,\n"," -0.009248935617506504,\n"," 0.0018875406822189689,\n"," -0.041337475180625916,\n"," 0.058443691581487656,\n"," 0.0022763703018426895,\n"," 0.029270267114043236,\n"," -0.025227027013897896,\n"," 0.013236810453236103,\n"," 0.002944526495411992,\n"," 0.019457150250673294,\n"," 0.016110066324472427,\n"," -0.05198181793093681,\n"," 0.012430408969521523,\n"," 0.040894221514463425,\n"," -0.028883537277579308,\n"," 0.015067912638187408,\n"," 0.09239586442708969,\n"," 0.02121494710445404,\n"," 0.007480486761778593,\n"," -0.0033233214635401964,\n"," -0.002339886035770178,\n"," 0.012589234858751297,\n"," -0.1342802345752716,\n"," 0.02031558007001877,\n"," 0.01768617518246174,\n"," -0.05268321558833122,\n"," -0.023530812934041023,\n"," -0.026717061176896095,\n"," -0.013087088242173195,\n"," 0.03908703848719597,\n"," 0.027810055762529373,\n"," 0.011960708536207676,\n"," 0.04247431829571724,\n"," -0.00442421855404973,\n"," -0.020441312342882156,\n"," -0.00826899241656065,\n"," -0.015550755895674229,\n"," 0.022087758406996727,\n"," 0.004621695261448622,\n"," -0.014388694427907467,\n"," 0.023994358256459236,\n"," -0.0582292340695858,\n"," -0.0099331671372056,\n"," -0.010042714886367321,\n"," 0.07457293570041656,\n"," -0.03797884285449982,\n"," 0.010910575278103352,\n"," -0.0022889883257448673,\n"," 0.02636038139462471,\n"," -0.02531702071428299,\n"," -0.07196509093046188,\n"," 0.00848864484578371,\n"," -0.04985334724187851,\n"," -0.005801867228001356,\n"," 0.008066907525062561,\n"," 0.007770885247737169,\n"," 0.003342714859172702,\n"," 0.03287779167294502,\n"," 0.006888681091368198,\n"," -0.03466842696070671,\n"," -0.014106638729572296,\n"," -0.008767509832978249,\n"," 0.02613939344882965,\n"," 0.017570998519659042,\n"," -0.004004020243883133,\n"," 0.010842319577932358,\n"," 0.019421536475419998,\n"," -0.0719195008277893,\n"," -0.007337742950767279,\n"," 0.011111297644674778,\n"," 0.03002890571951866,\n"," -0.014773234724998474,\n"," 0.019041910767555237,\n"," 0.00028824765468016267,\n"," -0.004452893044799566,\n"," -0.054694268852472305,\n"," 0.01697462797164917,\n"," 0.0013997675850987434,\n"," -0.011799097061157227,\n"," 0.031178060919046402,\n"," -0.04550449177622795,\n"," 0.007713133003562689,\n"," -0.03563157841563225,\n"," -0.06914002448320389,\n"," 0.04378608241677284,\n"," 0.00036782139795832336,\n"," -0.007868947461247444,\n"," 0.0014175238320603967,\n"," -0.006829064805060625,\n"," -0.019654812291264534,\n"," 0.021692387759685516,\n"," -0.02671353705227375,\n"," 0.027025697752833366,\n"," -0.012073234654963017,\n"," 0.00226462259888649,\n"," -0.009352006949484348,\n"," 0.008049597032368183,\n"," -0.004622841719537973,\n"," 0.020915603265166283,\n"," -0.051050230860710144,\n"," -0.0034802942536771297,\n"," -0.1311715543270111,\n"," 0.004408399574458599,\n"," -0.01813955418765545,\n"," -0.0275739636272192,\n"," 0.01200046669691801,\n"," -0.013726920820772648,\n"," 0.006438294891268015,\n"," 0.010197283700108528,\n"," 0.045651063323020935,\n"," 0.07339279353618622,\n"," 0.31404444575309753,\n"," 0.040360596030950546,\n"," 0.07630705088376999,\n"," -0.022691234946250916,\n"," 0.07930364459753036,\n"," -0.008296498097479343,\n"," -0.001364410389214754,\n"," 0.03970262408256531,\n"," -0.01712982915341854,\n"," -0.02165408805012703,\n"," -0.03384648263454437,\n"," -0.018191443756222725,\n"," -0.005438839551061392,\n"," 0.03792886808514595,\n"," -0.006253005005419254,\n"," 0.056774504482746124,\n"," -0.03885917365550995,\n"," -0.01544282678514719,\n"," 0.03838051110506058,\n"," -0.011170480400323868,\n"," 0.0032022588420659304,\n"," -0.008023150265216827,\n"," 0.00020840804791077971,\n"," -0.028196843340992928,\n"," -0.017211761325597763,\n"," -0.023526448756456375,\n"," 0.0056788260117173195,\n"," 0.03450411930680275,\n"," -0.005623215809464455,\n"," 0.010863450355827808,\n"," -0.018281495198607445,\n"," 0.028423404321074486,\n"," 0.0064941090531647205,\n"," -0.01840757206082344,\n"," -0.02973613701760769,\n"," -0.002462305361405015,\n"," 0.015030725859105587,\n"," -0.04245378077030182,\n"," -0.03410576283931732,\n"," -0.00346108665689826,\n"," -0.02255570888519287,\n"," -0.014520548284053802,\n"," 0.025679832324385643,\n"," 0.015541516244411469,\n"," 0.025381125509738922,\n"," 0.03253401070833206,\n"," 0.022953234612941742,\n"," -0.019970426335930824,\n"," -0.01113145425915718,\n"," 0.012594848871231079,\n"," -0.03230107203125954,\n"," -0.0177161768078804,\n"," 0.007070531602948904,\n"," 0.0014426372945308685,\n"," -0.03720026835799217,\n"," -0.008501147851347923,\n"," -0.01404254138469696,\n"," -0.050851766020059586,\n"," 0.01178160309791565,\n"," 0.046909064054489136,\n"," 0.023019002750515938,\n"," 0.050531055778265,\n"," -0.035873960703611374,\n"," -0.03255975618958473,\n"," -0.024577513337135315,\n"," 0.0022870502434670925,\n"," 0.013122805394232273,\n"," -0.030998962000012398,\n"," -0.008330709300935268,\n"," 0.04432343691587448,\n"," 0.009493527002632618,\n"," -0.016682785004377365,\n"," -0.013848108239471912,\n"," 0.030617309734225273,\n"," 0.015226052142679691,\n"," 0.028278985992074013,\n"," -0.009086583741009235,\n"," 0.03653910011053085,\n"," -0.018093163147568703,\n"," 0.037199486047029495,\n"," -0.019359372556209564,\n"," -0.013216814026236534,\n"," -0.02112983912229538,\n"," -0.011630630120635033,\n"," -0.0086214579641819,\n"," -0.046504002064466476,\n"," 0.015493170358240604,\n"," 0.038581885397434235,\n"," 0.0013121172087267041,\n"," -0.009747699834406376,\n"," 0.0474151186645031,\n"," -0.005564361810684204,\n"," -0.02258291095495224,\n"," 0.018116330727934837,\n"," -0.031705014407634735,\n"," -0.07017185539007187,\n"," 0.005196413490921259,\n"," -0.01396207045763731,\n"," -0.03111228160560131,\n"," 0.018375743180513382,\n"," -0.02322166971862316,\n"," -0.007154187187552452,\n"," -0.031794045120477676,\n"," 0.04047037661075592,\n"," -0.002431830856949091,\n"," -0.020441945642232895,\n"," -0.0035324126947671175,\n"," 0.02297254651784897,\n"," -0.005800653714686632,\n"," 0.039025407284498215,\n"," 0.018281301483511925,\n"," -0.027119988575577736,\n"," 0.03432628512382507,\n"," 0.0390113927423954,\n"," 0.02159249037504196,\n"," 0.018622353672981262,\n"," 0.05129512399435043,\n"," -0.018989628180861473,\n"," 0.04177605360746384,\n"," 0.00727868964895606,\n"," -0.016710901632905006,\n"," -0.034343235194683075,\n"," -0.022286083549261093,\n"," 0.04793029651045799,\n"," -0.01518605649471283,\n"," -0.013203619979321957,\n"," -0.0009810113115236163,\n"," -0.018420955166220665,\n"," -0.05235622823238373,\n"," 0.029396239668130875,\n"," 0.00828403141349554,\n"," -0.04179404675960541,\n"," -0.030575329437851906,\n"," 0.06443523615598679,\n"," 0.06939848512411118,\n"," 0.04247836023569107,\n"," 0.07080347836017609,\n"," 0.026610979810357094,\n"," -0.04080541431903839,\n"," 0.02474781684577465,\n"," -0.009862644597887993,\n"," 0.03361111506819725,\n"," -0.012983273714780807,\n"," 0.0012775975046679378,\n"," -0.0164195504039526,\n"," 0.03572589159011841,\n"," 0.0010706580942496657,\n"," -0.004315496888011694,\n"," -0.012499860487878323,\n"," -0.01198571640998125,\n"," 0.02429819479584694,\n"," 0.0012427489273250103,\n"," 0.018028823658823967,\n"," -0.05126431956887245,\n"," -0.025044655427336693,\n"," -0.00854528322815895,\n"," -0.017103228718042374,\n"," -0.003134177066385746,\n"," 0.0045129116624593735,\n"," -0.009132849983870983,\n"," -0.01857186295092106,\n"," 0.024079816415905952,\n"," 0.053146544843912125,\n"," 0.11878260970115662,\n"," 0.00018970029486808926,\n"," 0.016529617831110954,\n"," -0.009222697466611862,\n"," 0.04568757116794586,\n"," 0.00720365671440959,\n"," -0.010070115327835083,\n"," 0.007814588956534863,\n"," -0.04440214857459068,\n"," -0.02670610323548317,\n"," 0.0038372373674064875,\n"," -0.01487564854323864,\n"," -0.030435796827077866,\n"," -0.008720188401639462,\n"," -0.005106443073600531,\n"," -0.010899476706981659,\n"," 0.0007610979373566806,\n"," 0.033963873982429504,\n"," 0.005682880990207195,\n"," -0.029007909819483757,\n"," -0.008510325103998184,\n"," -0.018797190859913826,\n"," -0.013274841010570526,\n"," 0.01357475109398365,\n"," -0.009689961560070515,\n"," 0.046378735452890396,\n"," -0.045380279421806335,\n"," 0.03669694438576698,\n"," 0.051904696971178055,\n"," -0.000365866522770375,\n"," -0.036066994071006775,\n"," 0.04137587919831276,\n"," -0.03172656521201134,\n"," 0.00981045886874199,\n"," -0.0038134234491735697,\n"," -0.01645187847316265,\n"," -0.029818180948495865,\n"," -0.008190887980163097,\n"," 0.01074985135346651,\n"," 0.016890332102775574,\n"," -0.021904192864894867,\n"," -0.019867168739438057,\n"," -0.02614489197731018,\n"," -0.017516862601041794,\n"," -0.006890112068504095,\n"," -0.023810653015971184,\n"," 0.026783473789691925,\n"," -0.012940973974764347,\n"," -0.02995394356548786,\n"," -0.03036041371524334,\n"," 0.024930506944656372,\n"," -0.01817908324301243,\n"," -0.012147151865065098,\n"," 0.006060454528778791,\n"," 0.05059313774108887,\n"," -0.020127492025494576,\n"," -0.030976036563515663,\n"," 0.019825797528028488,\n"," 0.009208227507770061,\n"," 0.06484999507665634,\n"," -0.050174564123153687,\n"," 0.02179708704352379,\n"," -0.029901064932346344,\n"," 0.018668007105588913,\n"," 0.009553886018693447,\n"," -0.03560813516378403,\n"," 0.04327484592795372,\n"," -0.0018667120020836592,\n"," -0.03184458240866661,\n"," 0.03173527121543884,\n"," 0.00011844776599900797,\n"," 0.04336623474955559,\n"," -0.027260994538664818,\n"," -0.03709437698125839,\n"," 0.014595898799598217,\n"," -0.0031635987106710672,\n"," 0.011967496946454048,\n"," 0.02358139678835869,\n"," -0.004980566445738077,\n"," 0.037025902420282364,\n"," 0.02706732042133808,\n"," 0.014278378337621689,\n"," 0.02761269360780716,\n"," -0.006839626934379339,\n"," -0.03223557397723198,\n"," -0.007311738096177578,\n"," 0.02594309113919735,\n"," -0.0499819815158844,\n"," 0.009200750850141048,\n"," 0.025005090981721878,\n"," -0.03213687241077423,\n"," -0.03642881661653519,\n"," 0.031699612736701965,\n"," 0.02427615411579609,\n"," -0.009299018420279026,\n"," -0.05615215003490448,\n"," 0.04025379195809364,\n"," -0.012488231062889099,\n"," 0.05157923698425293,\n"," -0.011289164423942566,\n"," 0.018800629302859306,\n"," -0.03235097974538803,\n"," -0.0019415180431678891,\n"," 0.015773339197039604,\n"," 0.004662072751671076,\n"," -0.031082065775990486,\n"," -0.01438305713236332,\n"," 0.021684488281607628,\n"," -0.01956820674240589,\n"," 0.029910795390605927,\n"," -0.022401807829737663,\n"," 0.004285944625735283,\n"," 0.022092295810580254,\n"," -0.046842239797115326,\n"," 0.04821241274476051,\n"," -0.011387060396373272,\n"," 0.015398098155856133,\n"," -0.055901315063238144,\n"," 0.006446936633437872,\n"," -0.036615755409002304,\n"," 0.04350602626800537,\n"," -0.010575746186077595,\n"," -0.0019419229356572032,\n"," 0.0017421490047127008,\n"," 0.0019651900511235,\n"," 0.011572997085750103,\n"," -0.0014158026315271854,\n"," -0.007150983903557062,\n"," -0.03156011551618576,\n"," -0.021715352311730385,\n"," 0.05843305587768555,\n"," -0.04771231487393379,\n"," 0.0047913664020597935,\n"," -0.0029593564104288816,\n"," 0.02708709053695202,\n"," -0.04260525479912758,\n"," 0.034148089587688446,\n"," -0.012799467891454697,\n"," 0.0316937156021595,\n"," -0.020222900435328484,\n"," 0.007754607126116753,\n"," 0.004863441456109285,\n"," -0.01885763369500637,\n"," -0.018437616527080536,\n"," -0.05751771107316017,\n"," 0.028298478573560715,\n"," -0.007848885841667652,\n"," -0.03221016749739647,\n"," -0.08370926231145859,\n"," -0.011043306440114975,\n"," 0.003606145502999425,\n"," 0.04449910297989845,\n"," -0.03156677260994911,\n"," 0.02783716842532158,\n"," -0.026807840913534164,\n"," -0.010273981839418411,\n"," 0.025372272357344627,\n"," 0.00531475804746151,\n"," -0.022216401994228363,\n"," 0.0026703428011387587,\n"," -0.015433799475431442,\n"," 0.02782594785094261,\n"," 0.01126966904848814,\n"," -0.0022619576193392277,\n"," -0.013020535930991173,\n"," -0.014211860485374928,\n"," 0.013352093286812305,\n"," -0.01229583565145731,\n"," 0.012600707821547985,\n"," -0.017594093456864357,\n"," -0.008902701549232006,\n"," 0.00043492147233337164,\n"," 0.0008706212393008173,\n"," 0.06812775135040283,\n"," 0.046554166823625565,\n"," -0.017168840393424034,\n"," -0.04842425882816315,\n"," -0.04180097207427025,\n"," 0.0646209716796875,\n"," 0.0212398748844862,\n"," -0.029563046991825104,\n"," 0.01465337723493576,\n"," -0.03678729757666588,\n"," -0.001189709291793406,\n"," 0.012769777327775955,\n"," 0.025916509330272675,\n"," -0.019098397344350815,\n"," -0.006563467439264059,\n"," 0.0268162339925766,\n"," -0.03600580245256424,\n"," -0.01902311109006405,\n"," 0.02213464491069317,\n"," 0.04634351283311844,\n"," -0.04863456264138222,\n"," -0.015201998874545097,\n"," 0.005938815418630838,\n"," -0.004658452235162258,\n"," -0.04462852329015732,\n"," 0.024039672687649727,\n"," -0.03933718428015709,\n"," 0.0032758088782429695,\n"," 0.020155929028987885,\n"," 0.014514549635350704,\n"," -0.026814527809619904,\n"," 0.01724502630531788,\n"," 0.03202315419912338,\n"," 0.003791242139413953,\n"," -0.015982389450073242,\n"," 0.036212701350450516,\n"," 0.016734253615140915,\n"," -0.030607860535383224,\n"," -0.04218849539756775,\n"," 0.06777872145175934,\n"," -0.041455287486314774,\n"," -0.011798538267612457,\n"," 0.0022779800929129124,\n"," -0.01821095682680607,\n"," -0.007977520115673542,\n"," -0.06407617777585983,\n"," -0.010042554698884487,\n"," -0.03773776814341545,\n"," 0.015432924032211304,\n"," -0.024874456226825714,\n"," -0.0075073689222335815,\n"," -0.0022894765716046095,\n"," -0.00630164984613657,\n"," 0.02591560408473015,\n"," -0.029434092342853546,\n"," -0.0048791831359267235,\n"," -0.028548020869493484,\n"," 0.0064383442513644695,\n"," -0.19070646166801453,\n"," 0.010354886762797832,\n"," -0.01443627942353487,\n"," -0.02672324888408184,\n"," -0.03510791435837746,\n"," 0.014581026509404182,\n"," -0.013972289860248566,\n"," -0.0070866988971829414,\n"," 0.016520092263817787,\n"," 0.022678615525364876,\n"," -0.08435708284378052,\n"," -0.01873595453798771,\n"," 0.00588691420853138,\n"," -0.02631841041147709,\n"," 0.09251832962036133,\n"," 0.011797451414167881,\n"," 0.00037852476816624403,\n"," -0.020022837445139885,\n"," 0.011656101793050766,\n"," 0.039530251175165176,\n"," 0.020418310537934303,\n"," -0.028582023456692696,\n"," 0.04110945388674736,\n"," 0.0021182051859796047,\n"," 0.04438966140151024,\n"," -0.014311911538243294,\n"," 0.04486989974975586,\n"," 0.007566541898995638,\n"," -0.05161222070455551,\n"," 0.0036258394829928875,\n"," -0.029152903705835342,\n"," -0.04716335982084274,\n"," 0.008947161026299,\n"," -0.012077918276190758,\n"," -0.012401615269482136,\n"," 0.011183051392436028,\n"," -0.007654379587620497,\n"," -0.041643913835287094,\n"," 0.010995190590620041,\n"," 0.009489567950367928,\n"," -0.021728184074163437,\n"," -0.0003309114254079759,\n"," -0.04110803082585335,\n"," 0.0067184800282120705,\n"," -0.02060086280107498,\n"," 0.02917381562292576,\n"," 0.00688191270455718,\n"," -0.05181773751974106,\n"," -0.04993794485926628,\n"," -0.08452887833118439,\n"," 0.020510056987404823,\n"," -0.0011042405385524035,\n"," -0.007471019867807627,\n"," 0.014294823631644249,\n"," -0.003806192195042968,\n"," -0.006121912505477667,\n"," 0.005837997887283564,\n"," 0.017991334199905396,\n"," -0.02619398571550846,\n"," 0.03332795202732086,\n"," -0.029000522568821907,\n"," 0.01111666951328516,\n"," -0.0234743170440197,\n"," -0.08334483206272125,\n"," -0.07128968834877014,\n"," 0.030904240906238556,\n"," -0.034212466329336166,\n"," -0.0028412044048309326,\n"," 0.00450946856290102,\n"," -0.007387805264443159,\n"," -0.00023046991555020213,\n"," -0.053871992975473404,\n"," 0.07349564880132675,\n"," -0.012437214143574238,\n"," -0.010348538868129253,\n"," 0.031532976776361465,\n"," -0.007548375986516476,\n"," -0.03417203575372696,\n"," -0.031853776425123215,\n"," -0.043304018676280975,\n"," 0.010568268597126007,\n"," 0.008788874372839928,\n"," -0.026155363768339157,\n"," 0.02448403835296631,\n"," 0.011100532487034798,\n"," 0.007506668101996183,\n"," 0.0059648421593010426,\n"," -0.019180938601493835,\n"," -0.04436185583472252,\n"," 0.006188365630805492,\n"," -0.032235853374004364,\n"," -0.06565487384796143,\n"," -0.005400496535003185,\n"," -0.007261943072080612,\n"," -0.003790556453168392,\n"," 0.0065101878717541695,\n"," -0.017160041257739067,\n"," -0.00798293948173523,\n"," 0.0033527836203575134,\n"," 0.009587249718606472,\n"," -0.0018356424989178777,\n"," -0.019716819748282433,\n"," -0.015092180110514164,\n"," 0.006956979166716337,\n"," -0.022682227194309235,\n"," 0.013420999981462955,\n"," 0.01692904159426689,\n"," -0.017003539949655533,\n"," 0.011727267876267433,\n"," -0.02609572932124138,\n"," -0.029728660359978676,\n"," -0.014782141894102097,\n"," 0.03095378167927265,\n"," 0.00536244735121727,\n"," 0.02425771951675415,\n"," 0.008094824850559235,\n"," 0.012098398059606552,\n"," 0.012899319641292095,\n"," -0.018278339877724648,\n"," 0.043159570544958115,\n"," -0.009787684306502342,\n"," 0.009417717345058918,\n"," -0.0022645178250968456,\n"," -0.045583512634038925,\n"," -0.010089104995131493,\n"," -0.0017338229808956385,\n"," 0.02494010329246521,\n"," 0.021360037848353386,\n"," -0.018669484183192253,\n"," -0.022160395979881287,\n"," 0.02923201397061348,\n"," -0.061369746923446655,\n"," 0.04145932197570801,\n"," 0.011021781712770462,\n"," 0.011323096230626106,\n"," -0.0114294970408082,\n"," -0.041970234364271164,\n"," 0.00242819101549685,\n"," -0.05758270248770714,\n"," 0.005079321097582579,\n"," -0.01939106360077858,\n"," 0.029852816835045815,\n"," 0.0016484919469803572,\n"," -0.025911051779985428,\n"," -0.03500194102525711,\n"," -0.011507861316204071,\n"," 0.04929227754473686,\n"," 0.020513124763965607,\n"," 0.003007369115948677,\n"," -0.04675076901912689,\n"," 0.013644193299114704,\n"," 0.01760934852063656,\n"," -0.0006991209229454398,\n"," 0.013229724019765854,\n"," -0.01876705326139927,\n"," 0.010971941985189915,\n"," 0.027121486142277718,\n"," 0.012710468843579292,\n"," 0.03842335566878319,\n"," 0.016207072883844376,\n"," -0.003923369571566582,\n"," 0.015252341516315937,\n"," -0.04539388790726662,\n"," -0.040035050362348557,\n"," -0.0061080316081643105,\n"," 0.006810069549828768,\n"," -0.01550010871142149,\n"," -0.00737299770116806,\n"," -0.006485013756901026,\n"," -0.04283785820007324,\n"," 0.00799755472689867,\n"," 0.04985395446419716,\n"," -0.035918787121772766,\n"," 0.01635659486055374,\n"," 0.040151629596948624,\n"," 0.007179348263889551,\n"," 0.015630071982741356,\n"," 0.009476643055677414,\n"," 0.08999210596084595,\n"," -0.001957467058673501,\n"," 0.04597179591655731,\n"," 0.029168054461479187,\n"," 0.046912781894207,\n"," 0.016589099541306496,\n"," -0.003628508886322379,\n"," -0.02423079125583172,\n"," 1.757991049089469e-05,\n"," 0.020767197012901306,\n"," 0.01933196932077408,\n"," 0.008912891149520874,\n"," 0.0006430581561289728,\n"," 0.025732101872563362,\n"," 0.006771458312869072,\n"," -0.014236441813409328,\n"," 0.05254427716135979,\n"," 0.07739907503128052,\n"," 0.007777676917612553,\n"," 0.02987738512456417,\n"," 0.01129234116524458,\n"," 0.01398010365664959,\n"," -0.00611578393727541,\n"," -0.007129750680178404,\n"," 0.036633189767599106,\n"," -0.038141969591379166,\n"," -0.0048060547560453415,\n"," 0.06925209611654282,\n"," -0.024775059893727303,\n"," 0.04012478142976761,\n"," -0.016477053984999657,\n"," 0.02223500981926918,\n"," 0.010520021431148052,\n"," -0.029773693531751633,\n"," 0.01701313443481922,\n"," 0.04536225646734238,\n"," 0.006587580777704716,\n"," 0.041545320302248,\n"," 0.03109963983297348,\n"," -0.01994597166776657,\n"," -0.0051990048959851265,\n"," -0.006269171833992004,\n"," ...]"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["print(len(hf_embedding_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YvZlM6UTDe-F","executionInfo":{"status":"ok","timestamp":1751799288322,"user_tz":-540,"elapsed":13,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"2626a311-ebf3-41ee-8d1a-099d921a523f"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["1024\n"]}]},{"cell_type":"markdown","source":["### 문서 임베딩"],"metadata":{"id":"szkFf6-KDpt_"}},{"cell_type":"code","source":["%pwd"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"6VEmRTHNEb_D","executionInfo":{"status":"ok","timestamp":1751799290282,"user_tz":-540,"elapsed":4,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"306b0537-dd36-4b00-e9e2-1a1ee20e4a30"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content/drive/MyDrive/250707/corpus'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["%cd .."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x_cTnMmHEfz3","executionInfo":{"status":"ok","timestamp":1751799290650,"user_tz":-540,"elapsed":8,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"689087ed-2c75-4d78-d2e6-a7883afcf474"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/250707\n"]}]},{"cell_type":"code","source":["save_directory = \"./chroma_docs_db\""],"metadata":{"id":"bbk0dYf_EStn","executionInfo":{"status":"ok","timestamp":1751799291143,"user_tz":-540,"elapsed":42,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["from langchain_chroma import Chroma\n","import os\n","import shutil\n","\n","print(\"\\n잠시만 기다려주세요.\\n\\n\")\n","\n","# 벡터저장소가 이미 존재하는지 확인\n","if os.path.exists(save_directory):\n","    shutil.rmtree(save_directory)\n","    print(f\"디렉토리 {save_directory}가 삭제되었습니다.\\n\")\n","\n","print(\"문서 벡터화를 시작합니다. \")\n","db = Chroma.from_documents(docs, hf_embedding_model, persist_directory=save_directory)  # HuggingFace Embedding Model\n","# db = Chroma.from_documents(docs, oepnai_embedding_model, persist_directory=save_directory)  # OpenAI Embedding Model\n","print(\"새로운 Chroma 데이터베이스가 생성되었습니다.\\n\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QrU0f24ZDsfS","executionInfo":{"status":"ok","timestamp":1751799301266,"user_tz":-540,"elapsed":9114,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"eafc099e-2e20-4ef3-bb4f-a8897684614d"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","잠시만 기다려주세요.\n","\n","\n","문서 벡터화를 시작합니다. \n","새로운 Chroma 데이터베이스가 생성되었습니다.\n","\n"]}]},{"cell_type":"code","source":["retriever = db.as_retriever(\n","    search_kwargs={\"k\": 3},\n",")"],"metadata":{"id":"nCHsPhonGW7x","executionInfo":{"status":"ok","timestamp":1751799303570,"user_tz":-540,"elapsed":4,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["### 채팅에 사용될 거대언어모델 생성"],"metadata":{"id":"pWOF-mXwFSsA"}},{"cell_type":"code","source":["from langchain_core.prompts import ChatPromptTemplate\n","\n","prompt = ChatPromptTemplate.from_messages(\n","    [\n","        (\n","            \"system\",\n","            \"\"\"\n","You are an assistant for question-answering tasks.\n","Use the following pieces of retrieved context to answer the question.\n","If you don't know the answer, just say that you don't know.\n","\n","Answer in Korean.\n","\n","#Context:\n","{context}\n","\"\"\",\n","        ),\n","        (\"human\", \"{question}\"),\n","    ]\n",")"],"metadata":{"id":"bDUKkAAuMEEg","executionInfo":{"status":"ok","timestamp":1751799307020,"user_tz":-540,"elapsed":80,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["from langchain_google_genai import ChatGoogleGenerativeAI\n","from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n","\n","llm = ChatGoogleGenerativeAI(\n","    model=\"gemini-2.5-flash\",\n","    temperature=0,\n","    disable_streaming=True,\n","    callbacks=[StreamingStdOutCallbackHandler()],\n",")"],"metadata":{"id":"NQXhIzYdFYZX","executionInfo":{"status":"ok","timestamp":1751799308732,"user_tz":-540,"elapsed":836,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["def format_docs(docs):\n","    return \"\\n\\n\".join(document.page_content for document in docs)"],"metadata":{"id":"Cj0FFTvwSpSX","executionInfo":{"status":"ok","timestamp":1751799310235,"user_tz":-540,"elapsed":2,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n","\n","chain = {\n","    # \"context\": retriever,\n","    \"context\": retriever | RunnableLambda(format_docs),\n","    \"question\": RunnablePassthrough(),\n","} | prompt | llm | StrOutputParser()"],"metadata":{"id":"4LuC3DuIH8m3","executionInfo":{"status":"ok","timestamp":1751799311062,"user_tz":-540,"elapsed":4,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["question = \"본 논문에서 제안하는 전처리 기법은 뭐가 있는지 알려줘.\"\n","\n","response = chain.invoke(question)"],"metadata":{"id":"7iPxE5bTIDoa","executionInfo":{"status":"ok","timestamp":1751799315437,"user_tz":-540,"elapsed":3214,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"execution_count":38,"outputs":[]},{"cell_type":"code","source":["print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z2zqFZdkMn1G","executionInfo":{"status":"ok","timestamp":1751799315454,"user_tz":-540,"elapsed":5,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"3c7bf9f1-5394-46b4-f50f-cf1c00395667"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["본 논문에서 제안하는 전처리 기법은 다음과 같이 두 가지입니다:\n","\n","1.  **구분자 기반 전처리 기법**: '/'를 사용하여 표 속성을 구분하고, 하위 속성은 중괄호 또는 대괄호로 묶어 표 구조를 자연어로 변환하는 기법입니다.\n","2.  **한국어 조사 체계 기반 전처리 기법**: 한국어의 조사 체계(예: \"~에서\", \"~은\", \"~의\", \"~이다\")를 활용하여 표의 열(Row) 값을 완전한 자연어 문장으로 변환하는 기법입니다.\n"]}]},{"cell_type":"code","source":["question = \"본 논문 제목을 알려줘.\"\n","\n","response = chain.invoke(question)"],"metadata":{"id":"GV5tA70xa02g","executionInfo":{"status":"ok","timestamp":1751799317624,"user_tz":-540,"elapsed":895,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"execution_count":40,"outputs":[]},{"cell_type":"code","source":["print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yHi2tstYMtg0","executionInfo":{"status":"ok","timestamp":1751799317635,"user_tz":-540,"elapsed":9,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"3faef8d2-1d5f-446e-8297-8888ba50e4df"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["본 논문의 제목은 \"거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법\"입니다.\n"]}]},{"cell_type":"markdown","source":["### 하이브리드 검색기 사용"],"metadata":{"id":"Rh7qh6paVJ78"}},{"cell_type":"code","source":["%pip install rank_bm25"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nHetP9sgXeID","executionInfo":{"status":"ok","timestamp":1751799328404,"user_tz":-540,"elapsed":7798,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"d658dd20-8901-4421-b27e-08d1d91ccf65"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting rank_bm25\n","  Downloading rank_bm25-0.2.2-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rank_bm25) (2.0.2)\n","Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n","Installing collected packages: rank_bm25\n","Successfully installed rank_bm25-0.2.2\n"]}]},{"cell_type":"code","source":["from langchain_community.retrievers import BM25Retriever\n","\n","bm_retriever = BM25Retriever.from_documents(\n","    documents=docs,\n","    preprocess_func=okt_tokenize,\n",")\n","\n","bm_retriever.k = 3"],"metadata":{"id":"fuyYHcApVQdu","executionInfo":{"status":"ok","timestamp":1751799335860,"user_tz":-540,"elapsed":7447,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["from langchain.retrievers import EnsembleRetriever\n","\n","ensemble_retriever = EnsembleRetriever(\n","    retrievers=[retriever, bm_retriever],\n","    weights=[0.5, 0.5],\n",")"],"metadata":{"id":"IO_t_Zt9aVq2","executionInfo":{"status":"ok","timestamp":1751799336394,"user_tz":-540,"elapsed":532,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n","\n","chain = {\n","    # \"context\": retriever | RunnableLambda(format_docs),\n","    \"context\": ensemble_retriever | RunnableLambda(format_docs),\n","    \"question\": RunnablePassthrough(),\n","} | prompt | llm | StrOutputParser()"],"metadata":{"id":"LKu5iWcpXEje","executionInfo":{"status":"ok","timestamp":1751799336398,"user_tz":-540,"elapsed":6,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["question = \"본 논문에서 제안하는 전처리 기법은 뭐가 있는지 알려줘.\"\n","\n","response = chain.invoke(question)"],"metadata":{"id":"AAhFzHE5asjC","executionInfo":{"status":"ok","timestamp":1751799339742,"user_tz":-540,"elapsed":3343,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iC9QNmKvNY-3","executionInfo":{"status":"ok","timestamp":1751799339765,"user_tz":-540,"elapsed":20,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"00392355-d752-4903-e158-4e6975c6d4b9"},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["본 논문에서 제안하는 전처리 기법은 두 가지입니다.\n","\n","1.  **구분자 기반 전처리 기법**: '/'를 사용하여 표 속성을 구분하고, 하위 속성은 중괄호 또는 대괄호로 묶어 표 구조를 자연어로 변환하는 기법입니다.\n","2.  **한국어 조사 체계 기반 전처리 기법**: 한국어의 조사 체계를 활용하여 표의 열(Row) 값을 하나의 완전한 자연어 문장으로 변환하는 기법입니다. 구체적으로는 표 제목에 \"~에서\", 표 속성에 \"~은\", 표 속성 깊이를 표현하기 위해 \"~의\", 그리고 셀 값에 \"~이다\"와 같은 조사를 사용합니다.\n"]}]},{"cell_type":"code","source":["question = \"본 논문 제목을 알려줘.\"\n","\n","response = chain.invoke(question)"],"metadata":{"id":"5UkhumY0avgi","executionInfo":{"status":"ok","timestamp":1751799340847,"user_tz":-540,"elapsed":1080,"user":{"displayName":"정민수","userId":"15755274897949506279"}}},"execution_count":48,"outputs":[]},{"cell_type":"code","source":["print(response)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gZw3nK7DNbn6","executionInfo":{"status":"ok","timestamp":1751799340867,"user_tz":-540,"elapsed":18,"user":{"displayName":"정민수","userId":"15755274897949506279"}},"outputId":"4fea32cb-624b-40bf-9f29-cf424811931e"},"execution_count":49,"outputs":[{"output_type":"stream","name":"stdout","text":["본 논문의 제목은 \"거대언어모델(LLM) 기반 질의응답 시스템의 표 데이터 이해도를 높이는 전처리 기법\" 입니다.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"MeoVrbtwNdUb"},"execution_count":null,"outputs":[]}]}